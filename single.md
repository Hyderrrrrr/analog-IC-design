目录
目录	1
电路基础篇	3
最基本的概念	4
器件模型	6
MOS管为什么会有饱和区特性的一个解释	8
小信号模型	10
VGS-VTH，VDSAT与V*	12
交流电容模型	15
电流镜的设计	17
Bandgap设计（一）	19
Bandgap设计（二）	22
Bandgap设计（三）	25
OPA与OTA	27
运放：开环与闭环	29
开关电容电路设计	31
开关电容中的flick噪声	33
Δ-Σ AD DA设计	34
怎样做FFT	37
AD DA的REF设计	39
ADC的噪声仿真	41
Jitter的定义	42
反馈与稳定性（一）	44
反馈与稳定性（二）	47
反馈与稳定性（三）	49
稳定性讨论	51
反馈观点看opa（一）	55
反馈观点看OPA（二）	57
多级OPA的补偿	60
信号流图与电路框图	61
传输函数的符号化运算	62
电学噪声	64
谐波参数的设计	67
ESD设计	69
接地二三事	71
版图中衬底如何连接	74
对版图的一些想法	75
一次EMC的debug过程	76
从线性时不变系统到线性周期时变系统（前言）	78
从大信号非线性系统到线性小信号系统	81
线性周期时变的分析方法之一：脉冲响应	84
线性周期时变的分析方法之二：频率响应	86
EDA使用篇	87
Gui vs cmd	88
ADE simulation 的背后	90
EDA版本相关的几件事	92
后仿真的经验	93
EDA使用的一些技巧	96
什么时候需要后仿真	98
几件小事	99
自己如何做一个蒙特卡洛模型	100
在linux下折腾EDA安装	102
设计思考篇	104
仿真的意义	105
物理学家与数学家；科学家与工程师	107
学而不思则罔，思而不学则殆	109
Gm Id方法的思考	110
模拟电路设计的流程	111
提问的学问	113
科学与迷信	114
设计历程	116
个人觉得一些重要的学科	117
总结	118

电路基础篇
 
最基本的概念
我以前的实验室里有个口号，叫做“夯实基础”。我的导师也是非常强调基础，我深以为然。如果基本概念出了错，那后面再多的讨论也是无用功。
在模拟电路设计与分析领域我个人觉得要掌握的最基本概念是线性时不变。许许多多的问题都出在对这个概念的理解上。
从分类上讲，一个系统可以是线性的，可以是非线性的。线性的系统满足叠加定理，即如果输入是a，输出是f（a），输入是b，输出是f（b），那么输入a+b，就会得到f（a）+f（b）。这个性质对于很多分析都很有用。线性系统其实在真实世界很少见，但是非常好处理。而非线性系统虽然更具有普遍性，但是分析方法却不固定。因此习惯上会对非线性做小信号展开，把非线性系统近似成线性去处理。
从另一方面分类，系统可以是时变的也可以是时不变的。这是指系统的参数是否随时间变化。其中时不变更简单。
只要是线性的电路，就可以用冲击响应反映这个系统的所有特征。对时变的而言需要无穷多个冲击响应，而对于时不变的只需要一个冲击响应。知道了冲击响应，就可以用卷积得到时域响应。对卷积做变换，就可以得到频域的图像。其中线性时不变系统，很容易做傅里叶变换或者拉氏变换，从频域去分析考虑。这是信号与系统一书中的核心内容。
线性时不变(缩写LTI）系统的最基本特性就是不变频。只要是1kHz信号进，就是1kHz信号出，再无其他分量，所变的唯有幅度和相位。所以谈到谐波，THD等，一定是针对非LTI系统而言的。非线性一般会产生谐波分量，比如1kHz信号进，出来的1k，3k，5k都有。典型的非线性电路包括Δ-sigma ADC。即使是1bit ADC，纯理想的积分器，也可以由于自身的非线性产生本征的谐波。
时变电路中又有一种周期时变，可以进一步简化考虑。我之前的毕业课题里遇到过一种简单的电路，就是一个电流在电容上积分，然后定时复位。虽然看起来简单，但实际上它就是一种周期时变电路。其他常见的周期时变电路例如mixer，其特点就是输出中出现了和周期频率相关的信号频率。
对于各种非线性电路，周期时变电路，目前的主要分析方法也是向线性时不变系统靠拢。例如非线性器件，就大概其的将其等效为一个线性器件，先讨论基本功能。然后再用其他方法讨论或者拟合非线性部分。周期时变，目前的标准做法是在一个周期内每个时间点求冲击响应或者其等效信息，然后用数学方法得到传输函数。这也是cadence 仿真软件中PSS分析的基础，不过这种方法不是人手工能够做到的。再比如xxx在分析vco特性时，使用了xxx函数，其物理意义也可以看作是一种冲击响应，这种做法是利用了软件现有的瞬态分析，从而避免使用PSS。
采样电路是哪种呢？采样其实就是一种周期时变系统。但是由于它的特殊性以及简单性（每个周期只有一个点的数据有效），数学处理很简单，大家对它研究的比较透彻，分析起来也相对容易些。众所周知，采样有混叠（alias）效应，体现为输入频率会被搬移，而搬移的距离也与采样频率有关，这与之前周期线性的讨论完全吻合。那么它简单体现在哪里呢？虽然有频谱搬移，但每个主周期都是完全相同的，因此只需要分析一个主周期的频谱就可以了。所以从另一个角度看，可以先不考虑频谱搬移的事情，等效成在离散时间上，它是时不变的，从而可以用z变换去替代了傅立叶变换，在频域讨论起来也一样简单。而频谱搬移的特性被隐藏在了z变换与傅立叶变换的关系中。
开关电容电路又该如何归类呢？在这个电路里，有开关的采样，也有时不变的运放。偷懒一点说，自然是周期时变了。不过这就失去了很多可以使用的技巧。所以不如认为它是时不变系统与采样系统的结合。连续信号经过采样，变成离散信号，离散信号经过离散信号处理，在输出被保持系统变为连续信号。这样每一步我们都会处理，从而简化的分析。但是这里的难点就在于寻找采样的边界。 
器件模型
如果所有的mos都在饱和区遵守I=1/2μ*Cox*W/L*（vgs-vth）^2这个公式，也许天下太平，模拟工程师就可以和数字工程师一样直接写代码，一天做成百上千个运算放大器了，spice会没人要，bsim小组也可以解散了。
可惜事实不是这样。由于我们最关心MOS在饱和区特性，因此下面重点看饱和区的公式修正。先说最基本的修正吧（衬偏对vth的影响就不提了）。上面公式里没有vds，意味着饱和区vds增加电流不变，也等效输出阻抗ro无穷大。这和实际不符（虽然模拟电路设计者很希望这样）。最早修正了一项（1+λ*vds)，称为沟长调制，认为是vds电压变化导致了夹断区的长度变化。这个公式似乎是从双极中借鉴来的。进一步，又把λ和管子的L以及电流做了关联，保证L越大，电流越小，ro越大。在有的文章中提到做模型参数提取时判断依据是I-V曲线的rms误差最小。但是ro是I-V曲线的导数，因此当rms误差最小时，未必ro很准。由此看来gm应该也有类似的问题。不过好在我们通常依赖的是很大的gm*ro做负反馈，而gm-C滤波器中也常常要校准，所以不准就不准。
再就是大尺寸工艺下，由于存在边缘的刻蚀，名义宽长和实际宽长是有差别的，这就导致如果需要精确匹配，必须使用同样的宽长，只是改变管子数目。在小尺寸工艺下还存在短沟效应，窄沟效应，w和l会影响vth（对其他各个参数也有影响，但对vth的影响最有名）。至于vth是随w和l变大还是变小，受不同效应的影响不同，不同工艺还不一样。对模拟工程师来说，这个效应一般都是想避免而不是想利用。于是大家就用较大的W和L，避免很小的Δ引入很大的匹配误差。至于多少算合适，如果没有定量的数据，那只能是个人凭经验（感觉）了。曾经有教授说5倍的最小沟长，也有文章认为最小沟长没任何匹配问题。
另一个著名的效应是速度饱和，这针对横向电场（vds）而言。当电场增加，一般载流子的速度也会增加，但是当电场增大到一定程度后，载流子速度基本不变，电流也就随之不增加。对设计者而言，外在的表现就是器件特性变化了：从电流随vgs-vth平方变化改为了线性变化。如果单纯这样变也没什么，但实际中是平方率和线性关系的混合。在最简单模型中可以定义vdsat=vgs-vth，就是vds超过vdsat电压，对I的影响就减弱了。当时是由于夹断效应。现在仍然可以定义饱和电压vdsat，不过这个就是速度饱和引起的饱和电压与vgs-vth的混合体。所以vdsat与vgs-vth就不再有直接关系。但是大趋势还是一致的。
再进一步的修正，有DIBL效应。这个名字很酷，意思也很简单，漏致感应势垒降低，就是加上vds之后，vds增大，由于漏端电场影响了源端，使得对应的vth减小。这反映在I vs. vds的曲线上，就是让曲线进一步上翘，等于减小了ro。
说到这里，应该是很多人经常问的，怎么vdsat不等于vgs-vth啊。如果用我上面的解释仍然有不足。在有些时候，即使采用最简单的模型（没有考虑速度饱和效应），等式也不成立。这是由于我们经常提的平方率公式仍然有一些简化。Mos器件的模型有多种，不同的模型近似程度不同，考虑的细节不同，甚至出发点也不同。但大多数都是从文章开头提到的level1 平方率公式演化而来，为了更接近真实情况，改用更复杂的模型公式，仅仅在level1的情况下，vdsat=vgs-vth，除此之外vdsat不等于vgs-vth是常态。常用的bsim公式中给出了vdsat的定义，是一个很复杂的表达式，不过核心思想还是上面的一些东西。同样，vth等也有自己的定义。仿真器在计算时会算出这些值，一般在DC工作点分析时可以直接看到。估计如果谁有心把bsim的公式按定义重新计算一遍，理论上应该和仿真器给出的值是一样的。不过这等于重新实现了一遍仿真器的DC功能。
版图效应也被器件模型考虑。最早期时为了计算电容，会有源漏面积周长等参数，这相对容易理解。后来版图的影响越来越大，还会影响到直流特性。出现了新的参数sa，sb，sc。这是由LOD效应提取出来的几个参数，对应栅到有源区边缘的距离。LOD指length of diffusion effect，当使用STI做隔离时，栅到有源区边缘距离不同，会有不同应力，从而器件特性不同。这个参数使得把几个并联的mos管单独画和合并画结果有所差异。换句话说，m和finger是不等效的。这曾经坑了我们一个项目。可以想到，如果用共享有源区的方法，ABBA结构虽然中心对称但一定是不匹配的，ABAB反而是对称的。这与以前教科书上的说法完全不同（以前做ABBA，考虑到电容也是不匹配的，但DC参数还是匹配的）。在有的工艺下，随着栅到有源区距离的增加，这个效应急剧下降，当超过一定距离后近似可以忽略，那么也可以通过加dummy的方法使得这几个参数影响不那么大。
到了65nm工艺，又出来了WPE，well proximity effect，指阱到有源区边缘距离不同导致器件特性不同。提取出的是sca,scb,scc，考虑的是阱边缘对有源区的影响。这个公式比之前的sa系列复杂多了，不过可以大致理解为对应者有源区和栅到阱的距离，距离越大，参数越不重要。在设计中，这个对vth影响很大。所以画版图更麻烦了，匹配更难做了，后仿也更重要了。  
MOS管为什么会有饱和区特性的一个解释
MOS有饱和区特性这件事据说Tsividis用河流与大坝模型来解释。这里我想用一个半物理半形象的模型来解释一下。
首先回顾一下电流是怎样形成的，这有利于我们下面的分析。半导体中载流子运动方式一种是漂移，主要是多子在电场影响下移动。另一种是扩散，主要是少子在浓度影响下移动。Mos是多子器件，因此以漂移为主。我们就忽略扩散效应。当以漂移为主时，电流就等于截面积的电荷Q乘以迁移率u再乘以电场强度E。
如果是普通导体，各个截面积的电荷不同，但是电流是连续的，也就意味者各处电场强度不同。但是电场强度沿电流方向的积分就是电势。从这个就可以推导出电阻串联的公式。电压在电阻高的地方分配的多，电阻低的地方分配的少以保证电流的连续性。
MOS的特性有些特殊。他的电荷与该处的电势有关系（因为在正常工作时，主要都是反型层电荷）。当VGS大于VTH，VDS等于0时，沟道电势完全相等，各处的反型层电荷也完全一样多。这是一个非常好的均匀电阻。此时可以等效算出一个等效电阻。但是如果维持VGS不变，当VDS轻微增加δV时，可以想象的到，由于源端的电势不变，因此源端的电荷基本不变；漏端的电位增加，漏端电荷开始减少。相应的，漏端等效电阻变大，电场强度也大一些。对整个沟道而言，电流也会增加，但是在源端来看，他得到的电场强度增加量比平均分配的要少一些，意味者此时的动态电阻比VDS为0时要大一些。所以I-VDS曲线不会是沿着直线变化，而是逐渐向下偏离。
当VDS逐步增加时，总有一天会导致漏端的电荷为0。当这个时刻到来时，再增加δV，压降就会全部落在漏端这一点上，而源端到漏端的电荷与电场强度再也不发生变化，这就是VDSAT点。在这点动态电阻开始变为无穷大，电流不再变化，MOS管从线性区进入饱和区。
如果我们假定当VDS=VGS-VTH时，载流子浓度突变为0，那么这就意味者夹断区域（载流子为0的区域）长度为无穷小，饱和区输出阻抗为无穷大。这是由于如果夹断区域不是无穷小，那么夹断区是绝缘的，一个绝缘材料串联一个导体会使得电流为0。但实际并没有这种无穷小存在。在前面的推导中，载流子浓度突变为0来自于耗尽层近似，同时忽略了少子扩散。当考虑到以上两个效应后，可以知道在这个区域载流子浓度非常小，但不是0，增加的压降仍然会落在这个区域，但是这个区域是有一定长度的，但是长度非常小，电势差近似为vdsat，因此场强非常大，并且会随着VDS增加而变化，输出阻抗也不见得是无穷大。
这就解释了为什么MOS会有饱和区特性。同时从上面的描述可以看出，在夹断区域载流子浓度不是0，我们也无需讨论为什么夹断了，电流还能流过这个区域。另一方面，在传统的推导中，会出现当VDS大于VDSAT，电流下降的曲线。然后书中直接说在VDSAT点取极值得到分区模型。其实这是由于在推导使用的电荷公式只适合反型区域。当变为耗尽区时，公式会推导出负的载流子浓度从而导致错误。
前面的讨论不是很严格，有很多隐含的假设前提。但是基本的大框架还是物理的。所以可以作为一个简化模型形象理解公式推导。如果想进一步严格的用公式推导，可以参考《用于VLSI模拟的小尺寸MOS器件模型》这个书。该书中作者就从最基本的前提出发，列出公式，然后使用一步步简化假设求解公式，从而得到了不同的器件模型。我们也很容易从这个过程中看出，是哪个假设导致了简化模型的差异。 
小信号模型
前面的器件模型里主要提到I-V关系，也就是我们通常说的大信号模型或者DC模型。但是平时设计电路时，用的最多的还是小信号模型。这两者什么关系呢？学过微积分的人都知道，一条曲线，如果在局部去拟合它，最简单最有效的方法就是把它线性化成一条直线。我们的小信号模型干的就是这么一件事。现实的器件I-V曲线都是非线形关系的，但是一旦线性化之后就可以在局部用线形模型代替，从而进入线形时不变模型的框架。但是缺点也不是没有，就是我们得时不时考虑，这个电路是不是真的像我们假设的那样工作，另外，用小信号模型是无论如何得不到谐波等非线性指标的（当然，也有许多变形的小信号分析方法来获得非线形的指标，但那时的小信号模型已经和这里的有了本质区别）。
mos的小信号模型里参数还算简单，一个gm，一个ro(或者是gds），时不时ro还可以被忽略。其中gm=dI/dvgs，ro=dvds/dI。所以用最简单的大信号模型可以很容易算出一个设计时很常用的公式:gm=2*I/(vgs-vth)。这个是针对最简单的模型用的，如果考虑速度饱和，系数就有所不同。实际中自然也是介于两者之间。对于ro，大家没有太多公认的模型。一般来说认为ro与与L和I是负相关的
有的设计思路是针对某个工艺做出各种gm对I的曲线，作为设计参考。这样方法能够进一步提高手算的精确度，俗称gmId方法。从我的经验而言，一般先定L和I，然后大概定个w，能保证工作在饱和区就行，如果有之前的电路参考更好，之后根据.op的仿真结果，只要大概调整一两次w就可以达到目的了，其实也不算慢。调整时遇到的最主要的问题是调整的时候要知道自己需要调整什么才能达到效果。如果起始电路不幸没有工作在饱和区，很多新手（包括我自己刚开始时)就会蒙了，因为不知道该调哪个管子，每个管子的电流都和预期的不一样，有时觉得调的方向正确，怎么一仿真和预期完全不同。所以说理解电路的工作原理是非常重要的，有个好的分析思路也是必须的。当调的时间长了就会发现让mos管工作在正常区域只是工作的一小部分（虽然它很重要），所以无须过于纠结。
前面的小信号模型是指工作在饱和区的mos。但是当进入亚阈值区后，gm就不再是这个公式了。所以为了获得大的gm而不停的减小vgs-vth（如果保证I，L不变），并不像前面公式里提示的那样，可以获得无穷无尽的gm，而是会趋于一个定值。而且到那时，w不断增加，寄生电容也增加，可以理解为进入得不偿失区了。这个原理大家很容易理解，每个公式都有自己的适用范围。不过很多时候在其他问题上大家常犯的错误就是超范围应用各种原理而制造悖论。 
VGS-VTH，VDSAT与V*
cmos模拟电路设计者的常见困惑之一就是vgs-vth怎么不等于vdsat。为什么要等于？他们会说，这是课本里讲的啊。如果我们再仔细研究课本，就发现各家课本里又在后面说了，由于各种二阶效应，例如速度饱和等，这两者是不等的。那么到底两者是什么关系，为什么是这种关系呢？我们其实应该从头来理清。
对一个mos管而言，他才不管什么vdsat，他只知道vgs。从MIS电容理论那里，又发展出了vth这个物理量，当vgs大于vth时，在源端就出现了反型层。在研究mos管IV曲线时，又发现其实I随着vds的变化近似可以分成两个区域来研究的，线性区和饱和区。那么怎么区分这两个区域，人们又找到了vdsat作为区分的标志。从名字上可以看出，这是saturation的vds电压，换句话说，当vds增加到一定程度后，电流不再按照原有趋势增加了，基本保持不变了。所以这是这几个值的原始定义。
从这也可以看出，我们未必需要vdsat电压这个定义，比如有些model里觉得IV曲线不应该这么划分区域，以致仿真常常不连续，在那种model里就没有vdsat的位置存在。
mos的IV曲线是客观的，但怎么描述却是有点主观的，不同人喜欢不同的近似方法，因此就出现了不同的model。大部分model都是从一个1/2u*cox(vgs-vth)^2发展出来的。这个model就是level1 模型。在这个最简化的模型里，自然有vgs-vth=vdsat。这也是我们课本一直在重点讲的图像。但这个模型有点过于粗糙，后面就发展出了许多新的修正。注意只是修正而已，大的框架还是在此基础上。这些新的模型就有了不同的名字，level2，level3，bsim3，bsim4等等。但是由于脱胎于level1，所以vdsat依然是决定两个区域的转折点。但是vdsat与vgs-vth却可能不完全一致。
比如从cadence自带的手册可以查到，level2 里的定义就是
 
这是从手册里复制过来的。在其他模型下又不相同。所以如果较真，那vdsat与vgs-vth的关系就好像隔了好几重的亲戚，不同模型下亲戚关系还不一样。但是这亲戚关系也不是无规律的。很多课本上也提了几种重要的修正原理，例如速度饱和。从上面的图片就可以看出，level2对vdsat的修正就分了两种情况：pinchoff和速度饱和。
再仔细看看定义，也还依稀可以在vdsat里看到vgs-vth的影子。
总结一下，vgs-vth=vdsat是最简单模型里的关系式。vdsat的作用是用来划分饱和与线性区域的，在不同模型下他有着不同的表达式，与vgs-vth只有间接的关系，甚至在有的模型里由于不区分不同工作区域，就没有vdsat这个变量存在。
现在说说另一个指标v*。这个东西没有统一的叫法，所以先从定义开始说起。mos用在模拟电路里最重要的参数就是gm，由于功耗也很重要，所以另一个重要参数是I。往往人们需要用功耗换速度，I越大gm越大，但作为讲性价比的工程师就想到了参数I/gm。在简单模型里，可以很容易推导出gm=2I/vdsat，所以vdsat=2I/gm。在复杂模型里，2I/gm与vdsat没有了直接关系，但是仍然可以定义2I/gm作为一个相似的电压值，有人就叫他V*。
这么看起来V*其实与模型关系不大，不论什么样的模型都可以计算出V*，不像vdsat，在有的模型里就不存在。V*的一个特点就是在从饱和区向亚阈值区变化时，V*先变小再接近不变，这说明一个管子在接近亚阈值区后性价比较高，但是进一步降低vgs-vth意义就不大了。
现在看起来，我们就有了vdsat，v*，vgs-vth这三个变量，其实还有一个vgseff，这是模型里用于计算的一个中间变量。在简单模型里他们是一样的，在其他模型里就没有直接关系了，其含义也是各有不同。不过如果去做参数扫描，就会发现这几个值在亚阈值区和饱和区相对接近。特别的，用我手头几个模型可以发现一些其他规律。1. vgs-vth随着vg的变化是一条直线，但是其他几个值都只是在饱和区接近vgs-th，在亚阈值区近似为一个定值。2.如果考虑速度饱和，vdsat按理会小于vgs-vth，但实际并不一定如此，说明还需要用其他效应来解释。2. 不同的模型中vgseff，vgs-vth，V*谁和谁更接近是不一样的，在level2的模型中 V*与vgseff比较接近，这是由level2的公式决定的。 
交流电容模型
上一篇里说小信号模型，其实漏了电容，所以只是一个直流小信号模型。要讨论交流信号的传输，就离不开电容（在一般的模拟电路设计中，电感出现的概率太小）。
其实对于电容，说起来也好理解，也不好理解。通常在饱和区，大家都知道有cgs，cgd，等等，而每个电容里都包括覆盖电容和本征电容，覆盖电容是由于加工造成的寄生性质电容，本征电容意味着是自身固有的，由于器件特性造成的电容。而大家更为熟悉的就是在饱和区，cgs=2/3cox*Area，是各个电容中最大的，但是cgd则由于miller效应，会被倍乘。这是许多教课书上的标准说法。
这里就说说一般不注意的几个问题。如果用软件仿真，会发现不仅有cgs，还有csg，不仅有cgd，还有cdg，更有cgg，cdd，css等。这又是怎么一回事呢？更常见的一个问题就是设计电路时，常常有人说这个栅上的等效电容就是cgg，所以如果前级接栅，可以用cgg算负载电容，这样说对吗？
首先问各位，c的定义是什么，应该是dQ/dv，而Q是什么，如果是通常的平板电容，两个极板的Q是一样的，只是符号相反。可是在mos这里就有问题了。当在饱和区时，source和drain通过沟道被连在了一起，所以你说哪里是source的电荷哪里又是drain的电荷呢？因此这时就需要精确区分Q了。
所以这里的C，书上起了个名字叫非互易电容，就是Cij!=Cji，而定义是什么呢？Cij=dQi/dVij。所以cgs和csg是不一样了。那是不是不能区分Qs和Qd，就变成糊涂账了呢？也不是，器件物理里根据若干若干假设，还是成功的吧沟道电荷Q划分开了，而不同的模型划分方法也有所不同，通常是4、6开，有的还给用户留了个口子，可以自定义，所谓的xpart。
至于第二个问题，cgg是什么，是不是这点的所有负载电容，是不是可以当运放的负载电容？前面说了，有cij 的电容形式，但是这些电容也不是完全独立的，比如cgs+cgd+cgb=csg+cdg+cbg，如此类型的关系始终存在。那么自然可以定义cgg为cgi之和，其中i=s，d，b。从这个意义上说，这个电容真的很像该点的电容之和。
可是要是用它直接当该点的负载电容，那就犯了严重错误了。为什么？因为假如可以这样干，那还讨论miller效应干什么，我们的仿真器也不用费尽心思优化耦合电容的计算了，一切都很简单了。我们必须记住一点，从某点看去的等效c，实际是和这点以及c的另一端电压如何变化有关的。举例而言，除了miller效应这个例子之外，还可以想另一种情况，电容的两端同样大小的变化，那么这个电容上的电荷不会有任何变化，也就不会有电流流入或者流出，这就是一种有源屏蔽的原理所在。
为什么要强调这个问题呢？因为在做gain boost时，不止一个人给我说，gaiboost小运放的负载电容就是它所连接的cascode管子的cgg。我想这样讨论过这后，应该不会有人这么简单的回答这个问题了。  
电流镜的设计
电流镜是模拟电路里的一个基本单元，可以用于复制电流，也可以用作给差分对做负载。作为一个模块，一般设计考虑的参数包括电流的匹配，输出阻抗，输入阻抗，输出电压范围，有时还包括噪声。而可以调整的参数就包括电路的拓扑结构，管子的w和l。这些参数的设计大多数人都从教科书上掌握的很好了，这里就不再重复。
在实际设计中，一般很少把这么小的模块单独拿出来提些指标出来。所以很多时候需要自己根据电流镜所处的环境有个明确的概念。比如一般为了传送电流用的电流镜，输出阻抗多少算合适呢？这很少有明确的答案。我个人理解，一般电流在产生时都多多少少有偏差，而这个偏差通常很大（因为与片内电阻有关）。所以输出阻抗引入的偏差通常要远小于前者就可以了。而且这也取决于电源的波动情况，后级对输入电流的容忍情况。
在电流镜中，cascode是常用的，要比其他什么wilson之类的常用的多，因为简单而且设计方便。在设计cascode管的偏压时，书上给了几种方法，常用的还是1/4的二极管接法做偏压产生电路，如果不想浪费电流，可以用串电阻的方法。但是后者理论上不能保证当工艺变化时偏置电压可以同步变化（因为电阻的R与mos的特性可以是不相关的），而且面积相对也大一些。前一种方法，书上都讨论的是电流镜管和cascode管同样尺寸，让vds=vdsat，推导出偏压管是1/4。可是如果刚毕业的学生这样照猫画虎，就严重错了。因为cascode管通常不需要和电流镜管同样尺寸，而令vds=vdsat，则管子刚刚在饱和区的边缘，一方面此时的输出电阻还有些小，另一方面一旦存在误差，就很容易使输出电阻下降很多。再者，这是大尺寸下的简单公式，小尺寸下受各种因素干扰，未必合适。所以书上说的只是给指明了一个设计方向，而不是让设计者如此照猫画虎。为了保证输出电阻，更多的情况是为了给实际留margin，要让vds大于vdsat一两百mV，保证不同corner或者当存在mismatch，或者存在其他没想到的效应时（比如IR drop，比如版图效应），也能正常工作在饱和区。另一个问题就是如果cascode管和下面电流镜管子尺寸不同，有没有好的电路可以保证相对工艺不敏感？此时可以把那个二极管连接的mos拆成两个不同的管子，分开优化，原则上这样可以匹配性更好些，好处应该是在仿corner时，不容易出问题。
提到cascode，就说说同样是提高输出阻抗的wilson电流镜。这种电流镜看着非常不舒服，因为和我们的直观完全相反（请注意它下面两个管子的栅极接法和电流镜相反）。但是它也很有来历。在几十年前，有源器件非常昂贵，因此wilson电流镜可以用最小的器件数目做出输出阻抗倍增的电流镜，可以说是一种天才的想法。只是由于工艺的变化，使得这种做法优势不再。和普通的电流镜或者cascode电流镜不同（这基本是前馈结构），这个电路结构中存在负反馈，所以会感觉不习惯。负反馈需要考虑稳定性，就没有前馈的容易设计。但是负反馈也带来另一个好处，就是节点x的输入阻抗很低，比正常的gm-1还小gm*ro倍。利用这个特性，可以去偏置别的栅极，且不怕干扰。例如xx。
类似消失的做法还包括电流镜mos管下面的电阻。在bipolar时期，这个电阻经常出现。这是由于bipolar的gm很大，对电流镜来说这不是个好事情。因为gm大就导致对失配敏感，所以需要这种电阻做degeneration。但是在cmos里就不那么常用了，因为可以通过控制vdsat来控制gm，比使用电阻更节省面积。但是这种加电阻的方法也可以用于减小mos电流镜的flick noise，因此也不能说一定就没有用了。
在低电压下，电流镜也可以有新电路。目前看到的一种是把每个管子拆成两个串联，上面的W/L大，下面的小，下面的处于线性区，号称self biased cascode。但对此我持一定保留意见。如果是长沟器件，从原理上讲，其实完全可以替换成一个长L的器件来增加输出阻抗。而在小尺寸工艺下，就涉及许多小尺寸管子的特性。我曾经曾经用不同的工艺做过实验，对比self biased cascode和单独一个长沟的器件，其输出阻抗各有不同，对工艺的依赖很大，没有明确结论说self biased cascode一定好。。
和电流镜稍微有些关系的一个问题是，用作提供偏压的输出是否要加decouple 电容。这个问题很难回答。加电容好处是减小高频抖动，但坏处是低频恢复时间的增加。razavi的书上也只是提出来讨论，没给答案。也许就是说没有标准答案吧。我问过的其他人似乎也没有定量的方法去判断，很多时候更多的是从习惯出发加电容，因为还可以当作dummy用。从阻抗的角度看，加电流就是减小高频阻抗，当有外界干扰耦合到这个节点上时，节点电压的变动是正比与高频阻抗的。这就是wilson电流镜做偏置电压的好处，因为它同时改变了高低频阻抗  
Bandgap设计（一）
Bandgap是模拟电路里的重要角色，差不多可以说有模拟电路的地方就有bandgap。它的作用一般是提供各种参考电压和偏置电流。除非外加，否则还真缺不了它。
从原理上说，目前用的bandgap都离不开两个东西，一个是ΔVbe，一个是Vbe。前者产生的是一个kt/q形式电压，正比与温度。后者产生的是一个随温度准线性的电压，反比与温度。而bandgap的输出就则由这两个电压线性组合决定。理想情况下两种电压的温度系数刚好相反，就产生了0温度系数电压。至于实际为什么有温度系数，从最大的因素上说，就来自于Vbe，VBe只是随温度准线性，而另一个电压则是线性度很好的。
原理上知道了，在实际中怎么设计？Vbe好说，就是给二极管（或者说三极管）一个电流，取它的电压。ΔVbe则离不开一定形式的反馈，通过反馈使得两个不同的Vbe电压做差值。从大的角度讲，一种是用opa设计的，一种是用镜像电流镜设计的，从反馈的角度看，这两种电路是完全不同的。用opa设计的是一个负反馈，更严格的说，是有两个反馈支路，一正一负，而一定要负反馈强于正反馈，保证整个系统是负反馈。另一种结构是上面一个电流镜，下面一个电流镜，只是下面电流镜加了diode做degeneration。这个从系统的角度讲是正反馈，正反馈如果用在电路里，就一定要保证环路增益小于1才能稳定。由于稳定性的要求，所以这两种电路都不能随便把左右互换。至于仿真稳定性，对于用opa设计的负反馈电路，必须把正负反馈两个支路合起来仿真稳定性，否则仿真结果没有任何意义，因为单看一路信息不完整。对于正反馈，一般都是看看增益是否会超过1。
在一般的应用中，我很少碰到很强调温度系数的设计，这似乎和学校里的要求刚好相反。这也许是因为我设计的电路中ADC和DAC很多都不是测量用的。偶尔碰到那么几个，其指标也在10bit左右，看了看别人产品的datasheet，也只要求30-60ppm，并不是很高的指标。如何在工程上实现一个很好温度系数的bandgap呢？其实我也很感兴趣。这里是说工程上，主要是强调不是仿真也不是从流片中挑出一些。根据我的理解，要实现良好的温度系数必须依赖trim，否则单靠工艺是很难保证的。而trim就是根据测量到的输出去调整Vbe和/或ΔVbe的系数，将输出调整到一个目标值。为了正确trim，得区分不同因素造成的影响，一种是PTAT因素。如果一种误差来源是完全正比与温度的，那么一次校准就可以实现。这是由于我们在模拟电路的课本上已经知道，bandgap如果是理想的，那么在常温下的电压必须是一个常数才能保证温度系数最低（这个常数是和工艺相关的，一般在1.2V附近，恰好是硅的带隙宽度，所以我们把bandgap成为带隙基准源）。当存在其他PTAT因素之后，可以等效为kt/q的系数发生了变化，那么仍然只需要通过调整系数把常温电压校准到这个常数即可。另一种因素是非PTAT，比如Vbe的温度曲线就是弯曲的。那么原则上就必须在两个温度点测量才能知道Vbe的真实系数。还有一种因素是一个offset。比如直接给bandgap的输出加入一个offset，那么温度系数不受影响，但输出值发生了变化。此时如果还用之前的理论值作为目标，那么输出电压正确了，温度系数却会变差。因此这种offset必须在设计时就尽量减小。
上面说了，平时对bangap的温度特性关注的少。那么设计时关注什么呢？我更关心启动问题。这是由于启动本身是一种特殊情况，所以设计者很难准确掌握周边情况，那么该如何仿真？仿真的结果可靠不可靠，都是个大问题。而且bandgap通常负责为其他电路提供支持，bandgap出问题了，其他部分就很难测试了。
bandgap由于本身经常有多个平衡点，最常见的就是没有电流的情况，所以需要加入启动电路来破坏掉0这个平衡点。从原理上讲，0点本身也不是很稳定，在该点存在一个正反馈使得当存在波动时会脱离这个平衡点，有可能自己过渡到正常工作点，但在实际电路中当电路工作在这点时，通常增益都很小，因此小心还是无大错（当然也听说过有人不加启动电路，也同样正常工作甚至量产，这种就没法评论了）。启动电路也是一个利用负反馈的过程，只是非线性更强烈，而且最终一般控制到通或者不通的状态。通常的做法是利用一个电路感知bandgap支路的电流或者电压判断bandgap状态，然后把这个值放大（反相器就可以），再以注入电流的形式去改变bandgap支路的状态。注入的多少都会影响到启动。如果注入太少，可能依旧启动不起来。注入太多，就可能影响到bandgap支路本身的工作，导致启动电路无法关闭。
也看到过另一种启动电路，其实不算启动电路，而算por电路，就是检测上电，如果上电就注入电流，否则就关闭。还有一种是给bandgap支路提供一个恒定的电流源。所以在现实中是八仙过海，各显神通。如果非要说某种才最可靠，现实时不时会给人一个反例，认为不可靠的反而工作，认为可靠的反而不工作。如果真要深究，也许也能发现工作的，在某种状态下会不工作，不工作的，也许是设计时忽略了某些因素。但工程上往往没有太多的机会这么较真。想想QWERTY键盘获得成功的历史就知道了。
前面也说了，启动本身是个不很确定的状态，因此怎么仿真就是个大问题。万一仿真时假设是过程A，但在实际电路中经历的是过程B，A通过仿真确定没问题，B则未必。所以在仿真时，一方面需要尽可能遍历不同状态，比如不同的启动时间，不同的电压，不同的器件corner，不同的温度，不同的mismatch或者系统失配（所以理论上后仿真和蒙特卡洛是必须的），另一方面，最好从原理上确认一下启动的过程，如果有一些非理想因素启动电路能容忍多少。借用数字电路的术语，前者算是直接验证，后者算是形式验证。再就是启动同样是一个负反馈过程，因此原则上也有稳定性问题，只是工作点不像运放那么单一。根据别人的经验，通常需要关注一下启动的波形，避免相位裕度过低造成过冲或震荡。 
Bandgap设计（二）
这个世界有时候很奇怪。
以前blog里曾经说过，bandgap从反馈角度讲，基本上有两种，一种是负反馈，例如利用运放虚地特性，将两个电位钳制，另一个种是正反馈，利用电流镜特性使两个电位相等。这两种在razavi的书上刚好给了两种例子，以前做设计时也基本就是这两种电路结构。
但是今年年初时，看到了另一种电路，很像电流镜结构的bandgap。通常的电流镜结构是上面两个电流镜，下面两个准电流镜，互相耦合），这里上面不是电流镜而是电流源，同时又多出一条支路，构成一个cs放大器，产生的电流去偏置上面的两个电流源。刚看到这个电路时由于不熟悉，觉得很新奇。从反馈的角度讲，似乎是反馈回来两个电流信号，而这两个电流信号又通过下面的准电流镜发生作用，那么到底该如何分析呢？
根据神奇的墨菲定律，之后我又不停的碰到这种结构和它的变形。而且周围忽然有很多人在用这种结构。终于前几天才知道这种结构的名字叫brokaw，而且可以在jssc(1974)上找到原始的文献。看了jssc上的文献才有豁然开朗的感觉，原来事情的发展都是有它的规律的，我们觉得突然是因为我们跳跃的太多了。
其实仔细研究jssc上的文章可以发现，原始文献中的结构和bbs上给出的并不一样。但是如果我们掌握了分析方法，就能忽略这些不一致的地方，关注内在的一致性。
  
这种结构特别之处就在于它有三个支路，和之前的比似乎多了一个支路。但实际上如果我们考察用运放的结构，就可以发现其实那种结构也是三个支路，两个反馈环路互相耦合。所以从这个角度讲，这种结构和运放的异曲同工。jssc上那篇文章就是利用这个说法去分析的。它认为那些管子构成了一个两输入的运放，而运放的目的就是使bipolar上的电流相等。这个运放和我们之前看到的有所区别，主要就是它的两个输入是不对称的。不用运放的概念也可以用反馈的概念，两个输入点，一个输出点，两个输入点分别相对输出点为同相和反相，只要整个环路负反馈强于正反馈就可以使系统稳定下来。
还可以从另一个角度去看这个结构。假如去掉第三个支路，就和接近我们平时习惯的结构。但是还是有一些差别的，那就是系统中有高阻点，整个系统是不能稳定的（这个稳定是指系统中各个点的dc电位是不能确定的）。我们平时的结构可能是将电流源中的一个接成二极管形式。但实际上电流镜也不一定非要把其中的一个接成二极管形式，我们知道还可以用运放的形式去使得两个管子电流相等且一边电位固定。从这个角度看，那个第三支路其实就是一个单端运放，而它与对应的两个管子和起来就是一个电流镜。如果从这个角度看，这种结果其实就是变形的双电流镜结构。而且用这个方法去看电阻应该放在哪边就非常简单了。
进一步延伸，以前我们理解运放结构的bandgap，认为它是两个反馈回路。其实也可以理解成它和上部的器件一起构成了一个电路，而这个电路的特性就是出来两个一样的电流，且节点电压一样。再看电流镜形式的bandgap，也是出来两个一样的电流，这种理解就把正反馈和负反馈这些都隐藏在了电路的上部的实现细节中。
说了这么多，其实只是理清了电路的结构，以后看到这种电路可以很快的判断电阻应该放在哪边。除此之外其实还有一个别的收获。为什么要做这种结构呢？仔细一想可以知道，如果我们用电流镜，那么电流镜两个drain端的压差可能会比较大，所以一般用cascode结构。如果我们用opa做的电流镜，就可以比较自由的调节drain的电压（低电压下我曾经用过这种结构）。这里也是一样的，用了这种结构，虽然多了一路电流，但是电流镜drain的电压更加接近，就相当于用了cascode。不过换句话说，能用cascode，也就省了这一路的电流（如果是自偏置的cascode）。  
Bandgap设计（三）
前面讨论了很多bandgap设计的理论问题。那么让我们在纸面上设计一个bandgap电路吧。我觉得用具体数值的方法来说明要比理论更直观。
首先我们需要一个Vbe。Vbe的大小在常温下一般都在0.6V左右，变化不大。这个值和beta与电流的关系都不是很密切。从厂家的数据中或者从仿真中都可以看到这个性质。因此我们给它的电流可以简单的设置为10uA，取个整数。那么为什么是0.6V呢？一种是从bipolar的电流公式入手，另一种也可以从具体数值入手。在0K时，理论上电压为硅的带隙电压，约1.2V，温度系数约-2mV/K，那么在室温300K时，自然就是0.6V。同时我们还需要一个ΔVbe。可以从公式知道如果电流相等，两个Vbe的差是kT/q*ln(N)，其中kT/q在室温下是26mV，斜率是0.086mV/K，N是bipolar面积的比。为了使两个斜率互相抵消，我们需要2/0.086=23.3倍的差距。这也可以看出ΔVbe是比较小的。N由于被ln了一下，因此N增加，面积线性增加，倍数却增加很缓慢。所以通常N可以取8方便版图。这样lnN就是2.08倍。所以还需要23.3/2.08=11.2倍的差距。这就需要一次电压电流转换来实现放大。就是把ΔVbe通过电阻R1转换为电流，然后再流经电阻R2，就变成了R2/R1倍的电压。所以我们需要两个约11倍关系的电阻，而电阻的大小根据电路的结构而定，很多时候是与Vbe的偏置电流有关的。ΔVbe本身很小，常温下只有52mV。在这个转换过程中一般离不开放大器，放大器有等效输入offset。那么这个offset会与52mV共同放大11倍。假定offset是5mV（通常都是这个量级），就会在输出变为55mV。对于1.2V输出的bandgap，其百分比大约是4.6%。换句话说，1.2V可能会偏5%左右。但是如果其他关系都是理想的，此时的温度系数近似为0。如果我们为了得到1.2V的输出，直接去trim bandgap的比例关系，那么反而得到一个比较差的温度系数。这种情况下，不如在bandgap输出之后增加一个新的放大比例，然后调整这个比例。当然在现实中还需要考虑工艺角的情况。有可能同样的电流情况下，bipolar的电压会偏10mV（具体看工艺），这样输出就直接变化10mV。在这种情况下bandgap电压变化了约1%。也有可能电阻偏了20%，那么给bipolar偏置的电流发生了变化，导致Vbe变化。由于电流变化是被ln化的，因此电阻偏20%的影响对Vbe的影响不会是20%，而是？？。这就是为什么在仿真corner时rfbs和rsbf的影响最大，mos的corner反而不重要。在这种情况下，bandgap的输出发生了变化，温度系数也发生了变化。但是教科书中也证明了，要让温度系数在某个点最低，其输出是一个固定电压。所以对这种情况，可以去trim电阻比例，使得输出恢复为理论值，温度系数也就最小。在实际的电路中，既有电路offset的影响，也有corner的影响，就使得这个情况复杂了。
上面的分析只给出了一阶的近似，而且不涉及具体的电路形式。但是从它出发，就很容易初步确定器件的各个参数。要进一步得到更高阶的特性，比如在一阶中认为是0的温度系数其实并不是0，那就需要进一步的分析其成因并加以优化。比如考虑到Vbe随温度变化的具体性质，就可以知道温度系数曲线一般是向下开口。而考虑到Vbe偏置电流是与电阻温度系数相关的，就可以进一步得到不同电阻对这个温度系数曲线变化量的影响。在这些情况下，理论推导和实际仿真是必不可少的。有时还得在流片测试后进一步修正。  
OPA与OTA
我以前的导师考学生时很爱出两个题，让学生画一个dff，画一个opa，分别代表了数字电路和模拟电路的基本单元。有一种说法，学好了opa，就等于学好了模拟电路。opa（ota）就像模拟电路里的砖头一样，几乎处处可以碰到。说了这么多，就是为了强调opa在模拟电路中的地位。因此几乎每次面试，不论是考别人还是被别人考，几乎都能看到opa的题，问噪声，问输入范围，问cmrr，问psrr，问offset，更多是问miller 补偿。以至于在这里我都快想不出来opa还有哪些特性需要格外强调（当然这里只是说opa的基本结构，如果要讨论state of art的新结构，那估计可讨论的太多）。
说说miller补偿。miller补偿公式估计被大家背的滚瓜烂熟了。但是如何深入的去理解挺是一个问题。因为我们习惯了一个节点对应一个极点的思维，然后顶多就是通过miller效应改变了第一级的c，如果有人问你能否用miller效应计算输出级的极点，该如何回答呢？。另一种想法就是第二级也可以看成一个带反馈的放大器，cc也是反馈支路的一部分。用这种思路，就好理解nested miller opa的设计。也比较好理解有的文献中说的nested miller opa可以提高运放的thd（不仅仅是通过增加前级增益）。
miller补偿里我们当年还碰到一个陷阱。通常认为miller电容是gm*r*cc，那么当gm*r小于1怎么办？这个例子很简单，但是也提醒我们每时每刻都要记住所运用公式的前提是什么。每次出现陷阱大都是因为我们忽略了前提，胡乱用公式导致的（我想起了小学生做数学题最爱干的事情，就是凑答案）。
再贡献一个别人出的题目，一个opa，如果带的负载不是CL，而是一个电阻串一个电感，传输函数变成什么了？
说说opa的环路仿真。要仿真环路，必须做到DC连接，AC开路。DC连接，opa才能工作在正常的工作状态。文献中给出了不少方法，有大的RC（LC）断环路，有特殊开关断环路，但是这些都有共同的问题，就是保证了DC,但是在AC态时忽略了断开点后级对前级的影响。如果断开点后级对前级影响很小，那问题不大，不然仿真结果就有较大误差。所以现在stb仿真用的较多，按照软件自己的说法，它考虑了后级对前级的负载效应。
开关电容里的opa仿真也是个麻烦事。不知道大家注意到没有，开关电容电路并不是一个线性时不变电路，所以我们才会觉得那么的别扭，以往积累的经验都没法用。如果不是线性时不变电路，该怎么办？目前有两种思路，一种是近似简化，把它近似成线性时不变LTI的，另一种就是认为，时变就当时变去考虑。后一种就会用到pss，pac等新的仿真手段，但是好像目前还没有pstb，而且对于线形周期时变电路的稳定性判据，也不应该沿用以前LTI的稳定性判据。所以这种方法有优点也有缺点。前一种方法很好理解，假定时钟周期很长，那么在opa稳定的一段时间内，我们就可以认为这是LTI系统。但是请不要忽略掉这种方法的前提，否则又会掉进一些陷阱里。
我看到其他人最爱掉进去的另一个陷阱是cmfb电路的仿真。经常仿真出来bode图完全不像正常的样子，相位开始就翘上去，然后又下来，但是看pm也能看。如果仔细看过gray书中讲cmfb的部分，就知道，其实有两个cmfb环路在系统中。其中一个虽然对系统影响不大，但是如果断环断错了位置，我们仿的loop gain就和真正要看的完全不是一回事。也有的人避免了这个错误，是由于他没有接外面的另一个环路。但是从仿真的准确度以及仿真的稳定性角度说，外面的环路应该接上为好。 
运放：开环与闭环
运放的设计是基础，但是对于初学者来说，总有一道跨不过去的坎，那就是怎么分析怎么仿真。这也许怪不得初学者，市面上的基本教科书除了allen的书提到用L和C对运放构成直流闭环AC开环的测试电路之外，其他的书对此都没有具体提。如果老师再不提这个事情，那学生自然就一直是一头雾水了。
我个人觉得对于运放，可以用开环思考闭环仿真这几个字来总结。先说闭环仿真，这基本上是大家的共识。主要原因就是opa如果开环来仿真，就需要在输入端加入一个offset电压补偿，否则由于比较大的增益，输出不是为高就是为低，运放的工作点也就不正常了，但是这点很难做到。所以在仿真时我们一定要让电路在直流构成闭环电路，使其工作点正常。至于交流，由于我们一般是要测开环特性，所以AC下需要电路开路。为了实现这个直流闭环交流开环，其实有很多方法可以用，比如之前提到的LC电路，或者RC，或者spectre下有特殊的器件。当然了，现在最流行的应该还是spectre下直接用stb方法，就不用考虑那么多了。
这次blog的讨论重点其实主要在前一项：开环思考。如何分析opa的静态工作点，各个器件该如何选择，各个器件大小和电路静态工作点的关系等等，其实是我们分析opa的第一步。开始的时候可能很容易犯晕，不过如果用合适的分析方法，就可以将这个过程简单化。首先我们应该认为电路工作在开环模式下。这是由于如果一开始就认为opa像仿真或者实际使用那样是闭环，那么在分析中就会把反馈引进来，输出就会反过来影响输入，从而把事情搞复杂）。其次，把电路里的节点分为高阻节点和低阻节点。高阻节点就是节点的对地电阻为高，比如两个mos的漏相连接。低阻就是节点对地电阻为低，比如mos的源和漏连接。一般来说，低阻节点的电压是可以容易确定，而高阻节点的电压却是不确定的。举个例子，比如一个反相器，输出就是高阻节点，它的电压与输入有关系，但是如果我们说输入是3v，输出电压的范围也是很大的，从1v到4v都有较大可能。（有反应快的应该已经看出，这里其实也和增益有关系）。在实际电路中，高阻节点的电压到底是什么呢？为了简化分析，可以认为阻抗无穷大，这意味着高阻节点的电压可以是任意值，只需要它的输入节点有轻微的变化。先考虑理想情况，就是电路如果没有任何系统offset，那应该是什么样子的。在这种情况下，从后向前分析。以通常的两级运放为例。在最后一级，输出应该是中间电平。而要输出中间电平，上下的电流应该是一样的。第一级的输出（电流镜的输出）根据对称性，应该和相应的电流镜输入电压相同。这个电压又决定了第二级放大级的电流。所以要实现零系统offset，理论上应该设计第二级放大级的大小使得电流与第二级电流源的电流一致，根据这个原则就可以确定各个器件的尺寸。那么非理想情况呢?非理想情况下，得考虑mos的输出内阻，得考虑电流镜匹配有误差，等等等等，还得考虑我们未必按照前面所说设计管子大小。这时候开环运放就有了系统offset。这时候该怎么考虑呢？这时得考虑反馈了。反馈的最终目的是让运放工作正常。这时运放的输出就会被反馈固定在中间电平。要实现这一目标，系统的各个部分电压都会发生多多少少的变化。对于低阻节点，该变化很小，但对于高阻节点，该变化却可能很大。所以此时我们不如倒着想这个事情：输出节点电压固定，反过来确定上下电流应该一致，反过来确定第一级的输出电压，反过来确定第一级的输入应该有一定的电压差，这就是系统offset了。
举两个例子做说明吧。一个是典型的classAB设计，就是用浮动电流源对输出级偏置。其实这个电路就是开环给输出级上下两个偏置，如果一切都理想，输出级的电流就等于是被一个电流镜偏置，所以静态电流是可控的。当然了，在实际中这个条件其实有时满足的并不好，所以系统offset必然会产生，从而进一步调整直流电流和上下两个管子的偏置电压。我常常碰到的情况就是理论上p和n管各自流过一半电流，但是如果按照理想的尺寸带入，可能并不是对半分。这就可以等效理解为和前端有了offset一样的效果。所以这时候可以调整一下尺寸，尽量对半分，使得当前端真正有信号时，也不会压缩可用摆幅。
另一个是allen书中提到的classAB。电路原始形态就是在两个输出管上各加一个运放构成的负反馈，减小输出电阻。理想情况下输入是电压v1，输出也会是电压v1。但是考虑有运放offset，那么上下的opa就会竞争，输出到底是v1+offset1还是v1+offset2，显然就是个问题。这里的主要问题就是在开环时输出被两个运放反馈控制，其实是个低阻点。最后为了实现输出是某个值，就必须有一个或者两个运放失去自己高增益的特性才可以，而这就意味着之前的假设不成立，输出级的电流可能变化很大。这个电路在80年代的jssc上出现，后来有好几篇对这个结构的改进，核心就是不要让两个opa去竞争控制一个节点的电压值，而是引入另一个调节机制，让某一个运放具有一定的适应能力。 
开关电容电路设计
开关电容电路曾经非常重要，Themes有一本80年代的书专门围绕开关电容滤波器展开。题目却是信号处理所用的模拟电路。当时开关电容电路的一个重要领域应该就是滤波器设计。但是时过境迁，开关电容电路在滤波器方面的应用显得少了些，而在AD，DA等电路中却成了一些基本构件，这还是得归结与工艺的变化，数字信号处理代替了不少模拟信号处理的领域。
由于开关电容电路成了AD，DA等电路的基本构件，所以我觉得它其实应该和opa设计一样，成为教科书里的基本内容。razavi的书就反映了这个特点，而gray的书似乎就有些反映迟缓了（不知道第五版如何）。
这里就说说开关电容电路里一些常见的问题吧。首先时钟怎么产生？放现在也许是个烂问题，但是放十年前真是一个经典的面试题。其实就是看大家如何理解为什么需要这么设计时钟，特别是关于电荷注入的分析。其次是电路的传输函数。如果简单的只有几个，估计大家都能写出来，无论是背还是电荷守恒推导。但是如果控制信号很多（如CDS电路），或者有环路（如Δ-sigma），该如何分析呢？其实我也不会一下子写出来。laker，allen等人的书上给出了一套系统的分析方法，可惜我看过之后仍然记不住，主要是觉得性价比太低，即使记住了用的很少，时间一长就忘了。那套方法我觉得当年是为计算机分析开发的，更注重自洽与规整性。所以我平时记住的唯有正向增益和反相增益两种最常见电路传输函数，其实百分之七八十的电路都不脱离这两种。对于CDS里那么多复杂的，也只好求助于电荷守恒了，好在他们的电路复杂，但规模并不大。而对于Δ-sigma，里面一个最重要的问题就是存在hold，因此在整个环路分析中必须小心相位关系（在这里翻船是常事）。再一个问题是建模，主要是速度建模。这方面大家基本方法一致，都是认为先有sr区域，当sr的斜率等于与BW对应的初始SR一致时，转入指数上升区。Δ-sigma设计中好几个simulink都是如此建的模型。因此这时候它的建立时间其实是个非线性的。在此基础上，有人提出opa设计的一些原则，有认为要sr大的，有认为可以优先考虑BW的，又有说经验上看，几比几分摊时间的，等等。关于这点，还真不知道哪家的更准确。不过一般sr和BW还是有一定关系的，sr~I/CL，BW~I/vdsat/CL，但是大家一般取输入管vdsat似乎也习惯较小，所以似乎想优化可以，但是范围也不一定会太大。不知道是否有人专门把输入管的vdsat取较大值。说到这里想起来有一个问题，如果是单级opa，输入管的cgd和反馈电容是并联关系，但是如果是多级，输入管的cgd就被用miller效应算成对地电容，为什么会有这么大的变化？开关电容的噪声也是一个问题，大家习惯上就用kt/c去算了。但是为什么说是kt/c，kt/c前面的系数应该是多少，这个kt/c代表什么含义的噪声，能说清楚的估计不多。可以看一下我以前的blog，这种噪声是线性周期时变电路产生的，所以和传统的线性时不变系统产生的噪声有一定差异。所以估算用kt/c也不失为一种简单方法，仿真用pnoise也不错。想了解跟多内容，我觉得understanding Δ-sigma ADC的附录可以算一个入门，cadence自带的介绍pnoise或者design guide上的pnoise介绍可以算仿真的入门。最后一个问题就是开关电容电路怎么仿。其实单纯的开关电容电路似乎问的人不多，许多人关心的是共模反馈如果用开关电容电路，原先的opa怎么仿。做法有好几种，一种是用连续时间的行为级直接替换共模反馈，一种是先瞬态让共模反馈建立好，然后用此时的工作点仿真ac（spectre里是在ac仿真处选previous op，而且要让tran先仿真），据说还有一种是用pac，这种我是没用过。从原理上说前两种都是忽略共模反馈本身引入的周期时变特性，只是让它提供一个共模点，而后一种则是把运放当时变电路看待，原理上有本质不同。 
开关电容中的flick噪声
开关电容电路里一般提到1/f噪声都一笔带过，原因是白噪声由于混叠效应，一般占主导地位。但是凡事也不能太绝对。在低信号频率时，比如音频adc，dac，比如测量adc，1/f噪声也可能起到重要作用。
1/f噪声同样也要受到混叠的影响，只是由于它下降的很快，所以混进带内的成分就少的多，所以一般认为不存在混叠也不会有太大误差。我个人觉得评估1/f的一个办法就是直接用noise分析，而无需考虑pnoise分析，只要基本概念清楚，两种应该差异不大。但在实际仿真中，这个想法还是有问题的。我有很类似的两个电路，只是工艺有所区别。在前者上就可以做到两种分析方法基本一致，后者就差别很大。仔细看进去，后者居然告诉我开关提供了很大成分的1/f noise，这更是与传统观点有显著差异，而且通过改开关大小，似乎也影响不大。查查文献，有人做chop类似的电路，也在理论上提出有1/fnoise的影响，但是后来几年又有人说没有。大家都有实验结果，不过相对来说说没有的人似乎更多些。我这虽然不是chop电路，但在1/fnoise的影响机制方面是类似的，所以到底有还是没有，这是个问题。如果说有，那就是等于认为仿真器不会说慌，因为它毕竟是基于某种算法给出的噪声，而这算法则是基于某种理论给出的，换句话说，该理论的直接推论就是有影响。如果说没有，那就是等于承认传统的理论，而认为pnoise背后的理论有可能有缺陷(这也不是不可能，至少design guide网站上就有文章给出了例子）。
这件事的最后是调整了一下电路的工作时序，1/f noise的影响就变小了，和以前差不多。这就更给人提出了一个难题，这种调整对1/f noise的影响是真实的还是虚假的？是算法敏感还是实际就是如此？其实我很想做个对比实验的，只是考虑到这是老板的钱，还是没机会这么奢侈的流片。也许学校里可以就这个发个论文。我个人倒希望这是真实的，这样才像一个真实的世界。估计eda公司也希望这是真实的，这样以后大家就会更依赖于仿真验证。  
Δ-Σ AD DA设计
这个题目实在太大了。我觉得在这里只能写成一个提纲的形式，具体的内容还是需要个人自行研究的。
1.看什么书？我强烈推荐schreier的那本understanding Δ-sigma data converters，科学出版社有影印版，不过据说现在已经卖光了。这边书好处是深入简出，还带有实例和行为级工具箱，基本覆盖了各个方面。之前看了不少其他的书，都不如这一本令人觉得立刻清晰了很多。许多人还推荐另一本Δ-Σ data converters theory,design,and simulation。作者也有schreier，不过内容实际是多人的汇编。这边书英文版是黄色的，如果你能有一本，时不时拿出来show一下，也能给其他人很深的印象。不过这边书是我刚开始学时用的书，感觉很不好，基本不是针对初学者写的，而可以算高级文献总结，读每一章都很吃力。其他还有很多书，不过大多是专门于一点。
2.系统设计。系统设计就涉及到系统函数的设计。在系统函数里，根据实现的不同，区分为连续，离散，离散的通常用sc电路设计，似乎用的较多，连续的则可以省略前置的antialias滤波器，功耗要节省不少，速度也能做上去。根据处理信号的不同，还可以区分为低通和带通（复数信号也可以算在内）。后者在通信里用的多。根据结构不同，可以区分为单环和mash。单环要做高阶的就有稳定性问题，mash每个环路都只是低阶，稳定性问题不大，但需要考虑各个环路之间的匹配。根据量化器，又可以区分为单bit和多bit。单bit的量化器不用考虑反馈DAC匹配问题，但是系统的非线性特性强烈。多bit刚好相反，在反馈DAC中必须考虑匹配问题。根据零点位置，还可以区分为零点均在dc和在dc与其他位置（这里只针对低通的讲），有不在dc的零点，就得考虑做局部反馈做出该零点，因此实现上有所不同。
在定系统函数时，绕不过去的一个问题是稳定性。对于1阶2阶，理论上只要信号不超过vref，就可以一直稳定。对于高阶单bit，有人给出rule of thumb是不能将传输函数的最大增益做太高。也有人提出要用不同信号去测试系统的稳定性，但是用什么信号才算比较合适？我没下载到相关文献，所以也不知道当初的人是怎么考虑。我们这边是说尽量用低频信号，但是具体的准则也完全靠自己掌握。对于多bit，有公式给出稳定的信号范围。但是对这个公式我也不是很理解，因为它给出的是稳定的充分条件而不是必要条件。如果信号出了这个范围又如何呢？从仿真看，似乎有时这个公式给出的范围非常小，那么是否一定要保证这个条件呢？
在系统函数确定的过程中，书上给出了一个约束条件，就是脉冲响应的第一个输出为1，等价于环路中必须有延迟，等价后就好理解原因了，因为涉及到可实现性。
定好系统函数之后，存在一个从系统函数到实际各个系数的映射。首先的一个问题是映射成量化器输出送到每个积分器输入还是映射成每个积分器输出都送入量化器。这实际就是信号与系统里IIR的两种实现结构，在书里就是feedback（FB）还是feedforward（FF）。这对信号传输函数的实现有影响。但是对最终实现的硬件开销是否有影响呢？这个在很多时候就是等于问电容的大小。书中给的例子里FF要好一些，但是否是常态这是个问题。sansen给出了一种把输入信号也送入量化器的结构，可以减少内部信号的大小，也可以减小电容。
在实际映射时，可以发现其实有多余的自由度，换句话说映射不是唯一的。这就给了scale空间。scale实际是开关电容滤波器设计中常用的方法，就是尽量让节点的输出占据所有的动态范围，保证最好的snr。scale的原理其实也不麻烦。在1bit实现中，还存在另一种效应，就是在量化器前加任意增益，对系统无任何影响。这对映射和scale有何好处？谁能谈一谈？
实际各个系数定好后，基本就是确定电容大小了（以sc电路为例）。而最关键的就是输入电容的大小，因为它对噪声的影响最大。如果只是理论，自然可以用ktc理论进行计算，但总有些不放心。但是如果用pnoise之类的仿真，就得搭建合适的仿真架构了。这个我还一直没走通，在design guide里有相关的介绍。
对ct系统的设计更复杂一些，看许多文献里是用冲击响应不变的理论设计，先给出dt的原型，再根据公式转换到ct域。由于只是了解了一下，没有动手，因此不在这里多说了。
3.电路设计.电路设计其实就落入了传统电路设计的领域。运放需要设计多快，增益需要多高等等，底限是多少。行为级仿真很有必要，理论是不是有提示呢？对于增益，理论分析认为只是影响零点位置，行为级分析里也是如此，因此给出的rule是大于osr，这似乎太宽松了。实践中似乎没有人这么干。对于带宽和sr，90年前后有人做的论文给出有两个设计区域，一个是sr很大bw小，一个是sr小bw大，都可以。不过实践中sr和bw也是基本同步变化的，所以也不会有人刻意将一个做大一个做小。至于bw应该是fs的多少倍，似乎也没有定数，一般几倍就可以了。
4.dac设计。dac比较可怜，讲了adc就很少谈dac，因为有些类比性。从模拟角度看，就是低通滤波器，只是这个滤波器比较特殊，需要考虑整个周期的特性，而不是像一般的sc滤波器，只考虑采样点的特性。这里我一直有个问题，就是音频dac的带外噪声如何考虑。如果太大，导致后级速度跟不上，自然不行，但是如果能跟上呢？因为人耳本身就是低通滤波器，是否就可以不考虑了呢？为什么许多音频dac的指标里还特意标明了这点？  
怎样做FFT
怎么给AD DA的结果做fft（快速傅立叶变换）是初学AD DA的人常问的一个问题。这也难怪，一般的模拟书上不怎么提这个事情，我只记得baker的第二册上有一部分内容讲这个。其实要理解了这里的道理，就发现这也不是太神秘的一件事情。
fft其实就是对一个信号做傅立叶分析，但是与傅立叶分析不同，一是它是将信号离散化，二是加了快速算法。通常的傅立叶分析用的是一个信号的全部时间信息，但是离散傅立叶变换（DFT）就只用了一些时间间隔上的信号信息。这样做可以适应计算机，但是也有一个问题就是有混叠效应（alias）。要避免混叠，就必须满足采样频率大于二倍最大信号频率。但在实践中，这个也只能改成尽可能大于。如果对DFT在计算过程中运用一些技巧，就能使速度提高很多，这就被成为快速傅立叶变换（FFT）。而这些技巧也不是随便能用的，这就引入了一些约束。
对AD做fft，其实比较直观。AD本身就是对输入信号采样的，所以只需要把输出的数字信号做成数组，去做fft。有的人习惯了模拟信号，似乎对离散信号没有感觉，非要把这个数字信号再用DAC传成模拟量，然后做分析，这就等于又绕了一圈。如果是仿真，等于多加了一个仿真器件拖累。当然在实践中我也可以理解，因为如果用caculator做fft分析，就只能这样。但是如果用matlab做分析，就没这个必要了。对于实际测试，如果没有逻辑分析仪，只有频谱分析仪，也只能这么绕一圈测试，这属于没有办法，但是在具体测试中得注意DAC的引入实际对AD的结果是有影响的，所以这种比较适合精度不高的AD。还有些人概念如果不清，没有注意到DAC的结果并不完全是ADC的结果的复制，那就有可能把DA的问题认为是AD的问题。
要做好fft，第一个要求是采样的点数必须是2^N。其实这条如果违反了也并不是罪不可赎。因为这是为了使得fft能够实现快速算法的一个约束。如果违反了，第一，现在电脑速度这么快，第二，fft算法本身在进步，2^N是最优，但也有一些次优的选择，第三，有时候我们分析的点数并不多，所以违反了也不是犯了天条。不过建议还是用这个最优的约束条件，有时候能把30s的分析时间缩短到1s（假如分析的点数很多，又不是那么优化）。
第二个要求，是在分析的时间内有M个被分析信号周期，M应该与2^N互质。这个要求非常重要，特别是如果要考虑谐波之类。为什么？首先说必须要有整数个周期，根据fft的性质，被分析信号的能量就会集中在第M个bin上。如果违反了这个，能量就会分散在多个相邻的bin上，形成频谱泄漏，大家可以看看那时fft的结果，信号就像一个大斜坡，一直向两边延伸，淹没了其他bin上的信号。其次，这个M必须和2^N互质。如果不这样，M的整数倍信号就会落在几个固有的bin上。对于AD，其量化噪声实际并不是真正的噪声，而是和信号同周期的。所以一般我们只有用互质的做法，才能将量化噪声打散，显现出真正的谐波。当然也有例外，有时为了突显量化噪声，专门不采用互质的做法，这也是有实例的。所以关键还是了解背后的原因。
前面说的在仿真中很容易满足。但在测试中却未必容易，主要是由于第二条中对信号频率有严格要求，而且这个频率一定要与ADC的采样频率同步，这个实施起来相对困难。即使是仿真，也有可能由于数值误差导致轻微偏离整数周期。所以就有一个加窗的概念。加窗是信号与系统里一个概念。当信号不在一个bin上时，让这个信号的主要能量占据的bin尽可能少。但是存在一个基本矛盾，不同的窗，如果信号主要能量占据的bin比较少，信号在这几个bin外的的能量就比较大。反之信号主要能量占据的bin比较多，信号在这几个bin外的能量就比较小。所以需要根据需要加不同的窗。在仿真中由于基本可以对齐周期，所以可以选用Hanning窗，其能量主要占据3个bin。在实际测试中数据较多，偏离整数周期较大，可以选用BH窗，其能量占据了5-6个bin。
上面说的是AD的仿真，测试结果做fft。对于DA，有另外一个特性。DA的结果是个连续量，切换过程也是有意义的，这和AD不同。因此在DA的一个时钟内必须采足够多的点才行，如果一个周期只采一个点那是远远不行的。 
AD DA的REF设计
以前做过一段时间的ad和da，但是对于reference应该有什么样的要求一直没有从理论上想透彻，只是说如果仿真没问题就可以了。查了一些书与文献，似乎也很少有专门讨论这个的。前两天，前同事过来问这个问题，于是边讨论边分析，觉得反而把以前一些没想通的问题连贯了起来，逐渐条理化了一些，因此在这里先初步写一些。
先说明一下，这里主要还是定性半定量的讨论，至于定量的结果，一定还是以瞬态仿真为依据了，因为读者也可以发现，在下面的讨论中有比较多的近似。
先说ref对ad和da有什么影响。无非就是两种，一种是谐波，一种是噪声。在这里必须强调一下，ad和da的结果与ref不是线性关系，而是乘积关系，因此谐波和噪声的出现是一个非线性的过程。从数学上看，输出y=输入x*Vref（或者是除以，但在小信号下把除法变换成乘法，分析起来相对简单）。如果vref不是一个恒定值，一种是vref本身有与x无关的噪声成分，另一种是vref有与x有关的成分，那么产生了噪声和谐波。
先说vref里有噪声，那么假如x是正弦波，就等于噪声被信号卷积到了信号附近，且一个特性是信号越大，引入的噪声越大。根据这个，应可以算出ref中噪声的要求。对于奈奎斯特AD，这里的算法都很简单。对于Δ-sigma AD，算法就比较麻烦，因为存在带外信号的影响和过采样的影响。简单想，就是即使没有信号，带外依然有较大的信号，这些信号会把ref上的噪声送到带内。但是送入多少又与噪声本身的形状有关，假如是白噪声，应该能得到一个表达式，并且这个表达式与带外信号的总能量成正比。
vref里不仅仅有噪声，还有可能大小与信号有关，因此就有谐波项产生。对于Δ-sigma,带外有大量的能量，那么那些能量的谐波也可以进入带内以噪声的样子出现。那么哪些情况下会使得vref与信号相关呢？与电路结构有关，与vref的设计有关。一般ad da都是开关电容电路，那么就有与信号无关的设计和与信号有关的设计两种电路，这两种电路在vref上抽取的电荷是不同的。即使与信号无关的设计，由于非理想因素的存在，也多多少少会抽取不同的电荷。而从ref的角度看，如果本身是个理想电压源，那么即使抽取的电荷每次不同，也应该保证vref是个常量。但实际上ref无法做成理想电压源，特别是高速情况下。所以从这个角度看，保证ref的输出电阻在对应的信号频率下足够小就是必要的。
这是仅仅考虑了ref的特性，认为其他特性都是理想的。当其他特性不理想时，如采样时钟也存在与信号相关的jitter，会导致大家互相作用，进一步降低谐波特性。所以前面的讨论只是给出了上限。
有人会问平时不是都是用带宽去讨论速度的吗？比如一般都要求ref在电容上建立到0.5个lsb的精度以下等等。这就等于要求refbuf的带宽。这与输出电阻的分析是否一致呢？对于一级opa，这两者是一致的，没有任何问题。对于两级opa，分析有些复杂。其实速度与带宽并非直接关系，而主要是与输出电阻有关，带宽通过影响输出电阻间接影响了速度。这个结论很奇怪，但是推导过程却不复杂，只要把小信号框图画出来就可以看到由于输入为dc，因此反映输入项的gm是不存在的，只有输出电阻在图中。当周期接入负载后，实际是一个周期线性过程，可以近似用周期近似法，等效成两个阻抗分压。这种分析方法忽略了大信号过程，但是至少相对准确的给出了对ref输出阻抗的要求。
因为以前是做音频方面的ADC，DAC，对绝对精度的要求不高，上面的讨论也默认了只考虑谐波不考虑绝对精度。对于重视绝对精度的应用，又是另一种讨论了，那时就必须是建立精度在0.5LSB一下。对于这种情况，输出阻抗只是一方面，因为建立误差影响绝对精度，而建立误差不仅仅和输出阻抗有关，还和初始状态有关。

 
ADC的噪声仿真
http://www.designers-guide.org/上有好几篇优秀的文章讲解一些模拟电路与EDA的使用。不过有一篇讲在device级仿真Δ-sigmaADC噪声的文章，我感到还是有问题的。
设计Δ-sigmaADC的人都知道，想在device级直接用仿真器得到等效噪声是很困难的事情。noise仿真是不行的，由于有比较器，pnoise也不行。仿真速度太慢，tran noise也效率不够。没有了仿真器的验证，单靠手算，又无法double check。在这个意义上看，那篇文章的想法是不错的，只考虑第一级，把比较器去掉，就可以用pnoise进行仿真了。
但是它存在两个问题。首先这个模型里没有包括vref的效果。vref噪声的影响是比较难于用简单手算得到的，因此有时希望用仿真来验证一些想法。但这个模型里就无法加入vref的噪声。（btw，vref的噪声会怎样影响，vref通路上的开关如何引入ktc噪声，两者关系如何，这些问题挺考验设计者对噪声对系统的理解）
其次，用文中的方法仿真得到的结果与手算的差一倍。手算应该是多少，其实也有人有不同看法，我是根据schreier附录里的思想分析得出的。然后用这个文章里的模型验证，发现仿真结果刚好少一半。哪里出了问题？分析了一下，我认为还是仿真出了问题。开关电容电路里有两种架构，一种是通常所见，另一种是flip 结构，采样电容在第二相被背在opa上。在Δ-sigma里ref反馈的电容在第二相不是被背在opa上，而是被背在opa的输入和比较器的输出。但是在该文章里由于省略了比较器和第二级积分器，就变成了背在opa的输入和输出。通过一些简单的计算可以知道，这刚好就造成了一半的噪声丢失（这也是一个常识，即这种flip结构的好处），所以理论和仿真可以达成一致了。
由此可见，有时候简化的不恰当，是会导致根本性的差异。但这也不是说手算就一定比仿真好。比如有人就记住了ktc噪声，但是这个c应该用哪个，如果是两级opa如何考虑，vref反馈和采样电容合并或不合并情况下如何计算这些细致的问题如果没有能分析清楚，记住一个ktc的结果也就是无意义的了。 
Jitter的定义
jitter可以理解成另一种类型的噪声，也就是一种随机量，只是这个随机量是用时间来衡量的，而不像普通噪声那样是用电压来衡量。
不幸的是由于不同人群对jitter叫法的不同，不同人群对jitter侧重点的不同，导致jitter的含义极其混乱。如果有兴趣，可以在jssc上看看大家都是怎么把不同含义的东西叫做同一个名字的。
在这里我大概总结一下jitter的定义。首先常用的jitter可以分为三种，这三种基本可以理解为一个是另一个的微分项。假定有一个理想时钟，那么每个时钟沿对应的时刻就是nT，其中T是周期。而一个带jitter的时钟，每个时钟沿的时刻就是t(n)。这里我们说的是“时刻”。那么误差就是nT-t（n），这是一个随机变量，这个变量我们就可以叫它phase jitter。如果是用相位衡量，那就是phase noise。第二种jitter是period jitter，就是用时钟的周期T（n）减去标准周期T作为随机变量。可以看出时钟的周期T（n）实际就是t（n）的微分项。第三种jitter叫cycle to cycle jitter，就是相邻两个周期的差作为随机变量，仔细推导，可以知道它是第二种的微分项。在实际应用中，还有一种变形，就是将多个周期合起来作为一个周期，这可以应用于前面三种jitter定义中任何一种。我个人觉得他可以算三种定义的变形，在本质上区别不大，因此为了简化讨论就不说那么细致了。（有的paper的定义不完全一致，我给的名词是大家比较常用的，大家只要知道实质就好，如果碰到了不同的名词，可以看看它是怎么定义的）
三种jitter对于不同的应用，完全不同。在adc，dac里时钟误差造成的噪声完全是随着phase noise走的，这毫无疑问。但在数字电路里，大家其实关心的是period jitter。而时钟分频对于jitter的影响，三种jitter又不是完全一致。所以我时常碰到其他人问我，我们的jitter是多少？在原来刚开始搞pll时我也是就随口报一下测试数据。等我明白了之后，我就会问，你关心哪种jitter？大多数情况下对方也不知道自己关心哪种jitter，很多时候也是看别人要求jitter是多少多少。这时候就得帮对方分析到底需要哪种jitter。所以如果有一天有人问你，你做的pll jitter是多少，你就可以看出来他对jitter到底了解的够还是不够。
在数量上，其实也大有学问。前面已经说了，jitter是个随机变量，所以怎么描述它的大小也是一个问题。有时候这个变量接近高斯分布，随着测量时间的延长，范围会越变越大，所以如果用峰峰值，就必须严格给出测量的时间，否则结果是发散的，且无法对比的。这时候更多的是给出rms值，这个值相对稳定可靠。有时候这个变量是由于干扰造成的，所以不会发散，这时候给出峰峰值才是比较合适的。
定义就先说到这，以后再继续说一些常见的问题，比如jitter和adc的噪声如何挂钩，频谱分析仪的phase noise如何和phase jitter 挂钩，三种jitter又如何联系，n 周期的jitter测量结果如何变化，实际jitter的测量等等，看起来jitter这里面要讨论的内容还是非常多的。（最近看martin那边教材第二版，发现他已经将jitter的定义补充进去了） 
反馈与稳定性（一）
反馈，在生活中无处不在。在电路里就更不用说了。没有了反馈，我们分析电路就容易的多了，可是我们能实现的也就少的很了。
反馈我觉得是学习模电中最重要的一个概念。一般我拿到手一个系统，或者电路，首先干的事情就是看看里面的信号反馈通路，如果能把它清晰的分解出来，那么对这个系统的理解就可以完成百分之七八十了。
要讨论反馈，也得先给他分分类。（说句题外话，分类的好处远大于我们一般的理解。）反馈本身有正负之分。正反馈一般讨论的比较少，但是正反馈也有一些明显的用途。负反馈是最常见的，也是讨论最详细的。下面我也根据实际中碰到的一些情况来讨论一下。而稳定性就像是负反馈的子女，与负反馈形影不离，所以也会在下面讨论一下。
先说说正反馈。正反馈的用途挺多。根据环路增益来说，如果大于1，就不稳定，形成latch。latch大家应该都用过。如果没有用过latch，那正反馈型的比较器呢？正反馈型的比较器有个特定，增益无穷大，所以只要给足够的时间就可以达到无限的精度，另一方面，它的输出是指数形式的，结合preamp，可以得到高速的比较器。这个是不是也不错？在比较器设计中碰到的迟滞也是由正反馈引起的，所以一般来说有迟滞就可以看到正反馈。如果环路增益小于1，那就是一个稳定的系统，我们之前在bandgap的设计中也见到过这种形式。除此之外，根据A/(1+A*beta)，还可以得出结论，当A*beta大于-1（此时A为负值）时，增益可以提高，这个在某些时候也会用到。
{对于正反馈，有个问题就是A/(1+A*beta)这个公式是否成立。因为对于环路增益大于1的正反馈，明显是无穷大输出，但根据公式却会得到一个常数。我的理解是如果用无穷级数求和方法去推导公式，那么这个级数是发散的，而我们却偷偷用了能收敛的条件。这种理解方式也许能说服一些人，不过我觉得还是有些不严格，因为实际上无穷求和只是我们对负反馈形象的一种理解。（在这个地方我又想了一下，觉得前面的理解应该是有问题的。首先，在理论上，如果增益为恒大于1，相位不变，是否一定会输出无穷大，存疑，我认为不是。其次，当环路引入延迟，那么就是之前说的那种级数发散，但是相应的公式中也不能用常数，带入实际环路T之后用公式仍然是成立的。再者，到底在DC相位如何会导致正反馈，我认为其实但看DC一点是不够的，需要看DC的邻域。这个问题在pll的理论中我一直没想通，现在看来是可以说服自己了。）}
对于上面一段，时隔一年，自己又有了新的体会，在概念上修正了自己的一些理解，同时对于一些传统的观点也有了自己的认识，觉得值得在这里写出来告诉大家。之前对正反馈的理解，一个疑问就是A/(1+A*beta)是否成立？因为假设A为常数，会得到一个固定的值，这与正反馈不稳定的概念格格不入。我不知道其他人是否专门为这个问题仿真看看，至少我前两天为此专门做行为级仿真看了看，结论是这个公式成立。如果这个公式成立，那新的问题就是系统难道是稳定的？我的结论是：稳定！有人会说，你这不是公开与教科书为敌吗？我们不是一直学的都是正反馈增益大于1则不稳定，只有小于1才稳定。我从毕业这么多年，也是一直这样理解的，但是总有几个问题绕不过去，一个就是刚才说的，那个A/(1+A*beta)是否成立，从这个公式里如何理解稳定性，另一个就是前一段自己给自己提出的问题：如何将稳定性与那个无穷级数求和的解释统一起来，以及如何解释pll的初始相位。刚才解答了第一个 问题，那接着就得说，用无穷级数求和解释稳定性，属于用一个不严格的形象式回答错误的解释了一个严格的数学问题。换句话说，无穷级数的回答，是错误的，它与正反馈的稳定性有一定的关系，但严格来说，是偷换了概念。一个正反馈即使增益大于1，也是可以稳定的。第三个pll的问题，如果沿着正确的理论走，那就是显而易见的了。
在这里，就将这个问题背后的理论理顺归纳一下。首先，A/(1+A*beta)是从数学公式推导出来的，在正反馈时，前提没变，形式没变，因此这个公式依然成立，如果搭一个行为级电路，放大器有一个固定的增益，他的确可以稳定在这个公式的计算结果上。所以用等比数列求和去解释稳定性，就错了。正反馈的稳定性仍然可以用最基本的理论去推导，那就是闭环传输函数中不能有右极点。根据这个，可以进一步推论，如果这个放大器有一个极点，那必然不稳定。形象的想，放大器的输出总有那么一点延迟，那就不稳定了，但没了这个延迟，就是稳定的。所以用等比数列解释，其实隐含着每次求和总是有延迟的这个前提。这个解释固然能说明很多实际情况，但在基本概念上却是错的。对pll的问题，那显然了，虽然dc时貌似是正反馈，但那又如何？谁规定了这样不行呢？
在实践中，不可能存在没有一点延迟的正反馈，因此如果我们看实践中的电路，正反馈的稳定性基本可以由增益大小去判断。但是这也不意味着我们就可以这样去理解正反馈的稳定性问题。现在新的问题就是正反馈除了像pll那样在dc两个极点，可以通过一个零点调整成稳定的，其他类型的都无法调整成稳定的吗？算下来似乎得正极点才可以，但是电路中如何能实现呢？另一个问题就是乃奎斯特判据在这里如何应用呢？
对于负反馈，搞电路的人为了对付它，搞出了很多方法。最基本的一种就是把电路系统分成了A和beta。我个人理解这种做法只不过是由于以前分立opa设计中使用方便，从问题的本质上说，单稳定性而言是不应该区分A和beta的。我平时会关注更详细的几个要素：基准（一般就是输入，也是需要达到的目标），误差产生（就是框图中的求和单元），放大与执行（就是把A，beta和在一起看）。一般对于系统，找到这三个模块就等于找到了一个反馈回路。
虽然系统框图分析起来很简单，但在实际电路中就没有这么容易了，因为实际电路前后级会互相影响。根据电路的特点，人们又根据输入输出的情况把反馈分成了四大类。假如把运放当成理想的，那这四大类基本就可以用于分析了。可是有时这么分析还不够严格，所以在这四大类的基础上又进行了修正，让负载效应也正式被计算在内。可是这也不是最终的结果，因为除了负载效应，这个模型中忽略了一些网络的前向增益和后向增益。要是前向和后向增益也加进去，那么我们一定能得到最可靠的结果，不过这时候也和直接求解没什么区别了。所以，反馈的模型实际是对最精确模型进行一定的修剪，在精确度和简便性上做出的最好的tradeoff。
除了这四大类模型，gray书上还给了另一种反馈分析的模型return ratio。不过这和工具一样，很多时候用哪种不但看哪种好用，还要看哪种用的熟练。（我回去后又仔细看了这部分内容，看起来方法也很简单）
刚刚在论坛上看到一个之前的讨论，问某个电路是四种反馈中的哪种。我觉得想法很好，但是问的方式有待商榷。随便拿出来一个带反馈的电路，如果不说明输入输出，其实无所谓四种反馈中的哪种，因为同一个电路从不同的角度去看，可以得到不同的结论。因此我有一个进一步的推断：虽然从不同角度去看，反馈种类可以不同，但环路增益A*beta=T却应该是不变的，换句话说，T是一个更为恒定的量。这个推断我没有办法证明（呵呵，一翻书，我才想起来其实n年前我给其他人定性的证明过，用的就是信号与系统里的内容，只是自己记不住了），但是验证了一些结构，说明还是不错的，所以如果不是为了输入输出的一些特性，没有必要硬套四种反馈模型。另外，在稳定性的考虑中，也是T起决定性作用，而不是A。 
反馈与稳定性（二）
去年我们说到反馈的一些特性。现在说说稳定性。
稳定性在实践中其实是和反馈密不可分的。一个开环使用的东西，讨论稳定性是没有意义的。所以不需要讨论什么比较器的稳定性问题。从信号与系统的角度说，稳定性就是问：“当一个开环系统变成闭环后，它的极点位于哪里，是左平面还是右平面（或者虚轴）？”。在这个问题上，我觉得模电的很多书讲的都有些含糊，有时试图用直观去代替严格的理论，但是不幸的是很多时候造成的麻烦比好处更多。
先解答第一个问题，为什么本来要研究闭环系统特性，却偏偏要在开环的传输函数中讨论？一个可能的原因是简单有效。因为人们通过这个途径找到了简便的判断依据。如果直接讨论闭环，不是不行，信号与系统书上给了判决方法，但这种方法只能判断一个严格给出闭环传输函数的系统是否稳定，却说不出如果系数有微小变化时会怎样，所以在实电路设计实践中几乎不可用。而pll的设计书籍中很多直接在闭环函数中讨论系统的稳定性。有的opa的设计，也是直接在闭合函数中讨论。在这些方法中，大多是把系统拆成了二阶多项式的乘积，然后讨论Q。通过Q讨论稳定，或者瞬态特性。但这种方法毕竟不能对高阶的传输函数起作用。所以实际设计中，更多的还是直接在开环传输函数中讨论，因为我们有奈奎斯特判据。
奈奎斯特判据的含义大家可以找找资料。其实就是在画开环函数的图形，然后数包围（-1，0）的圈数。从wiki中得知，奈奎斯特判据的数学基础是复变函数，就等于将开环传输函数与闭环极点数目关联了起来。从理论上来说，这是最重要的判断依据。在此基础上，才有了个phase margin 和gain margin的概念。但是我觉得所有的模电课都应该在一开始就强调pm和gm的不完备性，换句话说，这两个东西并不是一定有效。但是现实中把这两个判据当成稳定的充分且必要判据的人比比皆是。所以误区1就是：pm没问题，就一定是稳定的。误区2就是pm，gm有问题，系统就不稳定了。（这里还只是讨论理论上的东西，还不涉及AC和tran的区别）
模电书上讲的很多的一个例子就是一个频率为f的sin波，绕环路一圈，到达相加节点后相位变为了-180度，然后说正反馈了，不稳定了。特别是在设计振荡器时，又有一个巴特豪斯判据，更加强化了这个概念。然而众多的基础问题就出在这里。是不是当增益大于1，相位低于-180，系统就不稳定了？这又如何解释pll的起始相位是-180？如果当增益未下降到0db时，相位低于-180之后又升了起来，是不是就不稳定了？我想模拟书上给大家个了一个直观的感受，却带来了一系列的问题。这有些像高中物理课本，没有强调惯性系和非惯性系，当年也给我造成了很大的困惑。
对于上面的一些问题，说说我自己的一些理解和结论。首先要推翻的一个结论就是当增益大于1，相位低于-180时，就会震荡。因为根据奈奎斯特定律，只有包围了-1，才会震荡，因此完全可以构造出满足前面条件的不震荡系统。同样的，对于pll，也不应该说什么震荡的问题（pll的曲线在dc点的增益裕度严重不对）。
解释了一个问题，会带来更多的问题。可能有人马上会问，那么巴特豪斯判据呢？这是good question。我想巴特豪斯的严格版本应该是增益为1，相位为-180.这是我们不用太多数学，马上可以算出，闭环系统有极点在虚轴上，这必然是等幅震荡。而巴特豪斯的工程版本则要求增益大于1，我们要注意到此时系统已经变成实际系统了，必须有一定的非线性使得等效增益降到1，才能真正震荡起来。
在另一个角度上看，系统振荡与否，取决于闭环的极点是否在右平面或者虚轴。而bode图实际是开环系统传输函数在虚轴上的取值。所以仅当增益为1，相位-180时，可以很容易的推导出闭环的极点在虚轴上，其他的都没法直接推导出右平面的极点。
说了这么多，是不是就否认了bode图中pm和gm的意义呢？没有！。对于我们大多数常见的系统，这两个还是很有效的。而且稳定不代表不震荡，pm和gm同时还给了时域上衰减震荡的趋势。只是当我们平时遇到一些特殊系统时，碰到用pm和gm解释不了的问题时，就应该反过头来仔细想想，这两个数值背后的条件是什么。
另外，我们还必须把理想系统ac分析和实际系统的tran分析区分开。ac分析得到的bode图一般只是一个稳定的必要条件而不是充分条件，tran一般才是最后的真正判据。
再就是当tran分析没问题时，ac如果有问题，是否可以否认ac的结论？我想保险起见，一定不要轻易否认。在实践中我碰到过tran激励加的不对的，也碰到过ac信号加的不对的，甚至碰到过仿真工具莫名其妙不对的，即使前面说的都仔细检查过了，设计者也不要轻易说，一定没问题。 
反馈与稳定性（三）
龙年第一篇，按照原计划，仍然贡献给反馈与稳定性这个家伙。
兔年底讲了稳定判据里的一些问题。现在首先讨论的一个方向就是一个多环路系统如何判读稳定性。这个问题其实在模拟电路里时不时也会遇到，只是没有人系统的总结一下。上次在论坛上我也就这个回答了别人的几个问题。希望以后问这种问题的人越来越少。
如果抛开电路，直接说一个多环路系统的稳定性，我想还是要去信号与系统中找答案。信号与系统中虽然没有明说，但是在信号流图部分介绍了一个一般的系统如何直接写出传输函数，在状态空间部分也说明了一个一般的系统，不管输入输出在哪里，总有一个特征的多项式。我们知道稳定不稳定，就是问输入输出的传输函数有无右极点，而这就是问传输函数分母的特征（我们假定本身开环没有右极点）。再看一下一般的传输函数性质，就知道这个分母其实也是有规律可训的，是若干个环路函数的组合然后加1.当只有一个环路时，就退化成1+T。所以要是想类似单环路一样判断稳定性，那就是要找出这个环路函数的组合，然后给它做bode图，或者奈奎斯特图。可惜我大概想了想，就是没有想到一种方法，可以断开某点或者某些点，然后把这个环路函数的组合直接仿真/观察出来。所以我觉得应该是没有一种通用的方法去画bode图。
补充几点，首先这个环路函数的组合是什么样子？我想课本是最可靠的，叫做梅逊公式。它大概是T1+T2+T3+T11*T12+ T23*T34之类的样子。其次，输出输出点不同，是否对它有影响？这也是个好问题。不过课本上表达式也暗示了，不论是写传输函数，还是用状态空间法，输出输出点的选择不影响分母。这也是为什么之前说环路增益对一个系统来说更基本一些。
那么是不是所有的多环路系统都没法看bode图了？多想一步就会想到实际中的系统很多都是多环路的，只是被我们简化成单环路了，那岂不是单环路的结果不可靠？区分几种情况。一种是假如每个单独的环路都是稳定的系统就一定是稳定的（这有些像gain boost里的情况）。我忘了这个的出处，也许是cadence的帮助文件？不过这个要求似乎很强，反过来说，如果每个单独的环路都不稳定，系统不一定不稳定。另一种情况是多个环路有公共点。这样可以在公共点断开。举个例子，假设正向增益A，反向有beta1和beta2两个反馈路径并联。大家都很容易想出来，环路增益是A（beta1+beta2），但也可以看成是Abeta1和Abeta2两个环路（有人会说，谁会连这都看不出来，却要看成更加复杂的东西。实际情况是有时很多人真没看出来，放n年前我刚碰到这个问题的时候，我也没能一眼看出来。所以有时画小信号等效，简化系统是非常重要的，我们平时常说的一眼就看出来实际是自己对这个模式很熟悉后迅速简化的结果）。这种就可以在A的输出或者输入点断开，因为这点就是公共点。（如果断开的点不是公共点，而是在任意点断开呢？我最近推导的结果是环路增益将变化很大，但是如果只是考察是否稳定，不同点断开的意义是相同的。但如果还需要用相位裕度等参数去考虑瞬态响应，那就差别很大了。）
一个实际的例子就是两级miller差分opa，cmfb反馈到电流源，同时外部还有差模的电阻反馈。这样的话外部的电阻反馈同样构成了共模反馈，因此在哪里断对于仿真cmfb的bode图就很重要了。好在还可以证明（这个我真的证明了），当外部的共模反馈比较弱时，高频的bode图形状变化不大，因此pm，gm等结果基本可以使用。
讨论的第二个方向是关于稳定性的一些工具。先说说理论方面，除了bode图，root locus也很有趣。说有趣是因为可以很直观的看到极点的变化情况，看到零点对极点的影响，看到反馈对整个系统稳定性的影响。另外，我还在想，其实现在也完全可以直接画出奈奎斯特曲线（bode图是该曲线的另一种表示方式），不知道为什么很少有软件支持。对于一些复杂的，奇怪的bode图，也许这个曲线更有意思。不过我曾经让软件画过一次，似乎由于比例的关系，显示效果不好，这可能是个问题。
再说说实际电路仿真方面。要做出bode图，主要就是要找到一个断点。接下来，“直流连接，交流断开”。直流连接是为了保证电路的静态工作点正确，否则开环的时候由于有时增益很大，后几级的管子会离开饱和区，交流断开则是为了得到A*beta的结果。为了实现这个，不论是大的RC，或者LC，或者交流开关等等，都可以，没有谁比谁更好或者更差。再接下来，“考虑断开点的负载”，这是由于断开之后，断开点本身的负载就被分开了，导致电路与原来不一致。举个例子很明显：假如一个opa，然后接一个电阻分压反馈，中间抽头到opa负端。假如opa负端有个大电容，那么在beta上就会产生一个极点。但是如果在opa负端断开，电容被opa拿走，那么这个极点就消失了。所以传统的做法是要仔细选择断开点，最好还要根据实际情况，在断开点左右加入等效负载。准确的做法是在断开点做两次仿真，据说spectre里的stb就是用的这种算法。所以一般来说就选stb好了。对于差分电路，需要区分共模电路和差模电路。直接搭个半电路是不太可能的，所以需要在断开点选择是断开差模还是断开共模。cadence给的教程里一种是自己用理想变压器提取出信号的差模和共模，在需要的信号通路上接probe，然后再把差模与共模用理想变压器恢复。另一种是用cmdmprobe，算下来是一样的道理。 
稳定性讨论
在之前的文章里对稳定性做了一些讨论。在最后还留了一些尾巴没有定论。前一阵则感觉对之前遗留的问题有了更进一步的认识。
之前存疑的问题有几个，其中一个是：对于复杂的多环路系统，如何判断稳定性，当时没有想到好的方法，而只想到对具有公共节点的系统，可以在该节点断开环路。今天看来，这个结论似乎不完全准确。
首先需要一些预备知识。除了我们熟悉的传输函数，在信号与系统里还给出了状态变量法。从状态变量法可以知道，在任何一个系统中，任何两点之间的传输函数都存在唯一的一个多项式作为分母。因此用这个分母就可以作为判断系统稳定性的依据。这和传输函数中的环路增益其实是完全等效的。之前的难点就在于这个环路增益如何给出。纯用梅森公式没问题，但是对我们电路设计者来说没意义。最近的结论就是在这方面有所想法：如果在系统的任意一个位置断开并插入一个激励，那么可以知道输出就是A/(1+L)，而A=1，因此用这个方法就可以得到环路增益L。这与以前传统的单环路方法是完全一致的，因此这里的结论就只是说：以前的方法在现在仍然可以用，不用在意什么单环路多环路。
上面的结论看起来与我之前的一些结论矛盾，但再仔细思考下去就能发现一个更重要的问题。
之前之所以把多环路专门提出了，就是因为在多环路仿真中发现了一些特殊的现象：在不同位置断开对环路增益有影响。大家不妨自己构建一个多环路的系统去亲自计算一下。当构建好这个多环路系统后，不妨再算一算令分母为0的多项式，看看有什么特点。
在此可以提出一个新的结论：系统的稳定性与系统的稳定性表现是两个完全不同的概念。这是我现造的两个概念，目的是为了区分两件事：系统是否稳定（在闭环情况下是否有右极点），系统在闭环后受到激励的表现（是否有过冲，是否有长时间震荡等）。对第一件事情，只有唯一的一个判据，就是奈奎斯特判据。这就等效于观察上面让计算的分母为0的多项式。不同的环路增益有不同的曲线，但是他们有一个共同点，就是如果其中一个曲线能取-1的值，那么其他所有的曲线也必须能取到-1。对第二件事情，在正常情况下我们喜欢用phase margin之类的值来判断。但是不同的环路增益的PM是可以完全不同的，也不需要完全相同。你在一条曲线上看到90度，也许在另一个条曲线上就只能看到10度。
举个不太恰当的例子：系统的稳定性只是在问这个系统是生是死，这是这个系统的特征，而系统的稳定性表现是问这个系统是否健康，至于什么是健康，那就仁者见仁了。
因此对多环路系统，是可以在任意一点打开环路仿真稳定性，只要这个曲线的PM不为0度就可以下结论：这个系统是稳定的（这点似乎我还没有严格的证明，之前的想法有一个漏洞）。但是如果想考虑这个系统在时域的表现，那最好还是在各个点都打开环路检测一下。
另一个问题就是类似pll这样的系统，在DC上相位就为180度，从理论上说gain margin严重不对，为什么没人说它不稳定呢？同样一个类似的问题就是如果相位先下降再上升，那么是否稳定。其实这里问的都不完全是稳定性，而是稳定性表现。就这个问题，我也大概想了想，把思路放在这里。一个系统闭环后的时域表现，基本可以用Q值来反映。如果一个系统闭环传输函数中有一个地方增益格外的大，那么就说明它容易过冲或者震荡时间很长。而判断闭环增益，就可以用开环增益来看，这是一个矢量计算的简单过程。H=A/(1+L)。对pll这样的系统来说，在DC点可以算出来，H并没有异常增大。对普通系统来说，基本可以认为PM越小，闭环时在GBW处增益就异常增加的越多。一个简单的总结就是只有开环时增益接近1，相位接近180，闭环时就容易产生H的峰值。两个条件缺一不可。
附录：为了更详细的说明这个问题，给出一个实例
 
用上面一个典型的多环路图来说明。在V1和V2处断开，可以分别得到图中的公式。让我们先不要管什么bode图，奈奎斯特判据之类，先想想如果求V1到y的增益，求V2到y的增益，求x到y的增益，会是什么形式？很明显，在分母处一定是1/(1+L）的分母再乘以环路中某个增益的分母，并且注意到不同处断开求的的1/(1+L)的分母都是一样。的。我们求的增益是什么？是闭环传输函数。因此判断稳定性只需要看这个多项式对应的根是否在右半平面。这就和状态变量法中推导的结果一致：任何一个系统，从任何一点到另一点的传输函数，其分母都可以写成一个共同的（1+L）的形式。如果开环时没有右极点，我们也就只需要考虑（1+L）的零点就可以了。
为了考虑1/（1+L）的极点，我们可以使用复变函数里的结论，去观察L是如何绕（-1，0）这个点运动的，这也就是乃奎斯特定理的意义。从上面可以看出，两个不同的L都可以用来看，只要其中之一能保证无右平面极点，另一个也能保证。但是这两个的PM，GM等未必需要一样。换一个意思就是从V1，V2，X等点加阶跃冲击，在Y处的响应可能会过阻尼也可能会欠阻尼。

这个问题可能过于复杂，许多读者也未必有相应的知识储备，所以总结观点如下：
0.预备知识：一个系统稳定与否，只取决于闭环传输函数中是否有右极点。为了判断是否有右极点，则需要用开环的环路增益（单环路情况）卷绕 -1的次数判断。对多环路，也有一个特征多项式，其地位与环路增益相同。
1. 一个多环路系统，在任何一点打开后给出一个非传统意义的环路增益，打开点的位置会影响该环路增益的形状。
2.但是该环路增益的形状尽管发生变化，由于闭环后是否有右极点是不变的，因此该环路增益卷绕-1的次数不变，因此可以用该环路增益判断是否稳定。
3.但在实际中，我们除了关心是否稳定，还关心在稳定情况下的时域表现。一般而言，可以用相位裕度来估计该时域表现。在不同点打开的环路增益的相位裕度是不同的

这个问题可能过于复杂，许多读者也未必有相应的知识储备，所以总结观点如下：
0.预备知识：一个系统稳定与否，只取决于闭环传输函数中是否有右极点。为了判断是否有右极点，则需要用开环的环路增益（单环路情况）卷绕 -1的次数判断。对多环路，也有一个特征多项式，其地位与环路增益相同。
1. 一个多环路系统，在任何一点打开后给出一个非传统意义的环路增益，打开点的位置会影响该环路增益的形状。
2.但是该环路增益的形状尽管发生变化，由于闭环后是否有右极点是不变的，因此该环路增益卷绕-1的次数不变，因此可以用该环路增益判断是否稳定。
3.但在实际中，我们除了关心是否稳定，还关心在稳定情况下的时域表现。一般而言，可以用相位裕度来估计该时域表现。在不同点打开的环路增益的相位裕度是不同的。
4.在实践仿真中可以这么做， 在仿真中断开环路，可以仿真得到开环的环路增益L。
stb或者ac仿真给出的是开环增益，就是L。不同点断开，其L也是有差异的，请看图中公式的左半部分。但是闭环增益是A/(1+L)的形式，闭环增益的极点就是1+L的零点，因此令1+L=0求零点，可以看出不同L对应的方程是一样的，因此必然会有同样的零点。根据复变函数的定理，其L卷绕-1点的圈数是相同的（注意此处推导可能有个漏洞，并不严谨，需要以后分情况补上讨论）。所以说不同处开环得到不同L，其稳定性是相同的。稳定性怎么看？用相位裕度是否大于0来判断，或者更严格的，用卷绕-1的次数判断。


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
关于这个多环路稳定性问题,放几个参考文献在这里. 
1. Trans on power electronics "measurement of loop gain with the digital modulator" Jan 1986。 它认为要在环路公共点断开测量环路增益。
2. Trans on power electronics "topics in multiple-loop regulators and current-mode programming" Apr 1987。它认为不需要在公共点断开，而是可以在环路中任何一点断开。但是前提是小环路是稳定的。我比较赞同这个观点，和我的推断是类似的。
3. Trans on circuits and systems II " Determination of stability using return ratios in balanced fully differential feedback circuits" Dec 1995.它引用其他文献的结论，认为需要在不同点打开环路去衡量稳定性。但是它认为在某些情况下可以用一个单一的环路去评价，那就是在公共节点断开。我没有看它引用的文献。
4. Trans on education " a comparison of two approachs to feedback circuit analysis" Aug 1992. 这个和多环路没有关系，是讲return ration and loopgain的区别。放在这里是因为我blog里其实一直是按照信号流图来思考。但实际电路中不太可能是理想的信号流图那样结构。因此这之间还是有差异的。这个差异影响有多大，如何修正从信号流图来的结论，目前还没有思考过。
5. Trans on circuits and system I "signal flow graph in loop gain analysis of dc-dc pwm ccm switching converters" Jun 1998.这里认为多环路中存在不同定义的环路增益,但是它认为只有其中一种是对的,那么对应只有在某些特殊点断开才是有意义的.对此我认为它忽略了一种情况,就是不同的分母形式可以有相同的零点.
由此可见，不同人不同来源对这个多环路问题仍然有不同的看法。但是就目前我的推导来看，至少在信号流图上，如果内部小环路不存在稳定性问题，是可以在任意点断开看稳定性的。但是我们用环路增益不仅仅是为了看稳定性，所以不同点断开的细节是不同的。


 
反馈观点看opa（一）
最近的一期jssc上有一篇讲opa/ldo设计的文章，里面提到用局部负反馈的观点看miller电容，我很感兴趣。
这个观点其实并不算很新颖，几年前hujising小组在做nested opa时，就是用这个观点来给出设计方法的，只是没有明说而已，我是猜了一段时间才明白他们的思路，就是从最内层开始，逐层看作一个小运放设计。看jssc上新文章时，从他的参考文献又跑到wiki上，又意外发现原来这方法据说是控制理论里的一种经典做法，这样就总算给它给了一个理论依据。
除此之外，早年还有一个做nested opa的文章，专门提到nested opa可以降低运放的谐波，用的解释方法也仍然是把输出级放在环路最内部去分析。当时看的时候也是想了一段时间才明白他的思路。
这个方法说起来也很简单，就是把通常miller opa的第二级看作一个小放大器，那么miller 电容就是这个放大器的反馈电容，这个小放大器就工作在负反馈状态下，自然他的带宽就是他的gbw，这就解释了miller电容对次级点的拓展作用。在这个观点下看，pole split就是root locus中反馈导致极点变动的同义词。
这个方法虽然看着比较强大，但是如何使用，我仍然存有困惑。首先，我们通常分析miller opa稳定性，都是在最后输出断开环路。从理论上说，等于只断开了外围的环路。严格的说，应该是断开两个环路的公共点才对。从理论上说，两个还是稍有区别的，只是如果是一个管子，差别理论上不会很大。那么我们是否应该用更严格的断环路方法呢？假如一个补偿形式很复杂的运放，理论上我们传统的断环路方式就会出问题。其次，这个方法解释miller opa很方便，如何扩展呢？比如cascode miller opa，那个cascode级如何表示呢？有的将其也建模成一个放大级，但是越是简单的单管，反而里面带的东西太多，为什么可以那样简化，为什么有的参数可以被忽略，在没找到一个统一原则前，我只好认为这是case by case的方法。我刚开始接触模拟电路的时候，就看到的是一个cascode miller opa的分析，当时文章还是直接计算得出的结果，最后的形式其实是三阶，被拆成了1阶加2阶，物理意义一点也不明显，也不容易记忆，但毕竟这是一个准确的结果。在另一个论文里，又是类似pll的分析一样，直接闭环去算传输函数，物理意义也不明显。如果可以用一个统一的原则将cascode级简化成另一级放大，自然是设计者的福音。但是这种方法也必须得告诉我们，简化时前提是什么。同时鉴于原始的计算方法里该级是一个2阶形式，如果这种方法不能给出同样类似的信息，而只能给出一个一阶的形式，那意义就小了很多。
不管怎么说，这种方法毕竟将opa化简成了我们平时熟悉的信号流形式，还是方便了一些内容的记忆。也许以后的教科书会用这种观点去直接分析运放也未尝不可。 
反馈观点看OPA（二）
上文中说用负反馈的观点看opa，有很多优点，但是似乎没法总结成一个系统的方法。这几天似乎又有所心得，先大概写一点。
首先说在dc情况下，不考虑电容，输出电阻也几乎不考虑。这时候主要是考虑cascode管的作用。如果我们在这级把分析变量从电压变为电流，就容易理解多了。这级就变成了增益为一的电流放大级。用这个方法，就很容易把运放用信号流图画出来，有了信号流图，分析反馈什么的就轻而易举了。
在ac情况下，就有些复杂了，因为即使用电流做变量，一旦考虑电容电阻，就变得没法分析了。在这点上我想出一种比较通用的方法，就是用miller定理，把所有跨接在两个节点上的器件变为两个节点对地的器件，这样就把所有的状态变量都变成了电压，各个节点现在就被完全拆分成了传输函数串联关系和反馈关系。这时就可以考虑信号流了。
这事说起来容易做起来麻烦，顶多是说概念上显得清楚了，但是从实质上来说，和直接推导传输函数完全一致，没有节省任何工作量。
先说好处，这种方法在原则上可以明确看出系统级零点的来历，比如在miller cascode opa中可以推出cascode级处是有一个前馈的，也避免了我们讨论问题时纠缠不清的一些情况，比如该处有个电容，是否构成极点，如果构成，又该和哪个电阻去拼（http://bbs.eetop.cn/viewthread.php?tid=384257&extra=page%3D7%26amp%3Borderby%3Ddateline里就是这种情况，感觉大家不停的在说，但由于缺乏数学上的严格性，就有些跟着感觉走的意思）。再说缺点，从数学上说，这个方法和原来的工作量是一致的。回忆电路分析里的内容，任何一个双端口电路，都可以拆分成前馈和反馈两部分，我们这里只不过是把这个过程明确化了。另一点，当所有节点都需要这样做时，就变成了许许多多的局部反馈，在每个负反馈处原则上可能简化分析，但高增益并不是处处都有的，因此可能对局部反馈的分析仍然很复杂，最后还是等效于求解传输函数。所以这个方法其实只在几种简单运放这儿似乎好用些。但这几种运放又已经被大家用各种方法分析的很透彻了。
举个例子：一个miller cascode opa
  ，
如果只看dc下，可以简化为
 ，
如果用等效电路方法可以给出信号流图。如果需要考虑ac情况，做更复杂的小信号分析可以得到
 ，
这个信号流虽然可以看出前馈反馈，但实际分析起来也很麻烦，倒是可以大概的看出补偿电容cc的反馈作用。需要注意的是上面的分析中还忽略了许多电阻电容，如果添加上去，会有更多的极零点出现，更进一步增加了分析的难度。 
多级OPA的补偿
前一阵关注了一下多级opa的补偿，才发现这个领域真是很恐怖。平时我们做两级opa，无非就是miller补偿最常用，大不了加个电阻，或者做成cascode miller，偶尔有其他结构。但是到了三级运放，大家都是跟着miller概念来的，但是排列组合之后的实现让人眼花缭乱。有好几个文章做了综述，不过还是让我看的头晕。最主要的问题是pz在哪里。一般的分析，都可以给出主极点或者运气好还能看出次主极点，但要认真些，想知道极点零点，似乎不通过运算，近似，是不太容易的。由于内部负反馈的效果以及设计思想的变化，往往使得pz不像传统的都是在实轴，而是形成复极点以提高带宽，这就进一步增加了分析的难度。  
信号流图与电路框图
信号流图是信号处理里一种简洁的方法，可以清楚的把系统表示出来。电路框图，特别是双端口网络的抽象，也是一种电路系统的简洁表示方法。
不过电路设计者并不是总有那么好的运气把电路框图直接转成信号流图。
为什么我们要转成信号流图？有了信号流图，我们分析反馈就方便多了，可以一眼看出环路增益，可以一眼看出多环路，还可以迅速的写出传输函数，这些都是信号与系统课程中交给我们的方法。
但是电路框图与信号流图并不完全等价，所以电路设计者经常在bbs上问，谁能帮我分析一下这个电路结构？这个结构该在哪里去打开环路？负载该怎么等效？等等。
有时候电路框图还是很容易转成信号流图的，特别是当有理想运放存在时。但是为什么电路框图不是总能转成信号流图呢？我们看看双端口网络就知道了。一个双端口网络在输入输出总是有四个参数，而信号流图却只有一个输入，一个输出。一个双端口网络其实是双向的，而信号流图里一个支路只代表一个方向。
所以大家喜欢运放，因为它基本可以认为是个单向器件，而且它不抽取电流（理想情况）。而即使是一个简单的电阻，都无法直接把它变换成一个信号流图中的支路。所以我们才需要不停的近似，尽可能的把双向效应去除，尽可能让v和i其中只有一个起代表作用。仔细阅读并推导一下gray书中讲反馈那部分的内容，就可以知道在其中我们做了多少近似。在信号与系统中反馈就是一个A和一个beta，而在电路设计者这里就变成了四种反馈形式，同时还得记住反馈网络对放大器的负载效应。
类似的，由于信号流图与电路框图的差异，导致了我们之前讨论反馈时的种种结论在真正应用到电路一级时，仍然有很多基础问题需要解决，比如后一级的负载如何被前一级看到。


 
传输函数的符号化运算
经常有人问，有没有能直接推导出符号化的传输函数？要不然手工推导太麻烦，还容易出错。我就找到了一个。matlab网站上有个scam的程序，可以干这件事。我去那个网站下下来程序，结合他的说明仔细看了一遍，大有收获。原理很简单，应该有不少人大学时上iccad课，老师让编写过spice like的程序，就是读网表，然后填矩阵，之后矩阵分解法或者迭代法求解矩阵方程。这里是同样的工作，只是需要借用matlab的符号运算功能去求解符号形式的矩阵方程。(网址http://www.swarthmore.edu/NatSci/echeeve1/Ref/mna/MNA6.html，原理介绍http://www.swarthmore.edu/NatSci/echeeve1/Ref/mna/MNA1.html）
不过原来的程序并不完善，有一些诸如压控电流源之类的没做进去（这可是mos里的基本模块），所以要想使用，还是需要自己改改的。另外还可以做进一步的改进，比如可以直接读mos，然后在里面自己把它分解成若干电容和gm，ro的组合。再比如可以让符号和数值同时存在，在最后给出符号解和数值解，做一下对比。
使用这个软件还是很有意思的，太复杂的东西它也能给算出来，而如果对于手工分析，可能东西一多就容易出错了。这也是电脑的长处所在。
不过要是电路太复杂了，比如阶数大于3阶，这时候要想理解结果也很困难，因为我们通常都愿意得到一个比较简单的结论，好记也好理解，但是如果有复极点，或者doublet之类，就很容易把我们绕晕了。我拿这个程序最复杂的是分析gain boost opa的小信号模型。可以考虑不同的情况，比如上面的负载也是gainboost，或者在小运放输出存在一个对地cap，或者只有cgs，等等，到最后公式逐渐变得复杂，想努力解释极零点是怎么产生的也开始困难了（不过这拿去发文章，估计有人会喜欢）。
所以对这个程序，我最想做的改动就是智能分析与简化最终结果，比如对最后的公式，用数值替代后，看看哪些项是可以忽略的，再看看是不是满足什么极点分离的原则，可以搞出两个很远的极点，再或者可以看出来有doublet。可惜我对matlab的用法还不是太熟，一直没能写出这样的程序。
不过程序再厉害，还是需要有人来写。而且分析的结果未必合人的口味。这点我很佩服那篇gainboost运放的经典文章作者，里面也没太多小信号分析，但是给出的结论却是设计中常用的。换句话说，那个作者"智能”的在分析过程中就知道哪些可以忽略哪些不能忽略，哪些是主要的。这种方法是小信号分析所给不出的。
说到这里，需要补充一下，离开学校后对我印象最深的文章应该是那个运放稳定性的系列文章(原文最早出于www.en-genius.net，但目前只能找到一部分，在电子工程专辑网站有翻译版，在各处往往被称作TI工程师写的运放稳定性系列。奇怪的是作者可能原计划写15篇，最后只有十篇面世，而且从最后一篇看，作者已经不在TI工作了）。主要是它的分析方法，强调用图直观的观察而不是推导，这是和学校完全不同的。我刚开始在学校读那篇gainboost设计的文章时，一直不是很理解他的一些推导过程，于是又自己推导了一遍。后来读了运放稳定性的文章之后，才理解了这种方法。回过头去再看gain boost设计的文章，就好理解多了。两种方法殊途同归，但是图解法要直观而且简单多了。可是只用图解法，我又总是担心自己会犯错（这不是不可能，其实图解法里用了大量的近似，那些近似什么时候有效，有时真的会搞错），所以我的结论是图解法用于理解原理最好，数学分析用于严格定量最好。 
电学噪声
这里强调一下，是电学噪声。因为噪声的广义概念，就是一切非信号，包括了干扰。而这里说电学噪声，主要是指电路内部本征的噪声，这种东西除非你降低温度到绝对零度（不可能），否则一直存在。而干扰，则可以在理论上通过加屏蔽去除，量化噪声也可以通过更精细的量化减小。
对于电学噪声，课本上专门有一章讲。如果不深入考虑，那课本上讲的就足够工程师平时使用了。因为对于噪声，无非那么几个概念：噪声源是什么，有多大，通过线性时不变网络后如何计算。再深入一些，就是计算时如何考虑噪声的相关性，噪声带宽如何理解，等效输入噪声和输出噪声如何理解。（我想起我以前做课题时一直在想的一个问题，不知有人能否解答：对于成像系统，一般考虑接收二极管上有shot noise，其机制是载流子通过势垒时的随机性。但在一些论文中还看到，光子本身也有光子噪声，其表达式与shot noise很接近。那么电路里接收到的电信号噪声是两者功率和还是只有一个？这实际是说这两个噪声的物理机制是否具有相关性。由于不是搞光学，而且一般这种噪声都不在总噪声中占主导，因此我也只是想了想，没有结论，也没有找相关论文）。
但是由于现在讨论的电路不仅仅是线性时不变的，例如开关电容电路。因此目前课本里讨论的那些噪声理论就显得太单薄。而要更深入讨论噪声，一些基本理论又是绕不过去的，所以很是麻烦。下面就结合我自己的理解讲讲这个问题。
单纯的开关电容电路其实还算简单。作为近似求解，而不考虑线性周期时变的理论，用传统的方法就可以解释基本所有问题。和线性时不变电路最大的不同，开关电容电路存在采样过程。采样对信号的影响比较简单，就是引入了混叠。那么对噪声来说也是一样的。这就是为什么开关电容分析里一提到噪声，就先算一个RC电路，然后求噪声积分，得到kt/C，高兴的通知大家，看电容上噪声是kt/C。学生们也就兴高采烈的记住了，碰到一个电容就用kt/C。这样好记是好记，但是假如一个C两个开关，交替切换，该是多少呢？两个c两个开关交替呢？之前就有人在论坛上问过这类问题。当时我给了答案，但是没给太具体过程，所以似乎没太大说服力。这里我具体说明一下原理。
首先看采样过程，采样对信号是混叠的过程，对噪声也一样。所以带外的噪声全部进入带内。而对于采样，只有一个fs的频谱需要考虑（具体可见信号系统之类的书），所以总噪声一种算法是在采样后的一个fs中积分，另一种算法是在采样前对所有频带积分，两种必然是一样的。注意这里是说采样，而不是采样保持。所以这个噪声的含义就是如果我们去看c上的电压值，每个周期看一眼，就得到一个离散的序列，这个序列有自己的功率谱密度特性，有自己的离散特性。由于这个电压值也是和电荷值相关联的，而电荷守恒对噪声也是成立的（换句话说，一个电容放在那里，上面的电压是不会忽高忽低变化的），所以我们完全可以用离散域的传递函数继续计算这个噪声传递到后级的效果。（换句话，只有采样这个过程是特殊的，之后就不用考虑采样的效果）。
从这个过程分析的一个推论就是，电荷上什么时候有多大的噪声，取决于对这个电荷如何做采样（想一想sc电路中c接运放输入端那里什么时候做采样？大家可以看看Δ-sigma数据转换器那本书里是如何分析的）。
刚才的分析里强调了采样和采样保持。严格说这两个是有重大区别的，采样是把连续信号离散化，而采样保持是把连续信号接着连续化，所以其实等效于两个过程：采样，线性时不变系统。之所以强调这个，是因为如果你问一个电容上的噪声是多少，就得反问你，你是关心采样的噪声还是采样保持的噪声。前者已经说过了，是每个周期去看一眼，后者则是不停的去看。所以两者的算法是不同的。假如一个开关和c串联，开半个周期，关半个周期，而又关心采样保持的噪声，该如何去算？严格说这是一个时变过程，不过由于简单，也可以直接分成两个过程算，前半个过程是一个连续电路的算法，后半个过程是采样保持的算法，最后总噪声就是两个过程的总和（在temes的那本模拟信号处理里有具体的计算过程）。
总结一下，在sc电路里，作为近似算法，可以把系统拆成采样，采样后的离散信号处理，采样后的连续信号处理三个部分。一旦过了采样，就和传统的线性时不变系统处理方法完全一样。而采样，就是混叠的过程。这样就把这个系统转换为了我们熟悉的系统，而唯一要做的就是找出系统是在哪里采样。
但是除了sc电路，我们似乎没那么好的运气了，例如vco的噪声。所以又发展出了对线性周期时变系统的分析方法，那么线性周期时变电路的噪声，也应该用这个方法才对。从理论上来说，对sc电路用线性周期时变是最准确的，不过这样也就只有数值解了。从实践上来说，两种方法对sc电路应该得到差不多的结论才对。根据我以前的仿真结果，要完全匹配是不现实的，但是数量级是没问题的（要求似乎太低，看到80年代有文献做过实际测量与传统理论的对比，是可以基本对上的）。我用pss+pnoise，有时有感觉这种仿真过于敏感，以至于不敢相信是实际电路真的如此还是算法不够稳健（没敢做两个对比电路流片，否则可以就此搞个研究了）。
pss的原理就是既然电路是线性的，那么传统上线性时不变系统只需要一个不变的传递函数就可以描述，现在就只需要一个周期变化的传递函数。所以pss需要算出一个周期的所有静态工作点，而pnoise就利用所有的静态工作点去求解。pnoise与noise分析还有一个小区别，就是pnoise里可以自动做采样，针对vco电路，又可以区分噪声的各种成分，这和noise很单纯的一个分析是不同的。
现在一种新的仿真方法是tran noise。就是在瞬态仿真时加入噪声。这种与前面的仿真方法有本质的区别。我还从来没有在大规模仿真中用过这种方法，一个问题是会是单纯的tran仿真变慢，另一个问题是可信度还没有得到完全确认（我记得曾经用几个不同的工具做同样的tran noise仿真，结果区别很大，当然也不排除有的工具没有设置好）。 
谐波参数的设计
在模拟电路设计的各个参数里，我对谐波是最没有底的。首先，影响谐波的因素很多。针对不同的情况，需要区别不同的因素。对于opa这种，一般包括开环特性自身引入的，以及环路增益可以抑制的两部分。例如，如果opa自己带重负载很吃力，输出级的vgs很大才能提供足够的电路到输出，自然谐波特性比不上大输出级的。而前级增益越大自然也越容易在环路中通过反馈消除谐波。对于ota这种，则基本是开环特性。对于开关电容采样，则采样自身引入的谐波就与很多因素有关，例如开关的电阻是否与信号有关，采样的时刻是否与信号有关，采样时注入的电荷是否与信号有关等等。而针对da这种，又需要考虑在纯数字转到模拟时输出电阻，时序等等引入的谐波。针对不同的情况我们就需要了解谐波的来源才能做到有的放矢，因素很多，并且越是指标要求高，参与影响的因素就越多。很多在低指标下无关紧要的因素在高指标下就变成关键路径了。这些因素又是符合木桶定律的，即最短板的地方限制了系统的谐波特性。所以如果谐波不好，拼命提高其他参数无济于事。我印象最深的一件事就是有一次做带电阻负载的运放，谐波挺差只有50dB。当时找了一圈原因没找到，怀疑模型有问题，就把输出级加大。仿真看性能提升了不少，但实际测试只提升了一点。最后才发现是反馈点在版图中有轻微的寄生。虽然版图上只寄生了很小的电阻，但是由于负载和输出级本身电阻也不大，因此推算下来和实测很一致，最后也通过实验证实了这个怀疑。
其次，谐波本身是一个非线性的特性，因此各个因素之间存在耦合也并不奇怪。我以前有个推理，就是假设输出是理想的RC低通，那么如果采样也理想，那么理论上不会有任何问题，因为这可以等效为一个非常理想的线性电路。而线性电路是没有谐波存在的。但是这个推理在实践中是有很大问题的。这是由于推理过程中认为采样也很理想。如果采样有非线性的因素，而输出是低通，那么采样的非线性与理想的RC配合就会产生谐波。可能在设计中单独考虑各个因素都没问题了，但是当合起来之后就有了问题。或者在设计中没有任何问题，但在实际中却由于有没有考虑到的非理想因素导致新的问题。
最后，不得不说说数值方面的问题。前面的讨论也许都没有任何问题了，但是谐波是多少，仍然对这个没有任何的概念。顶多说应该不错或者应该有改善，但是具体数值，是很难事先掌握的。这是由于分析谐波时的思考方式与其他参数不同。其他很多参数都可以用线性电路的分析方法得出，有一套成熟技术。谐波必然是非线性过程的产物，而非线性过程是没有什么套路可用的。例如噪声虽然是随机过程，但是可以套用线性过程的计算方法，因此输入多少输出很容易计算出是多少，只是工作量的问题。谐波却不行。有人尝试做各种事先估计，例如用opa的增益变化来估计谐波，或者用简单的关系式代替具体的非线性关系来推算。不过这些方法的精度比我们对其他性能参数的估计能力差的多。所以瞬态仿真非常重要。但是仿真结果却非常的不靠谱。例如运放谐波与增益有密切关系，但是平时我们仿真的增益只要差不多精度就够了，因为我们几乎不用开环的增益做具体事情，都是用闭环的结果，所以增益仿真即使差20dB，从100变到80，我觉得几乎没有人测试或者注意到。但是对谐波测试就很明显的变化出现了。而增益的仿真也许也是不靠谱之一，因为IV曲线的拟合优先考虑曲线本身的误差，而增益却依赖于曲线的斜率。另外，谐波对数值计算的误差也非常敏感，选用不同的步长不同的简化算法，谐波几乎可以变化几十dB。因此必须学会区分数值计算带来的谐波和电路自身的谐波。EDA工具自己也尝试解决一些问题，例如spectre就有专门的分析用于谐波，比自己控制步长更可靠。不过很多时候还是不够用。谐波仿真依附于瞬态仿真，有时候速度过慢，每次结果不理想需要修改电路就很浪费时间。
有了这些限制，感觉谐波的设计定性多于定量，细节才是魔鬼，指标要求越高，对细节的要求对电路的理解就越重要。和其他参数的设计比，谐波优化更像绣花的精细活。 
ESD设计
ic里的esd设计算是一个偏门。在学校里很少有课程讲这方面内容。在公司里又很少有专人研究这个。所以esd相关的内容，一般都扔给analog design，layout，或者foundry。大家解决问题的办法也多数是连猜带蒙，有时候讨论起来也发现大家各自有各自的一套理论，有点鸡同鸭讲的感觉，那观点差异就大了（为什么呢？）。不像模拟电路设计，好歹一说稳定性，那就看看bode图吧。我这里的内容，也主要来自看的一些书籍（看书的理解不同，观点就不同），看的一些相关讨论及文档（看讨论也是各取所需，只看符合自己胃口的解释。看文档，我挺喜欢看foundry的文档，虽然不讲原理，但比较实用，如果能根据要求去反推原理，就感觉比单纯看书效果大），以及一些实验结果的理解（那就更是个人有个人的理解了）。所以大家也是各取所需，批判着看吧，有能提出自己论点和论据的更好。另外需要强调一点，esd是与工艺密切相关的，所以在有些工艺上成立的结论在另一个工艺上就不能那么绝对的接受，这是我个人的理解，但是我认为这个理解是没什么疑问的。
先从总体上说，esd我个人感觉应该包括esd器件设计，esd整体框架设计，内部电路针对esd的设计。
在最前面，其实应该提一下esd测试，包括hbm，mm，cdm等不同测试方法。所谓的hbm 2000v，很多人容易理解成内部电路要抗2000v电压，其实这个测试电路更像是一个电流源，如果芯片内部不能及时把1.33A电流（2000V/1500ohm)泄放，电压才会升上去，造成失效。
先说esd器件设计，这个似乎是很多书的重点内容，无非就是用diode，bip，scr去保护内部电路，这些器件的特性如何。对于diode，没什么好说的，无非一个正向导通，一个反向击穿，不过是利用正向导通还是反向击穿呢？我个人理解大多数是用正向导通特性，因为反向击穿电压似乎还是有些高。
对于bip（ggnmos，gcnmos等也是利用寄生bip），scr这种，属于有snapback特性的器件，参数就包括trig电压，hold电压，二次击穿电流（有的书上是vt1，vt2等）。按照大多数的书说法，trig电压的设计是保护并联器件不被击穿，hold电压是保证正常工作不发生latchup，二次击穿电流反映了承受电流能力的极限。不过一般电路设计者哪里有条件去测试这些呢？多数情况下还是希望知道一个定性的与layout的关系。可是似乎albert wang等人的书上就是对此不提。
我个人理解，trig其实就是bip的击穿电压（与掺杂浓度相关），它应该介于cb0和ce0之间，因为基区电阻大小是介于0和无穷大之间的。esd的版图里就有一项是考虑衬底接触的画法。我自己理解凡是方便esd的画法都是容易latchup的画法。比如esd cell的衬底接触就不要求多（似乎有design rule里特别强调了。但是我印象中若干年前的工艺里又是另一种要求，是工艺变化造成rul的改变，还是知识发展了，认为以前的做法不好，这是个疑问。为了这个blog，专门查了一下资料。我手上某年ker的一个ppt里提到，在0.35um工艺下给esd mos每个finger间都插入接地ptap，保证寄生bjt的基区电阻一致，从而开启一致。但我手上foundry的design rule里都明确禁止了这种做法。）。除此之外，gate电压也是一个控制参数，gcnmos就是利用这个原理去控制cell的开启。还有其他的一些做法，比如scr里给衬底注入等，不设计esd cell，我也就没关心那些奇怪的做法。这里顺带提一下，pmos似乎比较特殊，一般讨论esd都是讨论nmos，pmos似乎snapback特性不明显，抗esd能力很强（为什么呢？有人说是空穴迁移率低，有人说是beta值低，但这前后的逻辑关系是什么呢？），给人的感觉是不用怎么特意保护。
另一项hold电压我就不是太清楚如何控制了，从电学上就是饱和压降和ir drop。但是这个电压也很关键，要避免esd电路变成latchup电路，就全靠这个参数控制。而二次击穿电流应该就基本上直接与esd等级成正比了。二次击穿应该与有效的w/l有关，所以给drain加入镇流电阻是最简单有效的方法，或者就是把drain端距离拉大一些（更多时候需要加sab，阻挡其成为低阻）。这个办法几乎成了esd的代名词，很多时候电路里标follow esd rule，其实就只做了这一个工作。加了镇流电阻，就是希望各个finger之间均匀导通，最差情况也是一个finger在二次击穿之前就能达到trig电压，从而开启其他finger（这个镇流电阻按某文献说法，还有另一个作用就是强迫电流从衬底流动。衬底通路是寄生bjt，在esd时导通能力要强）。所以这里其实还有另一个esd rule，就是每个finger不能太长或者太短。但是加在source端行吗？至少很多实验结论是不行。foundry还提供esd注入一个选项。按一些文献的说法，这是为了降低esd mos的trig电压。但是工艺厂家不同，这个步骤的方法和目的是否一定相同？在不知道每个工艺厂家具体情况之前就轻易下结论是不可信的。就我看到的文档，是没有提这个步骤的详细过程，只是告诉用户，如果加了这层，可能会提高esd能力。 
接地二三事
接地是个不大不小的问题。我一直认为如果想解决这个问题，其实只需要最基本的电路知识，但是同时也需要对电路保持最大程度的理解，所以这个问题真是一个不大不小的问题。
地这个概念其实是最能让人迷惑的东西，因为它似乎是个奇点，所有的信号到那里就都结束了，自己却永远是0v。但是在实际中，经常有人爱说，嗯这里有噪声，是因为地上有噪声。其实我也爱用这个借口，因为电源有噪声似乎是可以避免的，但地上有噪声似乎就没法避免了。但是似乎这里有逻辑问题，地不就是0v吗，怎么会有噪声？
要解释这个问题，我习惯用海平面打比方。有了海平面，我们可以说珠穆朗玛峰是8848米。可以说北京海拔是10米，但是如果由于温室效应，海平面上升了怎么办？
所以可以看出，电路里的地其实并没有特别之处，其实就是被大家选作海平面的东西（注意，这里的地是信号地）。而对单端信号，其实隐含的一个信号就是它所对应的地。而单端信号互相传递，其实也依赖于各自地的传递。这里就不具体展开讲了，留作下次具体论述。这里就是讲讲实际中遇到的几件和接地有关的事情。
做audio设计，有单端和差分两种信号输入输出方式。从信号质量上讲，我们都喜欢差分，讨厌单端。其实主要还是因为单端信号的地很难处理。最简单的就是把两边的地连在一起。但是这也出现了许多问题。
首先是测试，信号源的信号接过来，能测出很好的质量。我一直就比较困惑这个问题，同样是单端信号，信号源是怎么处理这个问题的呢（我猜测信号线的地并不是仪器的地）。
当我们把设计好的芯片送给应用人员时，他们那里的抱怨接踵而来，芯片ADC接收到的信号不对，DAC输出的信号不对，等等。刚开始他们抱怨用ADC从声卡输入端接收信号时，出现有节奏的声音。我们反驳说，声卡本身就不是高质量的输出，不能期望有好的输出质量，换言之，也许本身音源就有问题，毕竟之前测出了好的质量是我们最大的底气。但应用人员也不甘心。他们继续反驳，如果他们用声卡自己播自己录，就没有问题。这下大老板也出面了，要我们解释，因为逻辑上的推理就是音源质量没问题。想了想，也只能做不同实验去验证。于是设计了一个实验就是两台电脑的声卡互相播和录，这一来也出现了问题。所以其实就是地的问题。自己播和录，用的是自己pcb上同样的地。而两个电脑互连，就是把两个地在输入线那里做了连接，虽然电阻不大，但仍然是有问题的。
之后在应用那里又碰到了奇怪的问题（不过由于上一次的解释，他们轻易不说芯片有问题了）。当我们的pcb一边连电脑声卡的输出，一边连一个调试器时，录到的信号又有问题。这次我们也没法一下子解决，只能实验。试到最后发现当调试器接到另一台电脑上时，一切都正常了。
我们的pcb是数模混合的，模拟和数字两边的地单点连接。但是模拟信号进来时，单端信号的地也是在接口处和我们的模拟地连接上。而数字信号进来时，地也是要和数字那边的地连接上。同样，电源信号进来时，电源的地也是连上了。所以如果在更高的系统级看，也许就谈不上单点接地。更主要的是根本不清楚电脑声卡那里地是如何处理的。所以这个问题一直困惑着我。从理论上来说，只要知道了所有pcb的走线方式，就可以像后仿真一样估算出问题的所在。但这个”知道所有“几个字可是困难重重，所以不知道大家是否有好的估计方法。
当最近研究了市电的连接之后发现，上面这个问题似乎还得向上延伸到市电的连接。因为所有的电源都离不开市电，而市电也有地这个说法，而这个地可是真正的大地。我们的信号地和这个大地是既有联系又有区别。从某些资料来看，这个大地也是导致各个pcb地产生差异的一个来源。而测试仪应该是考虑到了这些问题，所以在电路设计上有特别之处，才使得我们的测试能顺利进行，不受太多干扰。目前我手上的资料还没完全研究透彻，有的信息也不完整，例如测试仪的设计也看不到具体内容，所以这方面的信息目前还是以猜测和推断为主，希望什么时候能归纳出比较准确的信息和大家一起讨论。

补充：关于“地”这个概念。
严格来说，电子工程师和电力工程师说的地，以及大地是不同的。我们平时用的交流电有L线和N线的区别。L就是火线，N是零线。从普通意义上来说，N线是和大地等电位的（有个物理老师曾说以前农村只接火线，然后直接接地，灯泡也是能点亮的）。但是插头有的还有地线，这个地线在插座里按理是接大地的（注意，按理而已），在电器上则应该接机壳。这种设计可以保证当机壳不小心与火线连接后，机壳与大地等电位，防止人看到220V电压。这里的地，确确实实是大地。220V进入电器后，一般要被整流，整流后的电路也有一个地，这个地和大地的电位不一致，所以人碰到会触电。要想安全，得再通过变压器构成一个新的回路。在变压器的另一侧是个浮动的回路，因此那里的地电位与大地比，是不确定的，如果我们碰了这个地，由于没有回路，因此就是安全的。当然实践中，这个地和变压器另一侧的地dc不连接，ac是连接的。如果考虑触电，是不用担心，但是如果考虑噪声，就不一定能忽略。
一件有意思的事情是：当我用手去碰led灯时，有时候灯会亮，有时候不会。为什么会亮，似乎很多人都说不清。如果下次你碰到类似的事情，可以好好分析一下，我想那时对整个供电系统的理解会更清晰一些。
我们平时用的设备，许多都是用变压器隔离的，例如信号发生器。但比较奇怪的是示波器，它的地是与插头的地线等电位的。 
版图中衬底如何连接
这个问题在我们组内一直是个争论不休的问题，一种说法是要把模拟地和衬底各自走线，另一种说法是在局部合起来。前者的理论依据是需要给衬底一个相对安静的电位，后者的理论依据是衬底和gnd在局部构成局部地，反而没有衬偏引入的噪声。也就此问过其他人，有的人给的答案更夸张：需要一个独立的衬底在数字和模拟电路之间偏置guardring，然后在数字和模拟各个模块之间用局部的连接。
我个人认为在没有确切的依据之前，似乎没有什么道理认为一种比另一种更好。许多人支持某种做法，只是因为这种做法在以前的单位里是强制性标准，没有机会尝试另一种做法。许多人支持某种做法，只是因为某一次用另一种做法做出来的有问题，或者某一次用这种做法做出来的是成功的。我们组曾经在同一个芯片上用两种做法做了两个模块，结果性能都还不错（低频高snr电路）。所以我个人是没太大偏向的，至少是不偏执于某一种的。
要想知道这个问题的答案，最好的办法是同一个电路用两种做法同时做一个电路，比较测试结果。但这个结果还是无法推广的，只适合于这种特殊情况。为什么呢？请注意不同工艺的衬底电阻是不同的，有的可以看作高阻，有的可以看作低阻。电路的周围环境也可以是不同的，比如数字部分非常多或者数字部分非常少，对应着噪声情况大还是小，高频成分多还是低频成分多。甚至电路本身也可能是不同的，比如自己是pll还是opa。
所以这个问题至今为止，还是一个开放的答案 
对版图的一些想法
模拟电路设计者总是以自己能够做tradeoff而自豪。但是时间久了，我觉得有时候其实我们是拿这个打马虎眼。
举个例子，做版图时，mos版图该怎么画，电阻该怎么画，时常设计者都会说要在面积和性能中做tradeoff，但是具体tradeoff的边界在哪里，一到具体的数值就只好打马虎了。
这其实变为一个数学问题，有约束条件1：面积，不能大于多少多少，约束条件2：mismatch，不能大于多少多少，不同的实现等效于不同的函数，求这些函数的边界在哪里。但是这个函数是什么样子的？在没有具体数值的情况下，只知道它大致凹凸性，所以只好用tradeoff打马虎眼。这也怪不得我们，因为很多时候的确没数据。
但是也有厂商做的不错，给了数据，那就可以近似计算一下了。前一阵看某foundry给的mismatch数据，给出了mos如果简单abba放置，aabb放置两种情况下的数据。从这个数据可以看出，他采用的模型是ΔVth=A/sqrt(w*l)，其中A是从工艺数据中提取的斜率。数据曲线能很好的拟合成一条直线，说明这个模型比较切合实际。abba的A大概是10mV*um，换句话说1um*1um的mos管，失配的sigma是10mV，而abab的A大概是11mV，大了10%。换句话说，同样面积的mos管，不同画法mismatch的sigma差了10%。
有了数据就好说多了。如果我们要把offset的sigma控制在5mV（正常水平），L取1um，w就分别需要取4um和4.8um。如果同样用4um的w，sigma就分别为5mV和5.5mV。这只是一个普通的失配要求。换句话说，两个约束条件距离实际曲线都很远，所以怎么做都问题不大，考虑到复杂性，可能简单的aabb更好些。甚至我们需要考虑另一个问题：这两个A的可靠性如何，是否他们自身也有一定的随机性导致这两个A本身可能并不存在真正的差异。如果要做1mV以下的offset，又不想用特殊技巧，只想用工艺硬做，这时说明已经接近约束条件2的边界，此时不同的画法才有了较大的区别，有时变成非abba不可。这也就是模拟版图的艺术里说的，需要根据不同的失配要求来选择不同的画法。只是如果没有数据，多少是高精度，多少是中等精度就全靠感觉或者传闻。
当然了，上面的讨论只是针对上述工艺。具体问题还要具体分析。有的工艺节点可能比较敏感，有些时候做对称并不完全是为了mismatch。这里的讨论也只是一家之言。
 
一次EMC的debug过程
用座机打电话，当旁边的手机有短信或者来电时，座机会提前嘟嘟嘟的响。一般查资料会认为这是手机的辐射干扰到了座机，专业术语叫emi/emc，i对于发射，c对应接收。
虽然对这个现象早已熟悉，对这个原理也看了一些书籍，但真正碰到要解决的时候，还是兜了个大圈子。
前一阵做一颗芯片，旁边一打手机，芯片的输出也是会附带“来电显”。同样类似功能的芯片就没这个问题。因此作为一个bug开始抓虫过程。
先是有先锋官去不管三七二十一的实验。他先根据现象，反推受干扰的pin，然后用示波器观察，的确看到这个pin上有脉冲跟随手机拨号过程。很显然这是一个emc过程。这个pin是一个比较器的输入，为了防止干扰在外部还有一个小电容滤波。作为实验，我们增大了电容，效果更差，而减小电容效果更好。最后他的结论是应该把电容去掉。
但是我们的常识是电容是为了滤波用的，所以这里有严重的实践与理论偏离。
我也是从干扰从空间电磁辐射传来出发的。不过仅仅这点理论储备似乎显得不足，电路板上的各个环路会引入什么样的干扰，似乎基础知识都还回去了。于是先做实验，用示波器在各处看波形，希望能直接看到在哪个回路引入了干扰。另一方面就是把pcb进一步简化，看哪个回路去除后就好转。没想到这个实验方法把我们引入了歧途。经过几天的排除法，我们似乎看到了引入干扰的回路。但顺着这个思路继续，做出一个毫无意义的结果：芯片放在那里，就能看到pin上的干扰波形，与pcb回路无关。这简直是出乎意料，难道是芯片内走线有问题？最后我直接用示波器观察一个导线，发现同样有干扰波形。结论就是示波器本身引入了新的干扰回路。这有些像量子力学了。所以接下来是不能用示波器这里看来看去了，只能从芯片表现来猜测干扰的大小。（根据许多文献的记载，需要把示波器的接地线去掉，换一个自制的局部接地线就可以避免这个问题）
刚才说了，输入pin有一个电容。这个电容的地没直接和芯片地连接，而是在电源输入处实现星形连接。从这个事实出发，我飞了一根线把这两个地连起来，然后断开原来的走线。芯片的表现有所不同。但是由于这个干扰源本身就不可靠，所以没法直接认定这个方法是对的。从理论出发，这时我才想通了干扰是从地回路引入的：两边的地在输入连接，然后一头去了电容，达到比较器的输入，比较器的输入另一端参考相当于芯片地，又走另一根线去了输入。当有辐射时，等于在这个回路里引入了一个电压源，电压源除以整个回路的阻抗形成电流，然后根据不同位置的阻抗决定了各处的电压。那么解决办法一种是减小回路面积，这已经通过实验确认。另一种是改变这个回路的阻抗。去除电容，等于在高频下增加了阻抗，那么另一种就是增加电感，于是我给这个地方加了个磁珠，也起到了效果。再一种方法就是改变pcb，减小回路面积。在新改的pcb上，也确实验证没有问题。至此，这个问题基本算解决了。不过还是留下了一些技术问题需要进一步思考。 
从线性时不变系统到线性周期时变系统（前言）
我们微电子的模拟课程基本上建立在线性时不变系统的分析上，信号与系统整整一本书基本都在讨论线性时不变系统，而电路分析的课程则将该理论应用到具体的应用中，例如gray的书，很多时候就是讨论传输函数，稳定性。因此我之前也说过，如果要选择一个最重要的概念来解释，那就是线性时不变。
但是在具体电路设计中，线性时不变其实只是一部分，我们遇到的很多系统是非线性，非时不变的。通常的做法就是把非线性小信号化，成为线性，把时变平均化，成为时不变。但是这些方法还是和真实的系统存在一定的偏差，那么偏差在哪里，什么时候偏差比较重要，什么时候可以忽略，这些问题说实话并没有人系统的讲解过。我想主要原因在于这个问题目前还没有普遍的解法。
在这个大问题之下，把我们的目标进一步缩小，针对线性周期时变系统，目前应该是有相对成熟的理论。cadence中的pss及其相关的分析就是一个应用实例。而虽然范围小了很多，但是这种系统也是相对常见的。开关电容电路，开关电源电路，pll电路，基本上都可以用这个系统来解释，这也是pss分析的目标电路。
但是即使是这种相对成熟的理论，也找不到比较合适的书来讲解其背后的原理。如果不知道原理，看着那么多选项，我想很多人仍然可以做出仿真，就像我们并不完全清楚tran仿真中trap，gear算法是用了哪个公式一样。但是如果能知道其背后的原理，我们也许可以更好的理解这个仿真以及仿真的结果，就像我们能大概了解trap，gear的优缺点一样。
最近无事，胡乱看了看相关的材料，觉得也许想清楚了一些问题，但是还有一些问题仍然没搞明白，所以准备在以后讨论一些相关的理论内容，对自己的好奇心也是一种交代。
作为讨论的引子，让我先来说一说一些我们可能习以为常，但是其实和线性周期时变系统分析相关的例子。
在开关电容电路里，几乎每个课本都会讨论一个开关电容，可以等效成一个电阻。那么问题来了，这个等效成电阻是什么含义？为什么OTA设计时又不认为它是个电阻，不会影响增益。这种“物理”性质的理解有时候可以帮助我们理解，但是再深入下去我觉得引发了困惑，因为它不严格。
在开关电容电路里，当负载是开关电容时，该如何讨论前级的驱动能力呢？当然我们可以分相位讨论，但是为什么这里需要分相位讨论，而不是状态平均呢？当前级是ref电路，后级开关电容上有信号时，还存在ref建立不足引入的谐波，这个谐波如何定量讨论呢？（谐波通常表明有非线性过程，因此不能完全被线性周期时变理论框架解释，但是可以类比线性时不变过程中的讨论）
在开关电容电路里，我们需要讨论运放的稳定性。我们可以在每个相位讨论，可以用pstb讨论，可以把开关电容等效后讨论，这几种讨论有什么关系和区别？
在pll电路里，讨论系统函数通常是等效为线性时不变系统。但是gardener也给出了一个离散化的讨论结果，两者不完全等价。为什么两者会有不等价的情况，但是在很多时候两者又是近似相等的？有人会说是带宽决定。那么在带宽不是很窄的情况下发生了什么事情。
在开关电源设计中，使用状态平均法来将系统转为时不变。这个状态平均法的条件是什么，与pss，pac又是什么关系。同样是开关电源设计，在电流模中，状态平均法在高频处有问题，一种解决方案是用一个采样过程来描述，另一种是将这个采样过程近似展开继续用线性时不变系统近似。那么为什么会出现采样过程？似乎采样过程在pll的分析中也出现过，也起到了更精确的作用，这里是否有关联存在。
进一步，在周期时变中噪声如何分析？pnoise给出的分析是什么含义，如果一个简单系统，是否可以手工算出噪声？在understanding Δ sigma adc的最后给出了一个开关电容算噪声的例子，在那个例子里是分相位计算，这与线性周期时变的普遍理论有什么关系？
可以看出，上面的问题要完美解答，需要一个线性周期时变系统的数学基础。有的问题还需要非线性系统线性化的一些理论基础。
在之后的blog里，计划对上面的问题尽可能做出相对严格的回答。当然也有一些问题目前自己还不清楚，希望有了解相关内容的同行可以一起讨论。
目前脑海里的一个大纲如下：
0. 线性时不变系统的分析方法
1. 从大信号非线性系统到线性小信号系统
2. 线性周期时变的分析方法之一：脉冲响应
3. 线性周期时变的分析方法之二：频率响应
4. 线性周期时变系统与采样的结合
5. 脉冲响应与频率响应的关系
6. 噪声与线性周期时变系统
7. 理论分析与实践的结合


(未完待续）
 
从大信号非线性系统到线性小信号系统
目前对于周期时变线性系统的理解，我也是从线性时不变系统的解决方法进行类推。因此在这里首先把我们熟悉的线性时不变系统解决方法做一个小结。这一节基本上等价于信号与系统这本书的一个总结。
对于平时的一个电学系统，我们可以用一个方程来描述它，即f（x,y）=0，其中x是输入，y是输出，x和y的系数是由系统特性决定的。这个方程也许是很复杂的，非线性的，甚至没有可靠公式的。通常我们可以称它为大信号方程。比如一个共源放大器，用电阻做负载。其中mos管的IV曲线的函数可以很复杂，不失一般性，这里我们写作K*(Vg-vth)^2*（1+λ*Vd）。最后的方程就变为K*(x-vth)^2*（1+λ*y）*R-Vdd=0。这个方程里也许还存在对时间的微分项。但是这么一个方程，我们通常是没有什么通用的手段处理的。因此需要在时不变的前提下线性化。
什么是线性化？如果一个系统，输入a时输出f(a)，输入b时输出f(b)，那么输入a+b时输出就是f(a)+f(b)，这就是一个线性系统。为什么要线性化？简单的说，可以认为这个系统能够分解成许多简单的情况，每种情况各自独立，那么只需要研究简单情况，然后通过求和就可以知道总体。怎么做线性化呢？从微积分的经验我们知道，如果一个曲线在局部展开，就可以在局部近似用直线代替，而直线就具有线性化的特点。所以如果我们能把上述方程在局部展开，就可以做到线性化。（曲线是如何与方程挂钩的？对上述公式，我们可以认为它代表了一个曲线，坐标轴分别为x和y，这个曲线上的所有点都满足这个公式。这个曲线可以是任意形状的，也是随时间变化的。但是作为简化，就可以在一个小范围内观察它。）而时不变意味者时间平移不变性，就是说这个曲线在时间轴上可以任意平移。
为什么要线性化？这是由于我们希望系统有分解的特性，即可以把输入分解成不同的组成，然后研究每种输入对应的输出，然后直接组合就可以得到总体。这是由于我们目前水平不足以处理各种复杂耦合而做的妥协，但并不意味着我们只能这么做。之所以多说这么一句，是因为总有人说科学就会简单思维，哪里有中国传统天人合一的哲学高深，中国传统讲究整体思维。然而，在各种条件都不足的情况下就讲究整体思维的人，请来做一下电路设计吧，希望不要成为只能夸夸其谈的人。
如何做线性化？首先需要找到一个固定的点。可以考虑这样一个情况：假定我们的输入是某个恒定值，一般而言可以用这个大信号方程可以求出一个恒定的输出值，即f0(x0,y0)=0，此时所有对时间的微分项都为0，为了强调这一点我将f改写为f0。这个点就是我们平时一直说的直流工作点。在这个直流工作点附近，假定x从x0变为x0+ΔX(t)，y从y0变为y0+ΔY(t)，这个新变量仍然满足f(x0+ΔX, y0+ΔY)=0。我们可以将第二个公式在x0，y0处展开，并减掉原方程（去除直流成分），然后忽略掉ΔX和ΔY的高次项（这个过程就是在曲线局部展开的过程），得到
（K*(x0-vth)^2*（1+λ*y0）*R -Vdd）-（K*(x0+ΔX-vth)^2*（1+λ*（y0+daltaY）*R -Vdd）=0，即
2*K*R*(x0-vth)*(1+λ*y0)*ΔX+K*R*(x0-vth)^2*λ*ΔY=0
作为直流工作点的x0和y0我们认为是常数，因此该方程是一个关于ΔX，ΔY的方程，且只有其一次项和对时间微分项（上述公式中没有体现），这个方程的系数与原大信号方程是有关系的，一般来说是原方程的系数与x0，y0的组合，因此也是常数。
通常来说，这种展开都会变为只含有输入和输出小量对时间的微分项，而没有小量自身的高次项和交互项。这就变为了信号与系统课上通常要讨论的内容：线性时不变系统的微分方程，其特点是方程中只含有输入输出对时间的微分项，且系数为常数（这种方程一定代表一个线性时不变系统，但反过来是否成立呢？）。
在我们电路中，不会这么复杂的先写方程再展开相减，而是可以直接将器件在工作点展开，比如mos管就可以展开成为一个压控电流源并联电阻，将这个小信号模型带入电路，可以得到同样的微分方程，但是步骤更简单。
在这里不厌其烦的写出这个推导过程，原因有两个，一是要强调这个小信号是和直流工作点密切联系的，小信号是指工作点附近信号的变化量而不是指信号本身；二是因为这个过程在线性周期时变系统中也会遇到，需要做类似处理，但又有所不同。
在此之后的处理方法就和信号与系统课程基本一致了。
我们可以把该方程左边写成输出y的对时间微分项，右边写作输入x对时间微分项。而系统的特征就体现在这个方程的系数中。由于该微分方程是个线性系统，那么我们可以将系统分解来分析。一种方法是将输入分解成无数个δ(t)函数。由于时不变特性，只要求出一个δ函数对应的输出h(t)，就可以用卷积的方法求出真正的输出。另一种方法是将输入分解成无数个e^iwt函数，求出每个e^iwt函数对应的输出，就可以求出真正的输出，这其实就是傅立叶变换或者拉普拉斯变换。这种方法也可以理解成，在频率域，输出的频域变换等于输入频域变换与系统传输函数的乘积，而系统的传输函数，其实就是由方程系数构成的多项式。因此有两种函数代表了这个系统的所有信息，一种是函数h(t)，另一种是系统的传输函数H(s)。作为两种方法的桥梁，可以知道，δ代表一个在各个频率上都有同样分量的信号，因此它对应的输出做傅立叶变换，和系统的频域变换是相同的。
从上面的分析可以看出，线性系统的一个特点是可以简单的分解。这和线性代数里的观点是相同的。对于线性系统，最核心的任务是找到一种合适且简单的分解方法，这等同与找到一族线性系统的基。在这里，这组基就是δ函数或者指数函数。
回到文章中间的问题。线性时不变系统和常系数微分方程是什么关系？这个问题我原来也没留意过，但在写这个文章时忽然有些疑问。我个人认为需要回到原始定义去。线性时不变系统的核心定义在于δ函数对应一个输出。而常系数微分方程对应的解表明δ对应的输出是一个由多项式比构成的传输函数对应的拉普拉斯变换。从这个意义上说，后者是一种特殊情况，而前者更普遍。换句话说，前者对应的输出可以是任意波形，如果要对应到后者，也许找不到有限次数的方程来描述。


 
线性周期时变的分析方法之一：脉冲响应
线性周期时变系统，也可以用类似的分析方法。首先看大信号系统。考虑一种系统，比如开关电容电路，其电路结构是时变的，因此在写大信号方程时，其系数并不是常数，而是一个周期函数。这种系统在很多情况下非常常见，比如开关电源电路中的恒定周期控制，pll。但是另一种系统，比如vco，不仅其电路结构是时变的，而且该时变的函数与输入输出也有关系。开关电源中的CRM控制可以认为是另一个例子。这种系统可以认为是一种振荡器。
为了求解这种系统，同样我们需要先找工作点，但此时工作点就不是一个点，而是一个周期函数了。
仍然考虑一个函数f（x,y）=0，在时间轴上看，它具有周期性。假定输入是恒定值x0，那么一般而言，输出y0也不是一个恒定值，而是一个周期函数。比如我们将上一节的方程中R改为R(t)。
假定输入变为x0+ΔX(t)，那么输出就从y0(t)变为y0(t)+ ΔY(t)，且仍然满足原方程。也用同样方法相减并展开，就得到一个新的方程。这个方程是关于ΔX，ΔY的对时间微分方程。和上一节讲的内容相比，区别在于系数，这里的系数将是时间的周期函数。
不失一般性，我们假定方程为λ1(t)dy/dt+λ0(t)y=μ1(t)dx/dt+μ0(t)x，其中系数均为周期相同的函数。
但是由于系数从常数项变为一个周期函数，这个方程的难度就增大了很多。在极限情况下，系数周期趋于无穷，就代表了一个通用的函数。虽然说它不是不能解。但是如果求解的过程过于复杂，就失去了直观理解的意义（当然直观理解在不同程度下有不同含义，同样是拉普拉斯变换，有人觉得就很直观易懂，有人就觉得还需要更进一步解释才能理解）
对于这种方程，线性特性仍然存在，但是时不变特性已经消失。因此为了继续使用线性的思维方式，我们仍然需要想办法做分解。
当输入为δ函数时，随着时间的不同，其对应的输出也不同。因此一种分解方式就是把输入按时间分解，考虑不同时刻对应的输出h(t,τ)，其中τ代表输入不为零的时刻。由于系统是周期T的，因此h(t,τ)= h(t+T,τ+T).而为了获得任意输入下的输出值，需要根据线性特性，来求输出值。为了求输出，此时仍然需要做积分，同样可以写出一个类似卷积的表达式。h(t,τ)就代表了这个系统的所有信息。
一种更通用的想法就是，如何把这个方程分解成若干个方程，例如f1(x1,y1)=0,f2(x2,y2)=0…。如果存在解y1,x1,y2,x2…，那么当输入为x=x1+x2…，输出就自然为y=y1+y2…。这样的话就成为我们熟悉的模式。而解决问题的关键就是如何分解，以及分解前后的关系。按照这个思路，可以进一步进行分析。

 
线性周期时变的分析方法之二：频率响应
上面的方法由于需要积分，需要一族函数，因此物理意义不是那么明显。由于大家对傅立叶变换比较熟悉，因此更希望能将系统在频率域进行分析。
这也是cadence pss分析的基础。按照cadence的说明，单一频率的信号输入会导致多个频率的输出，单一频率的输出对应着不同频率的输入。因此此时系统传输函数是一个多到多的映射关系，可以用多个传输函数来描写。不过对于这点，目前我还没有看到推导过程。我自己打算用

信号经过线性周期时变系统再以同样周期采样，等效于信号经过线性时不变系统再采样
粗粗的想来和不严格的推导，感觉应该是成立的。不知道有哪本书讨论过这个问题。
感觉对于线性周期时变系统还是不很了解，比如那个pstb的原理。
~~~~~~~~~~~~
目前的几个粗糙推导是这样的：
1.假定普遍情况下的脉冲响应是h（t,tao)，是一个二维函数，因此可以做二维傅里叶展开。从而得到当输入是单一频率时，输出波形的傅里叶变换是上述二维图像在一条直线上的值。因此一般来说，输出是包含很多频率的。其中有一个频率是原始输入频率。按cadence文档提到的，pstb就是只看该点的bode图（该说法仅仅是帮助文档一句话，没有其他来源）。
2. 周期时变系统的h是在一个方向存在周期性，因此其傅里叶展开应该在一个方向是离散的。
3. 至于采样，可以直接计算采样点的值，算下来确实与一个等效的时不变系统再采样效果相同。至于这个等效的时不变系统脉冲响应，与原始的脉冲响应，也是存在一个简单线性关系。那是否也意味着傅里叶变换之间也存在一个简单的关系？没有仔细算。
4. 当周期时变系统相对简单时，完全可以算出等效的时不变系统。这就解释了以前做课题时为什么有人对周期时变系统也画出了传输函数的图像。


 
 EDA使用篇

 
Gui vs cmd
当年上学时，曾经听到传说，资深的模拟设计大师是不用gui的，都是用命令行。当时听了觉得神奇的不得了，又觉得不可思议。因为自己那时也由于条件限制，曾经手写过网表，发现问题很多。一个是其实在写之前还是必须把电路图画在纸上，标上节点名称，否则规模一大绝对搞不定。另一个是如果出了问题，想找到问题难上加难。
后来工作了，见的人多了，才知道有些传说也就是娱乐娱乐而已。要真有那样的大师，也不是因为他觉得gui不好，而是由于之前没有方便的gui，习惯了手写的方法。gui还是有一定优势的，直观，加上能够highlight节点，找起画电路的问题效率高的多。那些option也往往是按照一定规律安排的，对于初学者来说简单明了，重点也突出。
再后来，自己也开始向cmd靠拢了。因为gui毕竟是给原始的套了个壳，有时候你想用的option它没给包装，要用就需要自己想办法包装一下，有时甚至想自己包装而不成。再比如一些模板化的东西，要是每次都gui去一点点点击，不如想办法搞个脚本，扔给计算机了。还有就是gui有时掩盖了对cmd的深入了解，有时到了命令行，看了手册才知道其实还有很巧妙的用法。
当然，用了cmd也不是就傻乎乎的自己从头开始，那种得要自己把一本手册先通读，再细读，费的精力太大。很多情况下，gui给了通往cmd的捷径，可以保存一个脚本，在这个脚本的基础上修修补补，再查查相关的文档就省事多了。
最后说说cmd下需要的东西吧。perl是个挺有趣的语言，虽然现在没python流行了，但我觉得用习惯了挺舒服，一个是文本操作方便，一个是数据结构方便。shell我有些怕，不同的shell差异太大，所以我就学学最简单的用法，复杂的扔给perl就成，awk等也类似，不学也罢。不过vi是个例外，学好vi还是能节省不少时间的。进到工具里，cadence用skill一统天下，skill其实挺复杂的一个语言，加上cadence本身给的文档问题，想对cadence里的数据操作，很难很难。为了做一些功能，比如让电路中的器件换模型，我就需要不停的google才行。直到今天，我也只是见招拆招，学到了skill在cadence中的一些用法。ocean虽然是附带在skill中的，但是ocean本身用的更多些，循环着跑仿真就很方便。一般cadence 会产生ocean的脚本，所以初级用法不学就会。高级用法文档也不算多。当然了，spectre的语法是必不可少要看的。有时在spectre里能找到不少有趣的东西，比如bsource，虽然号称要被veriloga代替，但简单的用来写一些东西，挺方便。除此之外，提取有calibre用的语法，快速仿真有hsim用的语法，veriloga有veriloga的语法，vec有vec的语法。隐藏在cmd后面的是许许多多的语言，当然我们也不需要一一精通。但用到哪个，有时间了看看user guide和reference对提高效率还是很有帮助的。 
ADE simulation 的背后
cadence里用spectre仿真，一般都是直接用图形界面，在ADE里调用spectre，包括看结果也在图形界面中。
图形界面有图形界面的好处，就是比较直观。可是图形界面也局限了设计者。要是想有个什么调整而图形界面不提供，就觉得束手无策了。
用了多年的图形界面，时不时也需要转到命令行去干点事情，就逼得我不得不研究起icfb里的仿真过程来了。下面就大概讲讲我的理解（事先声明，我没做过 cadence AE，而且软件版本不同行为可能会有所不同，我这里说5141，所以如果大家发现自己那里不是这样，请自动忽略，毕竟渔比鱼重要）。
先说网表生成。在ADE里有个switch view list和stop view list在控制网表产生的遍历方法。更具体些，我们做电路图，每个cell都有若干view，那么生成电路图时用哪个view，就是这里的list控制。可以想象是一棵树，stop的就是最终的树叶。cadence文档里对此有详细的解释。至于用了schematic view之后又是如何更具体产生网表的，我不是太清楚了，怀疑和CDF里的simulation information有关系。
产生网表的过程还是一个名字替换的过程。这是因为spectre允许的名字和schematic里允许的名字规则不完全一样。所以可以会有一个名字转换的表格存在。这个表格以目录的形式和最终网表放在同一个目录下，一般是netlist/amap。举个例子，电路图中的a<1:0>就需要转换（虽然spectre能认类似的结构，但网表里还是被转换成a_1 a_0了）。知道这些，对于后仿真，使用别的波形软件等工作有很大的帮助。
最终的网表会在netlist下的input.scs，可以肯定的是这个就是ADE最后使用的网表，不信可以看看ADE里simulation -》netlist里。同时ADE还提供了相应的命令行runSimulation。需要说明的是runSimulation里应该是用了与ADE交互的模式+inter=mpsc，所以如果我们用这个命令行，就要把相关的删掉。
从命令行里可以看出，仿真的输出都在../psf下面。这是默认的行为。对于parameter仿真，corner仿真，结果是在../Corner等目录。但是结构是完全一样的（至于网表是如何生成的，我有些没明白，怀疑不是一次生成的，而是仿真一个产生一个。可以确认的是在不同版本，不同option下也有所不同。）。在psf里有个重要的文件叫runObjFile。以前我没注意到，后来才发现它其实是用于解释仿真结果目录结构的（旧的result browser必须有它，新的似乎可以不用）。要是corner仿真等，全靠它指示看波形软件到哪里去找结果。而corner和parameter仿真结果不能同时被波形软件提取出来估计也和这有关（不知道新版本是否可以做到）。有兴趣的可以看一眼这个文件，还是文本格式的。很多时候，如果缺了这个文件，仿真结果虽然就躺在那里，看波形的就是视而不见。
其实spectre在命令行里也提供了不少便利，网表里也是，但是在图形界面下未必有对应的按钮，或者不能搞批处理。所以有时候利用图形界面产生的基础，在上面做简单的修改，搞命令行模式也是提高效率的事情。具体的可以查spectre的使用手册。 
EDA版本相关的几件事
刚才用cadence，发现可能是由于仿真数据太大，cadence自带的波形工具就不能读出来。回想以前，似乎也发生过类似的事情，但印象中换了版本就再也没出现过。网上有人也问过这个问题，但回答的人中有的说有限制，有的说没有，却没有人报出自己的软件版本。
另一件就更印象深刻了。在cadence 的icfb里把网表导成电路图是件不大不小的事情，为此我专门研究了几天，找文档看文档实验，终于觉得自己搞定了。没两天别的部门的人跑过来说能不能帮我们导个电路图看看。我觉得小菜一碟，就说你等一下，马上完成。结果打开软件发现怎么熟悉的配置全变了。捣鼓了好久还是没能完成，只好很遗憾的告诉对方，搞不定。我猜对方一定觉得我外强中干:(。真正的原因其实是：刚刚把软件换了个小版本号。（其实后来再研究，发现新的导入比旧的导入合理多了，不过其他部门的人估计被我前一次吓跑了）
几天前又发现一个和版本有关的问题。spectre 6.1中做corner仿真，如果有ic语句会使得仿真失败，7.1就没这个问题。
我原来工作的单位没有专门给我们部门的cad，所以向来都是装一堆软件在服务器上却不说明，全靠自己配置。不过这种模式也让我见识了各种小版本号的icfb，也碰到了各种意想不到的bug。有一个小版本号的spectre读取vec文件，居然限制文件的名字不能多于8个字符（这是我一点点试出来的，所以印象深刻）。
因此软件使用这东西，和理论不同，太容易发生变化了，一切只能以文档为准，甚至文档有时都不准，还是以自己的具体使用为准，别人的使用心得也仅供参考。  
后仿真的经验
看到板上有人问后仿真，就在这里大概说说我的经验。
后仿真要是从方法上分类，我觉得大概有三种，一种是gui，一种是网表，一种是反标注。
gui的就是用calibre产生calibre view，然后仿真的时候自动从calibre view中生成网表。这种我没用过，看别人用过。好处是方便，与原来的流程整合度很高。不过要是想做些debug的事情就很麻烦。
网表就是直接产生相应的网表，然后在前仿真的网表里替换。这种方法比较土，工作量也大，根据不同的提取工具和仿真工具，需要修改一些东西。我最不可理解的就是做提取时用的是cdl，做仿真时用的是spectre view，然后如果pdk做的不好，这两种view总会多多少少有些差异，导致产生的网表需要修改。这种差异是换什么提取工具都不能消除的，只能怪pdk。但是这种流程EDA公司一直没有修改过。一般的差异包括了：端口顺序，节点名字（仿真器有时会修改节点名字，特别是总线，可以看我之前的blog，cdl也可能会用不同格式的名字）。随着EDA工具的版本提高，PDK库的升级，以及提取文件的选项设置，好像目前需要修改的越来越少了（不知道为什么，05年的时候需要修改的地方非常多，即使t这样的公司给的pdk，前后仿真连模型名都完全不一致，需要自己找到对应的然后修改）。一般只用修改接口处的内容就可以了，内部只要保持自恰就行。需要注意的是需要保存节点的名字和ic设置的名字。有时候这个地方最麻烦，因为提取后的名字会和原来可能有差异。再就是有时bipolar会在前仿中用m=...，但是后仿用area=...，后一种与器件模型不自恰，会导致仿真失败（这是我又一处不理解EDA公司的地方）。这种方法的好处是比较灵活。有时候为了debug，只要在网表中手工修改一下，看看效果，就可以知道找的地方对不对。有的人习惯前仿用cdl的网表，这样后仿就能保持基本的一致性。不过说实话，我觉得cdl格式并不是为仿真用的，很多pdk里提取出的cdl网表也就是能用而已。
还有一种是反标注（back annotation）。我挺看好这种方法的，但是目前工具对这种方法的支持也有问题。提取的时候，如果选反标注，就会生成诸如dspf之类的文件，按照我的理解，就是把寄生器件和节点对应关系之类的信息写在这个文件里。（实际中可能会有dpf，包括器件的实际信息，dspf，寄生参数，spef，另一种格式的寄生信息）。然后仿真器再根据这个dspf里的信息，结合前仿网表，自己自动产生内部的仿真网表，但是对外保持接口不变。由于对外接口不变，设计者的工作量就小很多，不用找名字对应关系了。可惜，这种方法目前的问题是：1.只有有限的仿真器支持，比如hsim，spectre不支持。2.不同提取工具产生的可能语法有差异，导致对一些信息的解释不同，特别是耦合电容，所以换仿真器或者提取工具时要小心。3.有时由于前仿网表和lvs网表的差异（还是pdk，cdl的问题，这无解），存在反标率，就是可能有的寄生参数找不到位置。这种问题还很难debug，因为有时候给的信息不全，想修改都不知道问题在哪里。不过我做下来，大部分还是由于名字大小写，总线，spectre自动改名之类的问题，或者由于做了一些简化，导致一些节点消失或者多出来。
我不知道为什么仿真器目前不能很好的支持这种反标注，按理说就是一个重新解释网表的过程，应该比写仿真器容易多了。
总结一下，目前后仿真许多问题的根源大部分来自于仿真用的网表和lvs用的网表来源不一致。如果来源一致，让EDA工具自己做那些改名字的事情就好多了（我的这些经验都来自于11年之前的EDA版本和t的pdk版本）。
还有另一种分类，就是按照提取的是r，是c，是cc等来区分。一般来说流程上差异不大，但是对于有r和没有r，名字一般会变化较大，因为有r的会增加不少新节点。如果多看看网表，还是能找到命名规律的。我比较看好新版工具的一个特色，就是让r和c的提取可以混合进行。以前是要么是提r，要么是提c，要么提r+cc，但必须是全局设置。现在可以在局部设置不同的提取方式，比如全局是提c，但局部提r，考虑到仿真时间，这种方法还是挺不错的。
再一种分类就是按照是打散了提取还是层次化的提取。前者据说精度最高，但是一般前仿都是层次化的，所以名字一定会变。后者偶尔用用也不错，但是我同事碰到一次奇怪的问题，就是网表出错了，查进去说有一个cell的端口名字不对，不知道为什么，这种事情难得碰到一回。
想到一个小事情，现在在新工艺下，经常要加dummy metal。如果提取时忽略dummy metal，往往比不忽略得到的寄生小，但是如果不忽略，网表将巨大无比。所以提取工具还给了个简化的选项，这也是在时间和精度上做巨大的trade off。
另一件事情就是无论提取工具多么好，最后起主要作用的还是规则文件。曾经有一次有个工艺给的规则文件里忘了提as，ad这些，至于sa，sb那就更不用提了，这样的东西即使提取了寄生，准不准是一方面，信不信是令一方面。
再就是提取的寄生电容到底准确度有多少？有人说提取的是为数字电路考虑的，所以会偏大20，30%。又有人说差了2，3倍。由于也没有可靠数据，都是道听途说，所以有foundry做这方面的人能说说实际情况最好。 
EDA使用的一些技巧
这里随手写些以前收集到的一些软件方面的内容。
icfb里可以用ocnPrint打印数据，和用计算器是一样的，但是计算器有时数据太多会报错（AWD）
icfb里控制电路图上显示数字位数用aelPushSignifDigits，或者cdsenv中asimenv digits int x和auCore.misc labelDigits int x。这几个应该是labeldigits优先（？）
spectre（5141）把sweep的结果和corner的结果可以同时放在一个目录下，但是它用主目录下的一个文件做索引，这个索引只能sweep或者corner选一个，因此数据结果都在那里，就是没法用awd去看。
icfb提取cdl时按照CDF里cdl的信息提取名字，提取仿真网表时按照CDF中spectre相关信息提取，两者名字可以没有丝毫对应关系。
calibre提取名字时按照rule中DEVICE语句和一些默认规则进行，因此又是另一套名字机制。
所以等到pex出网表时，如果做pdk的人，写rule的人想搞混乱，那可以想多混乱就多混乱。
spectre 的多线程是+mt，加速是turbo，更快是aps，想中间中断然后可以接着仿真，可以用savestate相应命令保存，recover恢复。
icfb的安装目录下有doc目录，里面是各种help。有空看一看作用很大。其他软件也一样。
cdl的语法类似spice。spice对global信号的处理有两种优先机制，subckt里的一个net名字如果在global里也有，在port里也有，谁优先是靠option控制。在calibre做lvs时也设计有lvs spice overdrive/prefer的option来控制。我猜这是为了处理stand cell，因为那里习惯把vdd之类都定义成global，在和纯模拟电路一起lvs时是个大麻烦。
calibre里xrc可以分步做，有时可以提高效率，避免重复。
calibre做xrc提取spectre网表时，端口顺序，大小写，一些特殊名字的处理都很麻烦，这个以前blog里提到过。唯一的好处是对网表的控制力很强。
linux里通常命令窗口关闭，对应打开的gui也关闭，更进一步，logout时各个程序也退出，所以用screen可以解决。其他的包括 setsid，（命令&）
从cdl导成电路图，不同版本差异很大。有一种是用devmap file控制如何解释cdl里的各个语句。
cdl导入电路，如果不加*.bipolar等，就不会管bjt等器件（印象中lvs也有这个问题）
cadence的symbol中可以用cdsParam [@....]等特殊写法，可惜对此不熟，也不知道哪个文档说明这个事情，用的好可以做些有趣的东西
skill是cadence里最神奇的东西，感觉就是九阴真经一样的东西。不过有时又觉得是屠龙之术，因为一年也用不了几回。
用skill修改cdf属性，直接修改不会调用callback函数，换句话说是不会刷新，查到的一种做法是：cdfgForm=nil(内置变量，避免出现对话框），callback=(getq cdfgData formInitProc) , (when callback&&calback!="" (unless (errset (evalstring (strcat callback "(cdfgData)" )) t )), parameters=(getq cdfgData parameters), (foreach param parameters....)不是太明白为什么要这么做，但是it works（这里给出的是个大概，具体的可以在个人空间里找我以前写的一个替换库的脚本）。
skill也可以直接产生电路，不过我做过的唯一一个玩具就是同一个电路参数不同，电路长的不一样。
icfb里的图形颜色不同位置受不同参数控制。线条等的颜色受工艺文件中的layer：propose控制，程序的背景受.Xdefaults控制（不过这个又受操作系统的X机制控制，很混乱很不可靠）
让terminal和xterm的标题显示不同内容，可以用setprompt命令，比如set prompt="%{\033]0; %~ \007%} `hostname` "
清除icfb下的lock文件，可以clsAdminTool -ale
spectre里有mdl，按说明是可以批处理一样边仿真边给出测量结果（类似spice的measure）看着很神奇，不过觉得平时用不上。
linux操作系统对安装包的管理有dpkg系列，apt系列，rpm系列（这个似乎不能算包管理），等于是各家给各家做的安装管理程序。
perl的语法可以让人苦笑不得，比如$str->{rule}[2]{shape}[4]=4，可以用@{${${$str{rule}[2]}{shape}}，但是@$$$$str{rule}[2]{shape}是不对的。 
什么时候需要后仿真
庆祝节日，写些技术blog。
之前做模拟，我是没有后仿真习惯的，整个行业也没什么习惯。当线宽减小后，大家开始重视了，但那时也没上升到必须的高度。后来到了65nm，一个是另一个小组发现流片结果与实际偏差太大，最后归结于后仿真，另一个是我们组发现新增加了许多版图效应，导致前仿和后仿有巨大差异。那时我们就把后仿的地位提高到了必须级别，同时也从仅在最后一个大block的查疑补缺地位提升到了每个单元的设计后仿同时进行。
这几年不做小尺寸的设计了，后仿也就不做了。但是最近几件事情让我觉得如果单纯把线宽和后仿联系，也是有问题的。
从基础说起，后仿其实是计入了版图的效应。后仿的网表比前仿更接近实际。那么是否需要后仿，就等效于新计入的效应对整个系统的影响是否大。如果都是很微小的效应，那其实一般都是通过前仿留margin就解决了，不需要后仿。如果这个效应已经很重要了，那就需要后仿。后仿目前考虑了：版图的wpe，lod等效应，这对应影响了器件的vth和匹配等特性；寄生电容；寄生电阻；寄生电感。即使做后仿也存在策略问题，哪些需要提取哪些不需要。如果一骨脑全提，最后仿真时间太长，也失去了意义。所以仍然需要用之前说的判断依据：寄生是否已经不能算微小效应了。
什么叫寄生不能算微小效应？一个电容10f算微小吗？不能这么看。如果一个本征电容是10pF，10fF就算微小，如果本征的只有100fF，那就有点悬了。如果这个10fF对应的电压源是100V，10pF对应的信号是1V，那也不能算微小。所以微小是相对的，而且要注意和谁相对。如果能在设计之处就意识到这点，那后仿的压力就小很多，如果不能意识到这点，那即使做后仿，也有可能事倍工半。 
几件小事
刚才仿真一个电路，用aps，liberal精度，只保存了一小部分节点。开始仿真了一小段，觉得结果不对，但是保存的节点不够，于是又多存了一些节点重新仿真，结果就和预期一致了。这么看来，有时快速仿真速度是快了，但是影响精度的因素太多，所以是否可信就成了问题。
---------------------------------------------------------------
某天review，说起esd cell。我们这边的esd单元曾经出过问题，后来foundry的人帮助review后提出在esd cell的source插入衬底接触，就解决了这个问题。我印象中t的design rule里专门提到禁止使用这种做法。当时看到那条rule还比较奇怪。回去后查了查柯明道的一份讲义，里面提到过这个情况。在.35工艺下，的确插入衬底接触，可以保证各个esd cell的均匀开启，主要原因是使得衬底电阻相对一致。但在.18工艺下，通过实验发现衬底接触越多，hold电压越高，esd特性越差。讲义中没有明确说明原因。
从这件事上可以看出， rule of thumb必须谨慎看待，这也是我一贯的观点。

原始论文里证明了.18um下该方法会变差。而单位的经历证明了在旧工艺里该方法的有效。 
自己如何做一个蒙特卡洛模型
关于spectre下蒙特卡洛（MC）仿真的资料有一些，但大都侧重讲如何在ade里设置，前提是foundry提供MC的相关模型。据我所知，t是有的，下面的一些信息还是从t的模型中分析知道的。但是也有些foundry没有，或者即使有，也没有具体讲自己的模型如何使用。所以这里准备从模型的角度讲解这个问题。理解了模型，也就可以自己编写或者看懂foundry的模型文件了。
我们自己先猜测一下MC仿真的过程。从文档上看，MC分为process和mismatch两种，spectreuser的文档具体给了一个示意流程图。在每次MC分析时，（如果选择process）先根据process相关信息，将每个器件的参数统一改变，（如果选择mismatch）再将每个器件的参数单独改变。所以在模型中，就需要提供相关的内容：器件的哪些参数要变，如何变。
正常的仿真，器件参数也会变，只不过那时是调用不同的corner。因此哪些参数要变，完全可以仿照corner仿真时各个section的写法。具体的说，就是在每个模型里都有一些参数，parameter，这其实是变量。在每个corner里都给这些parameter赋值。MC时也是这样，需要在模型里有参数，在最前面有参数赋值。只是这里的参数赋值有专门的语句：statistics。具体语法可以参考手册。在statistics里分了process和mismatch两种情况，然后在每种情况下可以用专门语句描述变量的分布情况。这就回答了前面所说的器件哪些参数要变和如何变的两个问题。当运行MC时，spectre会自动根据statistics里的描述，产生相应的模型变化。而当正常的仿真时，spectre会去别的parameter赋值部分寻找变量值，所以互相可以不冲突。
但是上面描述的只是基本用法。在许多mismatch模型中，变化量的参数是和器件的w，l相关的。如何把这两者关系描述出来，上面的方法就不适合了，因为w和l并不能传递到statistics中去。spectre对此的解决方法是引入了inline subckt。可以参考spectreusr中对这个的描述，基本就是为了解决上述问题而提出的。在inline subckt中，w和l可以作为参数传到下一层中，在此同时，模型参数也被向下传递，因此可以在中间定义模型参数与w，l的关系，这时各个参数是可以相互看到的。这也就是为什么MC分析时，管子的模型一般都要换掉。
因此在最后，出现的情况就比较多了，电路中的模型可以用普通模型，也可以用MC模型，分析可以用普通仿真，也可以用MC分析。有人的blog里就总结了tsmc中几种排列组合能实现的结果。我想只要了解了底层机制，记忆这些就容易多了，而且即使工艺厂下次改变了模型写法，也能很快知道如何使用模型。
最后，说一个问题。当器件存在m参数时，按照m参数的传统意义，等于是完全相同的器件并联，因此MC分析似乎也是这个思路。但实际中理论上各个器件应该是有差别的。所以如果m大，理论上应该是失配减小，但仿真结果却是不变。我不知道是哪里还可以继续改进对m的处理，使其更加合理。目前从foundry的做法来看，是直接用子电路形式代替了model来处理m，这种做法目前我还学不来，只能是写个perl程序把m都替换掉。 
在linux下折腾EDA安装
最近忽然心血来潮，要搞搞EDA软件安装。EDA软件基本都是linux版本，因此必须要折腾linux了。
这下可就是要折腾个底朝天了。好在本人本着刨根问底的精神，在这个过程中也搞明白了很多事情。如同题目说的，linux目前还是一个折腾人的操作系统。好在有网络，很多问题顺利解决了。
这里就不提软件的安装了，集中提提linux的表现。
先是操作系统版本太高，有的命令不向下兼容，导致需要找个旧版本的命令。这是拦路虎第一个。
其次操作系统版本不匹配，装完之后什么libgcc库的问题，什么libXp的问题，都是从网上找资料一一解决。
再就是装完了，用不了帮助系统。这个网上似乎没人仔细说。先看了看，调的命令似乎是另一个软件的，原来path里另一个软件在前。改了之后还不行。再看，网上说了，旧软件调的是netscape，早就不存在了，做个link。还不行。于是进到这个命令里，原来是脚本，于是一行一行的debug（这点好，自己的机器自己想怎么办就怎么办，单位的软件有问题，IT可没那么多耐心），最后发现还是库的问题，于是缺版本的就补上，路径不对的就调整顺序，总算是自己搞定了。
总结一下，其实我这还算好的，主要问题一个是操作系统的兼容性，包括不同命令的不向下兼容，不同系统包含命令的不同，不同版本所带的库不同。另一个问题就是缺库，或者说缺so文件，或者so文件版本不对。这个问题又由于找库的路径设置，以及操作系统环境变量的设置，变得极为复杂。A用了B，要么是系统里没有B，要么有B，但有好几个，结果由于LD路径设置的问题（有的软件自己启动时又重新设置LD），导致找到的B版本不对。知道了这些问题，解决起来还算顺利。就是总担心自己不停的给这个软件修so文件的bug，会不会影响到其他软件。
回想一下，window早期其实也有这些问题，当年dll也时不时缺。不过现在基本没这些事情了。linux看着是一家，其实类比到windows，也相当于从win95到win8了。要让所有软件能不修改的运行在win95到win8，估计同样是不可能的。
其实只要把库给对了，linux的软件运行起来基本还是正常的，可是这个给对就比较困难了。不同软件可能需要的并不以一样，却要同时运行。单位上后来是给不同软件运行启用不同的环境。自己在家里想搞个傻瓜的，觉得主要问题还是出在path设置上，path等于设置了寻找文件的优先级，自然对不同软件就地位不同。
现在linux又有yum，apt等智能管理软件的工具。可是这些东西都是管理升级用的，似乎并不适合我的情况。到后来我都是只要需要的so文件，然后直接扔到自己目录下。这有些像全局变量和局部变量的关系。全局变量用多了总是担心会影响到其他东西，还是局部变量可靠些。
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
这两天又碰到一个新的奇怪问题，把解决方案写在这里也许可以帮助有的人。
现象：新拿到的一台机器，使用icfb时开ade很慢，关icfb也很慢，会报无法连接到wavesan，或者是mps session error之类的错，而且时好时坏。后来发现是和网卡有关，当网络有连接时正常，否则就有问题。仔细看了看进程，发现wavescan的mpshost与其他icfb里进程名称不同。我的机器名是a.b形式，其他icfb进程，如libmanager的命令行中都是mpshost a.b，只有wavescan是mpshost a。icfb之间的进程通讯都是走ipc，也许就是因为mpshost的名称不对造成了无法通讯。再进一步追查，在联网时，nslookup可以找到a的ip，而且是127开头（因为在dns设置中有search b的选项，就是会自动将a转为a.b，dns自动在外网中查询，居然查到了一个）。在不联网时，就无法找到a对应的ip。于是修改hosts文件，将a也手动添加进去，于是问题解决。唯一奇怪的就是为什么wavescan会在被调用时用a作为mpshost的名字。
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
 
设计思考篇
 
仿真的意义
如果学术化一些，我可以把我们设计的芯片定义为三个层次：生物级，数学级，物理级。听着很高深，让我慢慢讲解。第一种是我们需要或者想要做出的一些指标，比如一些spec，一些feature，这些可能是老板拍板的，可能是自己决定的，但无论如何都只是停留在大脑中，只是一个概念，所以只好说是生物级。第二种就是我们设计工程师大部分时间在做的，设计一个芯片，跑仿真。这时候我们其实是在写一些数学表达式，在解一些方程，所以只能说是数学级。第三种就是tapeout之后的芯片，那才是真正的芯片，电子空穴在晶格中跑来跑去，不就是物理级的吗？
定义这三种层次，并不是为了好玩，用这个模型还是为了解答题目中提出的问题，而解答题目提出的问题则是为了更好的做我们的设计和仿真工作。
工程师的工作，最终目标是让物理级和生物级芯片完美统一（通俗些，做的芯片和期望的完全一样），而为了达到统一，必须经过数学级模型（做数字电路的有福气，可以用fpga验证，但仿真也是必须的，做模拟的偶尔可以搭一些验证电路，但概率很低），所以我们就必须讨论一下如何做好数学级的芯片（通俗些，就是怎么做设计，怎么做仿真）。
把设计和仿真的过程再分解一下，是两个过程，一个是如何建立方程，一个是如何解方程。
有人会说，我从来不做数学推导。其实我这里说的建立方程是个抽象概念。我们写出一个网表，写出一个simulink模型，写出一个verilogA模型，其实都是建立方程的过程。而跑程序其实就是让matlab，或者spice去求解所给定的方程。所以设计的过程其实就是一个建立数学方程的过程。要做好设计，一个重要的内容就是如何建立一个好的数学方程。什么是好的数学方程呢？我觉得一个是精确，另一个是求解快速。可惜这两个一般是互相矛盾的。所以在设计过程中，一般是逐渐细化的过程。刚开始时，用一些高层次的数学手段，建立一个基本符合的模型，然后逐渐细化成电路的网表，然后再细化成带寄生参数的网表。
那么设计者在其中要起到什么作用呢？设计者的作用就是保证建立模型的合理，选择合理的解方程工具以及在时间和精度上做合理的tradeoff。这才是设计者区别于仿真器的一点。目前有的EDA公司搞设计自动化，其实就是在做后一步，假设当仿真时间足够短之后，设计者不必要做太多的tradeoff，那就可以由机器做这个工作（这个假设是否合理完全看当前block的大小以及硬件的发展速度）但前两个作用是很难替代的。
举一些实际的例子说明吧。
先说保证模型的合理（这个模型并不是指器件模型这个概念，但是器件模型其实也是模型的一种）。最简单的，假如你用工艺厂家的模型设计电路，然后让他工作在液氮温度下，那就属于不合理的模型，因为工艺厂家给的器件一般参数只到-40C，而液氮远低于这个温度，所以基础都错了，上面的电路也就不对了。这时就需要要么自己提参数，要么预留更大的margin。再比如，假如只做了前仿，期望仿出线和线之间的干扰，有些不现实。所以有的人故意在前仿加一些寄生电容考虑耦合。再比如一个常见的例子，对全差分结构opamp仿psrr，而不带mismatch参数。其他例子还包括，用现有的前仿或者后仿电路，期望得到衬底噪声（目前一般的衬底电阻电容是没有被包含在后仿网表中的）；用普通的器件仿真snapback特性的ESD电路（snapback目前是没有被建立在器件模型中的，有人这样仿，但目的是看RC常数）。
然后说说选择合理的求解工具。这个最常见的例子就是用tran仿完之后，看某个节点上的波动，这是不是噪声呢？（目前有的仿真器开始有带noise的tran仿真，这种的确是噪声，但传统的tran仿真，的确不是噪声）。
最后一个是在精度和时间上做tradeoff。举个例子，在整个adc上跑蒙特卡洛仿真，这就属于要tradeoff的范围了。我在国外的论文上真看到有人在晶体管级做这个，但是我很诧异他们的仿真速度。通常的做法是在比较早的行为级就做这个工作，因为那时可能一个仿真才几分钟。但是如果在晶体管级，多多少少一个仿真都要在几小时到几天的范围了。而蒙特卡洛仿真做一个是没太大意义的。那时再做，精确一定是精确了（但可能也精确不了太多），但花的代价未免太大。再比如，是用spectre仿真呢还是用hsim，用hsim的话是设成level几，后仿真时是提取什么样的参数？这些其实都是一些工程上的东西，学校里未必讲，但在实践中常常碰到。 
物理学家与数学家；科学家与工程师
熟悉数学发展史的人应该忘不了微积分的发展历史。牛顿身兼数学家和物理学家两大头衔，创造了微积分这个神器。之后物理学家用的不亦乐乎，数学家也努力维护这个神器。但是有个大主教站在一边大声的嘲笑：你们微积分就是建立在沙滩之上的，得意什么？物理学家似乎不管不顾，就是拼命向前冲，其口号就是“有用就行”。数学家则深感不安，终于经过几代人努力，把漏洞补的差不多了。据说当时有著名的物理学家听说有个大漏洞被补上了，立马心中大吃一惊，回家翻看他写的那些论文，然后庆幸自己没用错公式。当然在这段历史长河里用错公式的著名数学家物理学家也数不胜数，只是我们现在都不提了。
上面说的是数学家和物理学家。其实映射到微电子的模拟电路设计，也是有的一比。微电子的模拟电路设计，实质上是一门工程。我接触过两个人，也都算名校毕业，不过风格就差的太远了。一个是什么问题都要求给个解释，另一个是不管黑猫白猫，抓住老鼠就是好猫。给人的感觉就是科学家和工程师的差异。我呢，则是个骑墙派。从心里，我认为如果有了正确的理论做指导，可以起到事半功倍的效果。但在实践上，你会发现微电子设计是一门工程，一方面时间要求紧，不可能给你充分的时间去反复论证哪个理论是对的，只要能有结果，那就是第一位的。另一方面，经费总是不充足的，纵然有很多问题，可是没钱做对比实验，而没有实验，有时只能是空口说白话，各说各的，只求能自圆其说。再者，作为工程，有时候条件控制过于复杂，想掌握所有因素还是很难的。所以在很多时候工程师就像物理学家，不管三七二十一，有工具就向前冲，更好的工程师不仅是物理学家，也是数学家，自己还能造些工具。但是如果要求所有物理学家都是数学家，要求所有数学家都是物理学家，并不现实。顶级的物理学家兼顶级的数学家有时也会犯错：前面说的那个，应该是拉普拉斯吧。(在实际工作中，我觉得应该尽量从原理出发，尽可能多的给现象以理论解释，这样解决问题也更快些。当然了，解决问题也很重要。今天就碰到一个实际问题，FAE在客户那里什么条件也没有，硬是凭感觉修修补补解决问题。我们在后方无奈的根据那一点点信息猜来猜去，防止FAE拆东墙补西墙。后来想让FAE实验一个可能更好的办法，结果FAE已经撤了。）
还是举两个例子更形象些。某次我们做运放，谐波比仿真结果差了很多。为什么呢？开始时没找对方向，认为是模型和仿真器不准，导致带负载能力不足，于是增加驱动能力。仿真上看改善了不少，但实践中一看，只算是从近似是个错误变成了比错误稍好些。再次仔细查，才发现是某处连线寄生电阻的问题，虽然本身寄生电阻不大，但谐波这东西，对这些非常敏感。另一个例子，某次做adc，也是谐波不好，稍微升了一些电压，马上就有了改善。根据这个线索，怀疑是某个开关不够大造成的。不过从仿真上怎么也得不出这个结论。改版的时候还是按照这个想法改的，结果是改好了。但是为什么仿真器一点提示都没有呢？至今只有一个猜想而没有结论。 
学而不思则罔，思而不学则殆
老夫子真是微博高手啊，说的句句都是名言。换到工程上，就是埋头干活不思考，就是傻干，光讨论理论分析不在工程上验证，就是傻想。
另外一点就是别人说再多经验也是别人的，事情不落在自己身上，自己是没有太多体会的。
有些时候，产品的难点不完全在于技术，而在于如何把需求约束条件转换为技术实现，更糟糕的是需求约束条件是什么也不知道。
设计电路时常常感到木桶原理的存在，即系统性能往往是被某一处限制住，如果不找到这个限制的地方，在其他地方处处增强，对性能的提高收效很小。
成功的设计都是相似的，不成功的设计各有各的不同。这是说设计出问题后，经常表现是一样的，但原因不同。论坛上经常有人问问题，以为回答的人都是老中医一样，一眼就能看出问题。其实在现实中，即使手把手帮别人调试错误，也需要不少时间定位。比如常常有人问Δ-sigmaADC的低频噪声高是什么原因。这就像有人问医生，我发烧，为什么？发烧是表象，直接原因是机体有炎症，深层原因就各自不同了，病毒细菌感染都有可能。甚至不排除温度计坏了这种事情。低频噪声高也是表现，直接原因是没有设计好，深层原因可能是op带宽不足，开关时序不对，整体架构时序不对，甚至不排除计算方法的问题。
不成功的设计都是相似的，成功的设计各有各的不同。这是说条条大路通罗马，各种方法都有优缺点。 
Gm Id方法的思考
前一阵版面上gm/Id说的轰轰烈烈，这个方法我也看过。在刚开始接触模拟电路设计时大家最头疼的莫过于定工作点，更头疼的莫过于经典的那个方法用起来很不顺手，vdsat是什么，vgs-vth是什么，书上说的都听好听，工作中一用才发现根本不是那回事。所以gm/Id也有其应运而生的理由。不过这个方法我没怎么用，原因有几个：1.毕竟在上学时没有使用这个方法，就有些不习惯了，就像习惯了awd，不喜欢wavescan一样。2. 这个方法带来的好处没有那么明显。我也不是格外排除新技术的人，比如仿真反馈，现在就喜欢stb方法而不会用LC去断环路，大的仿真sx去看波形而不是awd，但是如果带来的好处不大，就没太大动力了。比如同样是稳定性，bode图就比根轨迹图用的多，反馈中A*beta也比return ratio用的熟练。gm/Id固然解决了vdsat定义的难题，但实际中调习惯了电路也不会太为vdsat头疼。3. 到了一定程度，工作点就是一个砖头一样的东西，盖大楼时有时就不纠结于某个砖缺了个角还是多了一小块，只要不是该放整砖的地方偷工减料成了半块就行。没有人会觉得你设计的是vdsat=0.2V比另一个vdsat=0.25v更优化一些。
从历史的角度看，可能有所启发。最早的教科书上一堆图表，因为那时计算是个大问题，查表是个好办法。后来计算的难度下降，大家都很容易算公式了，公式就多了，因为公式更加准确，抽象能力也更强。但是再往后发现随着工艺进步公式越来越不准了，只好不停的修补公式，这时再记忆公式就没太大优点了。所以返璞归真，又回到图表的老路上去。所以gm/Id用历史的眼光来看，就是过去的图表又回来了。最终我们需要用简化公式来理解大致趋势，用图表来得到查表数值，用仿真器来精确得到数值。
从学校的角度，有的学校和老师没有把这些相关信息讲清楚，搞的很多学生觉得课本距离实际太远，许多学生上来就问怎么才能知道vth，u，beta，却没想到看一看自己用的model是哪种，看来所谓的gap就来自于这些小细节。 
模拟电路设计的流程
现在数字电路很讲究流程，还设有有专门的流程组。我的理解是这样的，流程就是用制度去保证人很少犯错。但是为什么几年前流程组还没组建呢？我的理解是这样的，事情必须复杂到一定程度，又可以简化到一定程度，才能看到流程的好处。就是说复杂是复杂，但是规律性又很强，可以复用。否则每次都针对新情况设计一个新流程，岂不是自己给自己找麻烦？
说完了数字，这里还是重点讨论模拟。似乎不会有公司给模拟搞个流程组（我见过的公司太少，有知道更多的可以留言）。我的理解是这样的，模拟的事情很简单，但是模拟的事情又很复杂。简单是说没有几样事情，复杂是说次次碰到的事情都可能不同。可能有些说相声了，不知道有没有人和我同感。
简单的说明一下我所经历的模拟设计流程：先是定spec，看个人做什么，如果是大的项目的leader，可以看做是项目的用户需求，如果是把大模块拆成小模块了，可以看成是各小block的设计任务。根据情况不同，可以写成书面的，也可以口头讨论。严格说，还不算一般理解的设计的开始。然后是行为级设计，这也看情况，有的就完全不需要，有的自己手推公式也算，有的太复杂，就要用matlab，用veriloga，或者icfb里用理想电阻电容，怎么方便怎么来。行为级的目的，一个是增加对系统的理解，另一个是提高仿真速度。和数字的类比，就好比是做算法的人写出c代码。之后才是一般理解的画电路图，做仿真。这好比是rtl代码实现。做仿真其实有些像数字中的验证工作。其实验证和仿真的意义非常重大。仿真就是看自己的设计是否按照自己的预期实现。而自己的仿真电路就反映了自己对电路工作的理解。所以如果只看仿真结果而不看仿真是如何实现的，就是白搭。说这个是因为以前经常有不懂模拟电路的头，当电路出问题了，会对我们这边说，你快仿仿，看看问题在哪里。似乎仿真包治百病。这可能就是从数字电路设计处继承的习惯。我认为好的思维方式应该是先收集一定的现象，然后通过思考进行定位，然后才是通过仿真去验证思考的结果或者帮助思考。模拟的仿真和数字另一个不同就是目前数字有把仿真放到验证组的趋势，而模拟的仿真很难脱离设计者。电路图结束后就是版图，版图有的公司是设计人员实现，有的则是单独的，不过即使是单独的，设计人员也依然负责把关。版图之后是后仿（其实两者通常交叉耦合）。这与数字的后端之后门仿也有类似之处。
除了这些，给soc做模拟ip还会有一些其他不完全算在传统设计概念里，但是也离不开设计者的工作，比如做数字集成用的模型，比如提供时序信息和版图信息，换句话说，就是把一个复杂的模拟IP包装成一个简单的黑盒子，给外界扔一个通用的接口信息。其实这些很多时候倒是可以做些自动化的工具简化工作。
这么看下来，现在的工具给设计者武装的很少，就是画电路图，仿真，画版图三大样，不像数字的无数种工具，如同集团军一般。但是要把工具用好，也有技巧在里面。特别是仿真，也同样要做tradeoff，是时间和精度的tradeoff。时常有人问要不要做蒙特卡洛仿真，要不要做这个仿真，那个仿真。当时我给我们小组写规范的时候，写到这里统统都没要求。不是不想，是没法一刀切。也许等某天机器无穷快，机器无穷多，可以硬性规定一些是必须做的。但是不硬性规定，就会依赖于设计人员的素质，而设计流程的一个目的就是要尽可能脱离人的素质。这真是一个难题啊。 
提问的学问
做这一行的，在实践过程中问题会遇到很多，因此就常常需要求助于别人。不过求助于别人也并不是一件简单的事情。我不是说别人会不帮忙之类，我这里要说的是，对于从别人那里得来的答案，千万别不假思索的接受下了。
为什么会这么说呢？道理有几条：第一，别人的情况未必就是你的情况。实践各种问题千奇百怪，可能同样的原因表现有多种，同样的表现原因有多种，你说的也许和对方的不是同一个东西。再加上工艺也在发生变化，不同工艺下的要求也是不一样，有时甚至是相反，要是用这个工艺下的结果去看另一个工艺下的情况，也许就失手了。比如同样是做匹配，小尺寸工艺下就有可能有源区到阱的间距强烈影响匹配，大尺寸下谁在意这个呢？第二，别人甚至都没有能够理解你的问题。实践中，我觉得在描述的过程中很容易丢失一些信息，这种情况下，别人的答案可能就是基于你的错误描述给出的。第三，所有的结论都是有前提的，但是往往在听者这里可能就无意的把前提忽略了。我们那里原来有个人做dac也做了几年了，有一次问他做dac里mismatch如何约束每个unit的面积。他blala讲了一个公式。我觉得似乎和以前我知道的不一样，且偏大不少。再问怎么来的，他又找啊找，从某个书里找出来。我对比他的公式和我知道的公式，就发现，他那个书里说的是worse case，而他却一直浑然不觉。
所以即使做工程，也怕死记硬背型的，知其然更知其所以然才是正确的态度。 
科学与迷信
前两天同事测芯片。那个芯片有个特性，上电管理里有个寄存器存储状态，下电再上是不工作的，第二次上电才工作。这个特性当时忘了告诉他。他就得出一个很奇怪的结论：这个芯片必须从某个电压快速上升到另一个电压才能工作。后来回顾，可能是他第二次上电有问题，再次上电用了这种方法，芯片正常工作了，于是他就得到了上述推论。
从这个故事我想起了另一个故事，某个小岛上的土著总是做一些奇怪的动作向上天祈祷，后来人们经过研究历史发现，原来二战时这个岛曾经是个基地，飞机有时会送给养，土著们看到地面工作人员的动作，以为只要这样做，就可以从上天得到东西。
从某种意义上说，这两个故事就解释了迷信的起源。在某些时候，我们看到了事件A，又看到了事件B，产生了错误的因果关联，就出现了一种迷信。有人会说，这种迷信挺容易破解的，比如我们多做几次实验，就可以推导出不同的结论从而否定假设。这听着容易，做起了挺难。设计芯片也算科学技术的领域了，可是类似迷信的做法也不少。有一次芯片性能有点问题，我们查了半天，觉得查到原因了，大老板说不改，因为如果改了可能出新问题。如果成功的IP，是连线也不能动的，万一动了出问题呢？这种想法也很现实，我们受限于各种条件，虽然理论上可以知道会怎样，但实际是做不到完全精确预测的，而如果失败的成本很高，比如几百万的流片费，那只能选择迷信了。
所以如果认知受限于各种条件，同时失败成本很高，人们自然而然就会选择迷信。当人们感到自己能正确把握规律，能了解背后的因果关系，迷信就逐步后退，这就是科学的力量。不过科学也是力量有限的。人类可以精确预测一个球下降的轨迹，没人能精确预测一个纸片的下降轨迹。当系统的复杂度进一步提升后，至少我们目前对规律的掌握能力是有限的。在现实中，类似的场景很多，比如经商，比如升官，所以商人和官员的迷信程度是远远大于工程师的，因为他们面临的是一个很难预测的场景或者失败了成本很高的场景。对未来越缺乏掌控感，就越容易迷信。当然这也和所谓的科学素养有关。经过科学训练的人和没经过训练的人面对同样的场景，反应也是不同的，前者从逻辑出发，寻找前因后果，后者更倾向于想当然。面对纸片下降的事情，有的人想发展流体力学，湍流理论或者非线性分析，有的人也许会用这个现象来占卜。
即使在工程师群体里，也存在很多类似的迷信，从某种意义上说，所谓的rule of thumb就是一种。有的人碰到问题，第一反应是试一试，碰碰运气，或者以前我就是碰巧那么解决了，那么这次也这么干好了。这种不存在因果关系的做法，和社会的迷信其实是一个性质。存在即是合理，经验在某种情况下是逻辑的一种补充。如果站在更高的认识角度，也许能给经验一个合理的解释。以前大老板对待IP的做法我完全可以理解。科学自身也没能一次回答所有问题。但是如果沉迷于这种迷信，不把自己的认识提高，那就和社会上没了科学是一个样子，停滞不前。所以如果能找到正确的因果关系，是上上策，这也是科学能不停发展的原因。
还有一种情况，有的人讲的每个词都是科学术语，但是前因后果之间不存在任何逻辑。这种表面看是科学，其实是迷信的做法也挺常见，也挺容易糊弄人，因为只要自己的思维偷懒，就很容易以为对方是在讲科学。很多乱七八糟的广告就喜欢这么搞。 
设计历程
之前有人把模拟电路设计分为了九个段位，文章写的生动有趣，吸引了不少人。我也照虎画猫，从我自己的感受谈谈模拟电路设计的几个阶段。
首先是相信spice。刚上学接触到spice，感觉多么神奇的工具，甚至计算机性能的benchmark里都有spice（参见计算机体系结构）。上课讲的是spice，课本里讲完电路之后也是用spice验证一下，给人感觉这就是传说中的神器。
其次是不相信spice。一旦流片几次之后，就总有这样那样对不上的问题。然后自己会说我用spice都仿过了啊。
再往后是有点相信spice。debug时发现，哦如果我在这里加一个寄生电容，那就和实际有些对上了。于是修改流程，增加后仿。
最后是发现与其说spice，不如说自己。如同我之前所说的，spice只是一个解方程的工具，如何列方程完全是设计者的责任，列方程的质量好坏也依赖与设计者。有人可以列出一个又快又准的，有人可以列出不快但准的，有人列出快而不准，有人不快不准。  
个人觉得一些重要的学科
概率与统计，我觉得是被低估太多的学科。从小到大，数理化都讲的是确定性的理论，一个炮弹初速多少，倾角多少，就可以计算出落地点，这给我们太多自信或者自满。但概率与统计上来就告诉我们实际情况远比这个复杂，世界也不是非黑即白，这个思想甚至比里面具体的知识更重要。就拿最近的疫苗事件来说，很多人就会直接说国产疫苗好或者不好两个结论，却没有仔细想过，好与不好其实可以更定量更精确的去描述。做analog，对概率与统计的理解应该更深刻些。（这两天在看《女士品茶》。这本书是一本讲统计学历史的书籍，几年前也曾读过，这次再读，似乎比几年前感受更深一些。）
控制与反馈，也是本身的意义比具体学科内容更重要。这几乎就是哲学上说的万事万物是相互联系的观点的科学版本，而且和哲学上的抽象不同，这里还告诉我们该怎样去考虑联系（当然，也只能处理一些简单的情况）。用这个观点去考虑一些社会学的东西也很有趣。比如，你可以论证如果A，那么B，然后论证如果A，那么！B，其实很简单，只要你偷偷的在论证过程中把从A到B的几条路径有选择的使用就可以了。
几何与逻辑，这两个放一起，实在是因为几何原本的逻辑性太强大了。由a到b，只有逻辑一条路可走。用逻辑去卡很多论证的话，就发现这个世界忽悠太多。 
总结 
如果从1999年7月开始用spice给老师跑仿真，画版图算起，进入IC设计已经十多年了。这期间做过的电路类型有读出电路，有Δ-sigmaAD/DA，有pll，dll，有高速IO，帮人调试过的电路也有一些。当然感兴趣想做而未作的电路更多了。从预研，电路设计，版图，测试，基本可以算作一个反馈过程。那么这个反馈应该也经历了很多次了。自己的本子上也记录了不少东西。想想还是把这些东西写成blog形式好一些，一方面可以起到整理自己思路的作用，另一方面也可以起到抛砖引玉的作用，提出很多问题与大家一起讨论。
基于以上考虑，准备写一个模拟集成电路设计的系列。初步想法是写一些书本上没讲，或者讲了但在实际中个人觉得很重要需要强调的概念，再就是写一些日常的技巧，这些技巧往往与具体电路或者具体软件有关，课本习惯是不讲的。至于时间安排，可能一周用中午时间写一两篇吧。顺序安排上，还是按照一般课本的做法，从器件到系统的顺序。
先给自己列个大纲，好督促自己。0.基本概念 1. 器件特性2.基本模块 3. bandgap 4.opa，ota 5.开关电容电路 6.传输函数，稳定性。7 反馈。8.版图。9 非线性 10.噪声。11。Δ-sigma AD DA 12. pll 13. 高速IO 14. 软件使用。


